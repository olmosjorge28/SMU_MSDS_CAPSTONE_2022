{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "from numpy.random import normal\n",
    "\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from multiprocessing import cpu_count\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torchmetrics.functional import accuracy\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, recall_score, precision_score, f1_score, roc_auc_score, auc, average_precision_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "from keras.layers import Conv1D, Dense, Dropout, Input, Concatenate, GlobalMaxPooling1D, MaxPooling1D\n",
    "from keras.models import Model\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# from keras.optimizers import RMSprop, adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "day1_dataset_1min = pd.read_csv('../Data Slices/5_days_timeseries_data/1min.csv')\n",
    "day1_dataset_10min = pd.read_csv('../Data Slices/5_days_timeseries_data/10min.csv')\n",
    "day1_dataset_30min = pd.read_csv('../Data Slices/5_days_timeseries_data/30min.csv')\n",
    "day1_dataset_60min = pd.read_csv('../Data Slices/5_days_timeseries_data/60min.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Datetime_updated_seconds</th>\n",
       "      <th>Price_USD</th>\n",
       "      <th>Price_Crypto</th>\n",
       "      <th>density</th>\n",
       "      <th>vertex_count</th>\n",
       "      <th>edge_count</th>\n",
       "      <th>max_diameter</th>\n",
       "      <th>max_radius</th>\n",
       "      <th>max_peripher</th>\n",
       "      <th>volume</th>\n",
       "      <th>collection</th>\n",
       "      <th>blacklisted</th>\n",
       "      <th>whitelisted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>118080</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-10-11 22:00:00</td>\n",
       "      <td>0.720015</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>zombieartist</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118081</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-10-11 23:00:00</td>\n",
       "      <td>0.720015</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>zombieartist</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118082</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-10-12 00:00:00</td>\n",
       "      <td>0.720015</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>zombieartist</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118083</th>\n",
       "      <td>3</td>\n",
       "      <td>2020-10-12 01:00:00</td>\n",
       "      <td>0.720015</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>zombieartist</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118084</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-10-12 02:00:00</td>\n",
       "      <td>0.720015</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>zombieartist</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118195</th>\n",
       "      <td>115</td>\n",
       "      <td>2020-10-16 17:00:00</td>\n",
       "      <td>0.106620</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>zombieartist</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118196</th>\n",
       "      <td>116</td>\n",
       "      <td>2020-10-16 18:00:00</td>\n",
       "      <td>0.106620</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>zombieartist</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118197</th>\n",
       "      <td>117</td>\n",
       "      <td>2020-10-16 19:00:00</td>\n",
       "      <td>0.106620</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>zombieartist</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118198</th>\n",
       "      <td>118</td>\n",
       "      <td>2020-10-16 20:00:00</td>\n",
       "      <td>0.106620</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>zombieartist</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118199</th>\n",
       "      <td>119</td>\n",
       "      <td>2020-10-16 21:00:00</td>\n",
       "      <td>0.106620</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>zombieartist</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0 Datetime_updated_seconds  Price_USD  Price_Crypto  density  \\\n",
       "118080           0      2020-10-11 22:00:00   0.720015          23.0      1.0   \n",
       "118081           1      2020-10-11 23:00:00   0.720015          23.0      1.0   \n",
       "118082           2      2020-10-12 00:00:00   0.720015          23.0      1.0   \n",
       "118083           3      2020-10-12 01:00:00   0.720015          23.0      1.0   \n",
       "118084           4      2020-10-12 02:00:00   0.720015          23.0      1.0   \n",
       "...            ...                      ...        ...           ...      ...   \n",
       "118195         115      2020-10-16 17:00:00   0.106620           3.0      0.1   \n",
       "118196         116      2020-10-16 18:00:00   0.106620           3.0      0.1   \n",
       "118197         117      2020-10-16 19:00:00   0.106620           3.0      0.1   \n",
       "118198         118      2020-10-16 20:00:00   0.106620           3.0      0.1   \n",
       "118199         119      2020-10-16 21:00:00   0.106620           3.0      0.1   \n",
       "\n",
       "        vertex_count  edge_count  max_diameter  max_radius  max_peripher  \\\n",
       "118080           2.0         1.0           1.0         1.0           2.0   \n",
       "118081           2.0         1.0           1.0         1.0           2.0   \n",
       "118082           2.0         1.0           1.0         1.0           2.0   \n",
       "118083           2.0         1.0           1.0         1.0           2.0   \n",
       "118084           2.0         1.0           1.0         1.0           2.0   \n",
       "...              ...         ...           ...         ...           ...   \n",
       "118195          20.0        19.0           0.0         0.0           0.0   \n",
       "118196          20.0        19.0           0.0         0.0           0.0   \n",
       "118197          20.0        19.0           0.0         0.0           0.0   \n",
       "118198          20.0        19.0           0.0         0.0           0.0   \n",
       "118199          20.0        19.0           0.0         0.0           0.0   \n",
       "\n",
       "        volume    collection  blacklisted  whitelisted  \n",
       "118080     1.0  zombieartist            0            1  \n",
       "118081     0.0  zombieartist            0            1  \n",
       "118082     0.0  zombieartist            0            1  \n",
       "118083     0.0  zombieartist            0            1  \n",
       "118084     0.0  zombieartist            0            1  \n",
       "...        ...           ...          ...          ...  \n",
       "118195     0.0  zombieartist            0            1  \n",
       "118196     0.0  zombieartist            0            1  \n",
       "118197     0.0  zombieartist            0            1  \n",
       "118198     0.0  zombieartist            0            1  \n",
       "118199     0.0  zombieartist            0            1  \n",
       "\n",
       "[120 rows x 14 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day1_dataset_60min[day1_dataset_60min['collection'] == 'zombieartist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_collections = pd.read_csv('NFT_Kmeans_Train_Val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2787550744248985"
      ]
     },
     "execution_count": 581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustered_collections[clustered_collections['train_val_set'] == 'Training']['blacklisted'].sum()/clustered_collections[clustered_collections['train_val_set'] == 'Training']['blacklisted'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2787550744248985"
      ]
     },
     "execution_count": 701,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_4= clustered_collections[clustered_collections['kmeans_clusters'] == 4]\n",
    "cluster_5= clustered_collections[clustered_collections['kmeans_clusters'] == 5]\n",
    "cluster_1= clustered_collections[clustered_collections['kmeans_clusters'] == 1]\n",
    "# clustered_collections[clustered_collections['train_val_set'] == 'Training']['blacklisted'].sum()/clustered_collections[clustered_collections['train_val_set'] == 'Training']['blacklisted'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['collection', 'blacklisted', 'train_val_set', 'kmeans_clusters'], dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustered_collections.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_df = clustered_collections[clustered_collections['train_val_set']=='Training']\n",
    "validation_df = clustered_collections[clustered_collections['train_val_set']=='Validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>collection</th>\n",
       "      <th>blacklisted</th>\n",
       "      <th>train_val_set</th>\n",
       "      <th>kmeans_clusters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1amazingbook</td>\n",
       "      <td>0</td>\n",
       "      <td>Validation</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1forthebirds</td>\n",
       "      <td>0</td>\n",
       "      <td>Validation</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1fungidents1</td>\n",
       "      <td>0</td>\n",
       "      <td>Validation</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2cryptokingg</td>\n",
       "      <td>0</td>\n",
       "      <td>Validation</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3dnanoocards</td>\n",
       "      <td>0</td>\n",
       "      <td>Validation</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>wpcwrarecard</td>\n",
       "      <td>0</td>\n",
       "      <td>Validation</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>wvmnftsonwax</td>\n",
       "      <td>0</td>\n",
       "      <td>Validation</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>xthingscards</td>\n",
       "      <td>0</td>\n",
       "      <td>Validation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>xxbleetcolxx</td>\n",
       "      <td>0</td>\n",
       "      <td>Validation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>zamuraionwax</td>\n",
       "      <td>1</td>\n",
       "      <td>Validation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>246 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       collection  blacklisted train_val_set  kmeans_clusters\n",
       "0    1amazingbook            0    Validation                4\n",
       "4    1forthebirds            0    Validation                4\n",
       "5    1fungidents1            0    Validation                4\n",
       "10   2cryptokingg            0    Validation                4\n",
       "12   3dnanoocards            0    Validation                4\n",
       "..            ...          ...           ...              ...\n",
       "968  wpcwrarecard            0    Validation                5\n",
       "970  wvmnftsonwax            0    Validation                5\n",
       "972  xthingscards            0    Validation                1\n",
       "973  xxbleetcolxx            0    Validation                1\n",
       "976  zamuraionwax            1    Validation                1\n",
       "\n",
       "[246 rows x 4 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Tuple\n",
    "from enum import Enum\n",
    "\n",
    "\n",
    "class DatasetType(Enum):\n",
    "    TRAINING = 'Training'\n",
    "    VALIDATION = 'Validation'\n",
    "    \n",
    "class Aggregation(Enum):\n",
    "    ONE_MIN = 1\n",
    "    TEN_MIN = 2\n",
    "    THIRTHY_MIN = 3\n",
    "    SIXTY_MIN = 4\n",
    "\n",
    "class Collection:\n",
    "    def __init__(self, name, aggregations:  Dict[Aggregation, pd.DataFrame] = dict(), blacklisted=0):\n",
    "        self.name = name\n",
    "        self.aggregations: Dict[Aggregation, pd.Dataframe] = aggregations\n",
    "        self.blacklisted = blacklisted\n",
    "    \n",
    "    def get_aggregation(self, aggregation: Aggregation):\n",
    "        return self.aggregations.get(aggregation)\n",
    "    \n",
    "    def add_aggregation(self,aggregation: Aggregation, a_df: pd.DataFrame):\n",
    "        self.aggregations[aggregation] = a_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, ds_type: DatasetType, cluster,  collections: List[Collection] = None, columns = []):\n",
    "        self.collections = []\n",
    "        self.ds_type = ds_type\n",
    "        self.columns = columns\n",
    "        \n",
    "    def add(self, collection: Collection):\n",
    "        self.collections.append(collection)\n",
    "        \n",
    "    def concat(self, aggregation):\n",
    "        return pd.concat(\n",
    "            [collection.get_aggregation(aggregation) for collection in self.collections], ignore_index=True)\n",
    "    \n",
    "    def fit(self, aggregation, scaler):\n",
    "        scaler.fit(self.concat(aggregation)[self.columns])\n",
    "    \n",
    "    def transform(self, aggregation, scaler: StandardScaler):\n",
    "        for collection in self.collections:\n",
    "            all_columns = collection.get_aggregation(aggregation).copy()\n",
    "            internal_df = all_columns[self.columns].copy()\n",
    "            internal_df = scaler.transform(internal_df)\n",
    "            collection.add_aggregation(\n",
    "                aggregation, internal_df.copy())\n",
    "    \n",
    "    @property\n",
    "    def length(self):\n",
    "        return len(self.collections)\n",
    "            \n",
    "    def format(self):\n",
    "        x_arr = []\n",
    "        for agg in Aggregation:\n",
    "            x = [collection.get_aggregation(agg) for collection in self.collections]\n",
    "            shape = x[0].shape\n",
    "            x =  np.stack(x)\n",
    "            x = x.reshape(self.length, shape[0], shape[1])\n",
    "            x_arr.append(x)\n",
    "        return x_arr, [collection.blacklisted for collection in self.collections]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing cluster 1 with shape (513, 4)\n",
      "processing cluster 4 with shape (369, 4)\n",
      "processing cluster 5 with shape (103, 4)\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "for cluster in list(clustered_collections.groupby(['kmeans_clusters'])):\n",
    "    print(f'processing cluster {cluster[0]} with shape {cluster[1].shape}')\n",
    "    cluster_number = cluster[0]\n",
    "    columns = ['Price_USD', \n",
    "                                    'Price_Crypto', \n",
    "                                    'volume', \n",
    "                                    'density', \n",
    "                                    'vertex_count', \n",
    "                                    'edge_count', \n",
    "                                    'max_diameter', \n",
    "                                    'max_radius', \n",
    "                                    'max_peripher']\n",
    "    training = Dataset(ds_type=DatasetType.TRAINING, cluster = cluster_number,columns=columns )\n",
    "    validation = Dataset(ds_type=DatasetType.VALIDATION, \n",
    "                         cluster = cluster_number, \n",
    "                         columns = columns)\n",
    "    for row in cluster[1].itertuples(index=False, name=None):\n",
    "        collection = Collection(name=row[0], blacklisted=row[1])\n",
    "        ds_type = row[2]\n",
    "        \n",
    "        for aggregation in [(Aggregation.ONE_MIN, day1_dataset_1min), \n",
    "                   (Aggregation.TEN_MIN, day1_dataset_10min), \n",
    "                   (Aggregation.THIRTHY_MIN, day1_dataset_30min),\n",
    "                   (Aggregation.SIXTY_MIN, day1_dataset_60min) ]:\n",
    "            collection.add_aggregation(aggregation[0], aggregation[1].loc[aggregation[1]['collection'] == collection.name].copy())\n",
    "        \n",
    "        \n",
    "        if ds_type == DatasetType.TRAINING.value:\n",
    "            training.add(copy.deepcopy(collection))\n",
    "        elif ds_type == DatasetType.VALIDATION.value:\n",
    "            validation.add(copy.deepcopy(collection))\n",
    "    models.append(MCNNModel(training = training, validation = validation, cluster = cluster_number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Price_USD',\n",
       " 'Price_Crypto',\n",
       " 'volume',\n",
       " 'density',\n",
       " 'vertex_count',\n",
       " 'edge_count',\n",
       " 'max_diameter',\n",
       " 'max_radius',\n",
       " 'max_peripher']"
      ]
     },
     "execution_count": 695,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models[0].training.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCNNModel:\n",
    "\n",
    "    def __init__(self,  training: Dataset, validation: Dataset, cluster,  \n",
    "                 filters = [200,200,200,200], \n",
    "                 k_sizes= [500,50,30,20],\n",
    "                 batch_size = 50\n",
    "                ):\n",
    "        self.training = training\n",
    "        self.validation = validation\n",
    "        self.cluster = cluster\n",
    "        self.scalers =   {agg: StandardScaler() for agg in Aggregation}\n",
    "        self.filters = filters\n",
    "        self.k_sizes = k_sizes\n",
    "        self.batch_size = 50\n",
    "        self.model = None\n",
    "        self.model_hist = None\n",
    "        self.scaled = False\n",
    "        \n",
    "    def scale(self):\n",
    "        if not self.scaled:\n",
    "            for agg in Aggregation:\n",
    "                print('fitting aggregation', agg)\n",
    "                self.training.fit(agg, self.scalers.get(agg))\n",
    "                print('transforming aggregation', agg)\n",
    "                self.training.transform(agg, self.scalers.get(agg))\n",
    "                self.validation.transform(agg, self.scalers.get(agg))\n",
    "            self.scaled = True\n",
    "            \n",
    "            \n",
    "    def retrieve_tensor_datasets(self):\n",
    "        train_x, train_y = self.training.format()\n",
    "        validation_x, validation_y = self.validation.format()\n",
    "        formatted_train = ({f'input{n}': data for n, data in enumerate(train_x) }, train_y)\n",
    "        formatted_test = ({f'input{n}': data for n, data in enumerate(validation_x) }, validation_y)\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices(formatted_train).batch(200)\n",
    "        test_dataset = tf.data.Dataset.from_tensor_slices(formatted_test).batch(200)\n",
    "        return train_dataset, test_dataset\n",
    "    \n",
    "    @property\n",
    "    def shapes(self):\n",
    "        return [aggregation_type.shape \n",
    "                for aggregation_type in list(self.training.collections[0].aggregations.values())]\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_base_model(shape, k_size = k_sizes[0], num_filters = filters[0]):\n",
    "        print(\"base model shape\", shape)\n",
    "        input_seq = Input(shape=shape)\n",
    "        nb_filters = num_filters\n",
    "        convolved = Conv1D(num_filters, k_size, padding=\"same\", activation=\"relu\")(input_seq)\n",
    "        processed = GlobalMaxPooling1D()(convolved)\n",
    "        #todo: fix maxpooling\n",
    "    #     processed = MaxPooling1D(pool_size=2, strides=1, padding='same')(convolved)\n",
    "        compressed = Dense(100, activation=\"relu\")(processed)\n",
    "        compressed = Dropout(0.3)(compressed)\n",
    "        model = Model(inputs=input_seq, outputs=compressed)\n",
    "        model.summary()\n",
    "        return model\n",
    "    \n",
    "    @staticmethod\n",
    "    def main_model(shapes, filters, k_sizes):\n",
    "        inputs = [Input(shape=shape, name=f'input{n}')for n, shape in enumerate(shapes)]\n",
    "        sub_models = [ MCNNModel.get_base_model(shape, k_size = k_sizes[n], num_filters=filters[n]) \n",
    "                      for n, shape in enumerate(shapes)]\n",
    "        print(sub_models[0].output)\n",
    "        embeddings = [ model(inputs[n]) for n, model in enumerate(sub_models)]\n",
    "        merged = Concatenate()(embeddings)\n",
    "        #todo: tweak dense be modifiable \n",
    "        layer1 = Dense(100, activation='relu', name ='hidden_layer1')(merged)\n",
    "        layer2 = Dense(50, activation='relu', name ='hidden_layer2')(layer1)\n",
    "        layer3 = Dense(25, activation='relu', name ='hidden_layer3')(layer2)\n",
    "        out = Dense(1, activation='sigmoid')(layer3)\n",
    "        model = Model(inputs=inputs, outputs=out)\n",
    "        return model\n",
    "    \n",
    "    def run_model(self):\n",
    "        train, validation = self.retrieve_tensor_datasets()\n",
    "        model_shapes = self.shapes\n",
    "        filters = self.filters\n",
    "        k_sizes = self.k_sizes\n",
    "        es = keras.callbacks.EarlyStopping(min_delta=0.1, patience=5)\n",
    "        model = MCNNModel.main_model(model_shapes, filters, k_sizes)\n",
    "        model.compile(loss='binary_crossentropy', # categorical_crossentropy\n",
    "                              optimizer='adam', #sgd, nadam, adam, rmsprop\n",
    "                              metrics=['binary_accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall(),\n",
    "                                       tf.keras.metrics.AUC(curve='PR')])\n",
    "        model.summary()\n",
    "        model_hist = model.fit(train,\n",
    "                                   validation_data=validation,\n",
    "                                   batch_size=self.batch_size, epochs=2000, \n",
    "                               callbacks=[es]\n",
    "                              )\n",
    "        self.model = model\n",
    "        self.model_hist = model_hist\n",
    "        return self\n",
    "    \n",
    "    def predict(self):\n",
    "        val_x, val_y = self.validation.format()\n",
    "        if self.model:\n",
    "            result = self.model.predict(val_x)\n",
    "            return [result[0] for result in results], val_y\n",
    "        else:\n",
    "            return [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pr_auc(actual, scores):\n",
    "    precision, recall, thresholds = precision_recall_curve(actual, scores)\n",
    "    # Use AUC function to calculate the area under the curve of precision recall curve\n",
    "    auc_precision_recall = auc(recall, precision)\n",
    "    return auc_precision_recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "class CustomClusteredModel:\n",
    "    def __init__(self, models: List[MCNNModel], thresholds=None):\n",
    "        self.models = models\n",
    "        self.scores = dict()\n",
    "        if thresholds:\n",
    "            self.thresholds = thresholds\n",
    "        else:\n",
    "            self.thresholds = {\n",
    "                1:0.37209302325581395,\n",
    "                4:0.20284697508896798,\n",
    "                5:0.07042253521126761\n",
    "            }\n",
    "    \n",
    "    def scale(self):\n",
    "        for model in self.models:\n",
    "            model.scale()\n",
    "        \n",
    "    def train_model(self):\n",
    "        futures = []\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            for model in self.models:\n",
    "                an_executor = executor.submit(model.run_model)\n",
    "                futures.append(an_executor)\n",
    "        \n",
    "        for a_future in as_completed(futures):\n",
    "            model = a_future.result()\n",
    "            print(f'Modeling for cluster {model.cluster} finished')\n",
    "            \n",
    "    def metrics(self):\n",
    "        all_predictions = []\n",
    "        all_actuals = []\n",
    "        all_scores = []\n",
    "        \n",
    "        for model in self.models:\n",
    "            predictions, actuals = CustomClusteredModel.predict(model)\n",
    "            print('prediction and actuals', len(predictions), len(actuals))\n",
    "            all_predictions.extend([1 if prediction > self.thresholds.get(model.cluster) else 0 for prediction in predictions])\n",
    "            all_scores.extend(predictions)\n",
    "            all_actuals.extend(actuals)\n",
    "        print(len(all_predictions))\n",
    "        print(len(all_actuals))\n",
    "        self.scores['accuracy'] = accuracy_score(all_actuals, all_predictions)\n",
    "        self.scores['recall'] = recall_score(all_actuals, all_predictions)\n",
    "        self.scores['precision'] = precision_score(all_actuals, all_predictions)\n",
    "        self.scores['f1_score'] = f1_score(all_actuals, all_predictions)\n",
    "        self.scores['pr_auc'] = average_precision_score(all_actuals, all_scores) #pr_auc\n",
    "        self.scores['auc'] = roc_auc_score(all_actuals, all_scores)\n",
    "        return self.scores\n",
    "        \n",
    "    @staticmethod    \n",
    "    def predict(model):\n",
    "        #add choose model (Andrew's clustering/classifcation) \n",
    "        val_x, val_y = model.validation.format()\n",
    "#         print('val x shape', val_x)\n",
    "        if model:\n",
    "            results = model.model.predict(val_x)\n",
    "            print('inside predict', len(result))\n",
    "            return [result[0] for result in results], val_y\n",
    "        else:\n",
    "            return [], []\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccm = CustomClusteredModel(models)\n",
    "ccm2 = CustomClusteredModel(models, thresholds={\n",
    "            1:0.2787550744248985,\n",
    "            4:0.2787550744248985,\n",
    "            5:0.2787550744248985\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting aggregation Aggregation.ONE_MIN\n",
      "transforming aggregation Aggregation.ONE_MIN\n",
      "fitting aggregation Aggregation.TEN_MIN\n",
      "transforming aggregation Aggregation.TEN_MIN\n",
      "fitting aggregation Aggregation.THIRTHY_MIN\n",
      "transforming aggregation Aggregation.THIRTHY_MIN\n",
      "fitting aggregation Aggregation.SIXTY_MIN\n",
      "transforming aggregation Aggregation.SIXTY_MIN\n",
      "fitting aggregation Aggregation.ONE_MIN\n",
      "transforming aggregation Aggregation.ONE_MIN\n",
      "fitting aggregation Aggregation.TEN_MIN\n",
      "transforming aggregation Aggregation.TEN_MIN\n",
      "fitting aggregation Aggregation.THIRTHY_MIN\n",
      "transforming aggregation Aggregation.THIRTHY_MIN\n",
      "fitting aggregation Aggregation.SIXTY_MIN\n",
      "transforming aggregation Aggregation.SIXTY_MIN\n",
      "fitting aggregation Aggregation.ONE_MIN\n",
      "transforming aggregation Aggregation.ONE_MIN\n",
      "fitting aggregation Aggregation.TEN_MIN\n",
      "transforming aggregation Aggregation.TEN_MIN\n",
      "fitting aggregation Aggregation.THIRTHY_MIN\n",
      "transforming aggregation Aggregation.THIRTHY_MIN\n",
      "fitting aggregation Aggregation.SIXTY_MIN\n",
      "transforming aggregation Aggregation.SIXTY_MIN\n"
     ]
    }
   ],
   "source": [
    "ccm.scale()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base model shape (7200, 9)\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 7200, 9)]         0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 7200, 200)         900200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 920,300\n",
      "Trainable params: 920,300\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "base model shape (720, 9)\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 720, 9)]          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 720, 200)          90200     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 110,300\n",
      "Trainable params: 110,300\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "base model shape (240, 9)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 240, 9)]          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 240, 200)          54200     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 74,300\n",
      "Trainable params: 74,300\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "base model shape (120, 9)\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 120, 9)]          0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 120, 200)          36200     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 56,300\n",
      "Trainable params: 56,300\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 100), dtype=tf.float32, name=None), name='dropout/Identity:0', description=\"created by layer 'dropout'\")\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input0 (InputLayer)             [(None, 7200, 9)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input1 (InputLayer)             [(None, 720, 9)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input2 (InputLayer)             [(None, 240, 9)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input3 (InputLayer)             [(None, 120, 9)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model (Functional)              (None, 100)          920300      input0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Functional)            (None, 100)          110300      input1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Functional)            (None, 100)          74300       input2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "model_3 (Functional)            (None, 100)          56300       input3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 400)          0           model[0][0]                      \n",
      "                                                                 model_1[0][0]                    \n",
      "                                                                 model_2[0][0]                    \n",
      "                                                                 model_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer1 (Dense)           (None, 100)          40100       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer2 (Dense)           (None, 50)           5050        hidden_layer1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer3 (Dense)           (None, 25)           1275        hidden_layer2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            26          hidden_layer3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,207,651\n",
      "Trainable params: 1,207,651\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/2000\n",
      "base model shape (7200, 9)\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 7200, 9)]         0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 7200, 200)         900200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 920,300\n",
      "Trainable params: 920,300\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "base model shape (720, 9)\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 720, 9)]          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 720, 200)          90200     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 110,300\n",
      "Trainable params: 110,300\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "base model shape (240, 9)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 240, 9)]          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 240, 200)          54200     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 74,300\n",
      "Trainable params: 74,300\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "base model shape (120, 9)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base model shape (7200, 9)\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 120, 9)]          0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 120, 200)          36200     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 56,300\n",
      "Trainable params: 56,300\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 100), dtype=tf.float32, name=None), name='dropout/Identity:0', description=\"created by layer 'dropout'\")\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 7200, 9)]         0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 7200, 200)         900200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 920,300\n",
      "Trainable params: 920,300\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "base model shape (720, 9)\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 720, 9)]          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 720, 200)          90200     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 110,300\n",
      "Trainable params: 110,300\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "base model shape (240, 9)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 240, 9)]          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 240, 200)          54200     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 74,300\n",
      "Trainable params: 74,300\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "base model shape (120, 9)\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input0 (InputLayer)             [(None, 7200, 9)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input1 (InputLayer)             [(None, 720, 9)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input2 (InputLayer)             [(None, 240, 9)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input3 (InputLayer)             [(None, 120, 9)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model (Functional)              (None, 100)          920300      input0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Functional)            (None, 100)          110300      input1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Functional)            (None, 100)          74300       input2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "model_3 (Functional)            (None, 100)          56300       input3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 400)          0           model[0][0]                      \n",
      "                                                                 model_1[0][0]                    \n",
      "                                                                 model_2[0][0]                    \n",
      "                                                                 model_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer1 (Dense)           (None, 100)          40100       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer2 (Dense)           (None, 50)           5050        hidden_layer1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer3 (Dense)           (None, 25)           1275        hidden_layer2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            26          hidden_layer3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,207,651\n",
      "Trainable params: 1,207,651\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 120, 9)]          0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 120, 200)          36200     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 56,300\n",
      "Trainable params: 56,300\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 100), dtype=tf.float32, name=None), name='dropout/Identity:0', description=\"created by layer 'dropout'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input0 (InputLayer)             [(None, 7200, 9)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input1 (InputLayer)             [(None, 720, 9)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input2 (InputLayer)             [(None, 240, 9)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input3 (InputLayer)             [(None, 120, 9)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model (Functional)              (None, 100)          920300      input0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Functional)            (None, 100)          110300      input1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Functional)            (None, 100)          74300       input2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "model_3 (Functional)            (None, 100)          56300       input3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 400)          0           model[0][0]                      \n",
      "                                                                 model_1[0][0]                    \n",
      "                                                                 model_2[0][0]                    \n",
      "                                                                 model_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer1 (Dense)           (None, 100)          40100       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer2 (Dense)           (None, 50)           5050        hidden_layer1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer3 (Dense)           (None, 25)           1275        hidden_layer2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            26          hidden_layer3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,207,651\n",
      "Trainable params: 1,207,651\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/2000\n",
      "1/1 [==============================] - 121s 121s/step - loss: 1.1072 - binary_accuracy: 0.0704 - precision: 0.0704 - recall: 1.0000 - auc: 0.0554 - val_loss: 0.5103 - val_binary_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0992\n",
      "Epoch 2/2000\n",
      "1/1 [==============================] - 91s 91s/step - loss: 0.4597 - binary_accuracy: 0.9014 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.2050 - val_loss: 0.4442 - val_binary_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0917\n",
      "Epoch 3/2000\n",
      "2/2 [==============================] - 281s 103s/step - loss: 0.5943 - binary_accuracy: 0.7616 - precision: 0.2727 - recall: 0.1053 - auc: 0.2351 - val_loss: 0.6899 - val_binary_accuracy: 0.8409 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.1062\n",
      "1/1 [==============================] - 51s 51s/step - loss: 0.2763 - binary_accuracy: 0.9296 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0985 - val_loss: 0.5919 - val_binary_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0961\n",
      "Epoch 4/2000\n",
      "1/1 [==============================] - 39s 39s/step - loss: 0.2543 - binary_accuracy: 0.9296 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.3002 - val_loss: 0.7067 - val_binary_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.1122\n",
      "Epoch 5/2000\n",
      "Epoch 2/2000\n",
      "2/2 [==============================] - 356s 172s/step - loss: 0.7604 - binary_accuracy: 0.4729 - precision: 0.3897 - recall: 0.7361 - auc: 0.3965 - val_loss: 0.6826 - val_binary_accuracy: 0.6190 - val_precision: 0.8000 - val_recall: 0.0784 - val_auc: 0.5503\n",
      "Epoch 2/2000\n",
      "1/1 [==============================] - 100s 100s/step - loss: 0.3516 - binary_accuracy: 0.9296 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.1289 - val_loss: 0.6874 - val_binary_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.1318\n",
      "Epoch 6/2000\n",
      "1/1 [==============================] - 45s 45s/step - loss: 0.2577 - binary_accuracy: 0.9296 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.1458 - val_loss: 0.6604 - val_binary_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.1452\n",
      "Epoch 7/2000\n",
      "1/1 [==============================] - 72s 72s/step - loss: 0.2056 - binary_accuracy: 0.9296 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.3547 - val_loss: 0.6466 - val_binary_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.3402\n",
      "Epoch 8/2000\n",
      "2/2 [==============================] - 261s 91s/step - loss: 0.6756 - binary_accuracy: 0.8007 - precision: 1.0000 - recall: 0.0175 - auc: 0.2600 - val_loss: 0.5133 - val_binary_accuracy: 0.8409 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.1338\n",
      "Epoch 3/2000\n",
      "1/1 [==============================] - 76s 76s/step - loss: 0.2134 - binary_accuracy: 0.9155 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.2111 - val_loss: 0.6744 - val_binary_accuracy: 0.8438 - val_precision: 0.3333 - val_recall: 0.2500 - val_auc: 0.3366\n",
      "Epoch 9/2000\n",
      "1/1 [==============================] - 48s 48s/step - loss: 0.2127 - binary_accuracy: 0.9155 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.1835 - val_loss: 0.6920 - val_binary_accuracy: 0.8438 - val_precision: 0.3333 - val_recall: 0.2500 - val_auc: 0.3372\n",
      "Epoch 10/2000\n",
      "2/2 [==============================] - 341s 183s/step - loss: 0.6892 - binary_accuracy: 0.6098 - precision: 0.4000 - recall: 0.0972 - auc: 0.4132 - val_loss: 0.6580 - val_binary_accuracy: 0.5873 - val_precision: 0.4615 - val_recall: 0.1176 - val_auc: 0.5082\n",
      "1/1 [==============================] - 45s 45s/step - loss: 0.2214 - binary_accuracy: 0.9296 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.2134 - val_loss: 0.7193 - val_binary_accuracy: 0.8438 - val_precision: 0.3333 - val_recall: 0.2500 - val_auc: 0.3358\n",
      "Epoch 11/2000\n",
      "1/2 [==============>...............] - ETA: 2:12 - loss: 0.5165 - binary_accuracy: 0.7450 - precision: 0.2308 - recall: 0.0682 - auc: 0.3098Epoch 3/2000\n",
      "1/1 [==============================] - 52s 52s/step - loss: 0.1892 - binary_accuracy: 0.9437 - precision: 0.6667 - recall: 0.4000 - auc: 0.3309 - val_loss: 0.7170 - val_binary_accuracy: 0.8438 - val_precision: 0.3333 - val_recall: 0.2500 - val_auc: 0.3394\n",
      "Epoch 12/2000\n",
      "2/2 [==============================] - 198s 65s/step - loss: 0.4846 - binary_accuracy: 0.7687 - precision: 0.2143 - recall: 0.0526 - auc: 0.3036 - val_loss: 0.4461 - val_binary_accuracy: 0.8636 - val_precision: 1.0000 - val_recall: 0.1429 - val_auc: 0.3393\n",
      "Epoch 4/2000\n",
      "1/1 [==============================] - 52s 52s/step - loss: 0.1704 - binary_accuracy: 0.9577 - precision: 1.0000 - recall: 0.4000 - auc: 0.5472 - val_loss: 0.7122 - val_binary_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.2500 - val_auc: 0.3428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 136s 41s/step - loss: 0.4820 - binary_accuracy: 0.7900 - precision: 0.4375 - recall: 0.1228 - auc: 0.3748 - val_loss: 0.4549 - val_binary_accuracy: 0.8409 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.2755\n",
      "Epoch 5/2000\n",
      "2/2 [==============================] - 241s 133s/step - loss: 0.6519 - binary_accuracy: 0.6150 - precision: 0.4590 - recall: 0.1944 - auc: 0.4575 - val_loss: 0.6617 - val_binary_accuracy: 0.5873 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4894\n",
      "Epoch 4/2000\n",
      "2/2 [==============================] - 154s 50s/step - loss: 0.4986 - binary_accuracy: 0.7936 - precision: 0.4615 - recall: 0.1053 - auc: 0.3452 - val_loss: 0.4405 - val_binary_accuracy: 0.8409 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.2761\n",
      "Epoch 6/2000\n",
      "2/2 [==============================] - 172s 105s/step - loss: 0.6539 - binary_accuracy: 0.6434 - precision: 0.5833 - recall: 0.1458 - auc: 0.4869 - val_loss: 0.6566 - val_binary_accuracy: 0.6032 - val_precision: 0.6667 - val_recall: 0.0392 - val_auc: 0.5418\n",
      "Epoch 5/2000\n",
      "2/2 [==============================] - 128s 32s/step - loss: 0.4981 - binary_accuracy: 0.8007 - precision: 0.5455 - recall: 0.1053 - auc: 0.3621 - val_loss: 0.4520 - val_binary_accuracy: 0.8636 - val_precision: 0.7500 - val_recall: 0.2143 - val_auc: 0.4035\n",
      "Epoch 7/2000\n",
      "2/2 [==============================] - 158s 73s/step - loss: 0.6664 - binary_accuracy: 0.6253 - precision: 0.4918 - recall: 0.2083 - auc: 0.4629 - val_loss: 0.6386 - val_binary_accuracy: 0.6032 - val_precision: 0.6667 - val_recall: 0.0392 - val_auc: 0.5753\n",
      "Epoch 6/2000\n",
      "2/2 [==============================] - 131s 58s/step - loss: 0.4532 - binary_accuracy: 0.7936 - precision: 0.4762 - recall: 0.1754 - auc: 0.4071 - val_loss: 0.4478 - val_binary_accuracy: 0.8750 - val_precision: 0.8000 - val_recall: 0.2857 - val_auc: 0.4353\n",
      "Epoch 8/2000\n",
      "2/2 [==============================] - 120s 34s/step - loss: 0.4309 - binary_accuracy: 0.8114 - precision: 0.6429 - recall: 0.1579 - auc: 0.4573 - val_loss: 0.4546 - val_binary_accuracy: 0.8409 - val_precision: 0.5000 - val_recall: 0.2143 - val_auc: 0.3948\n",
      "Epoch 9/2000\n",
      "2/2 [==============================] - 204s 117s/step - loss: 0.6129 - binary_accuracy: 0.6641 - precision: 0.6129 - recall: 0.2639 - auc: 0.5409 - val_loss: 0.6542 - val_binary_accuracy: 0.6111 - val_precision: 0.6250 - val_recall: 0.0980 - val_auc: 0.5516\n",
      "Epoch 7/2000\n",
      "2/2 [==============================] - 134s 36s/step - loss: 0.4468 - binary_accuracy: 0.7972 - precision: 0.5000 - recall: 0.2105 - auc: 0.4502 - val_loss: 0.4646 - val_binary_accuracy: 0.8409 - val_precision: 0.5000 - val_recall: 0.2857 - val_auc: 0.3987\n",
      "Epoch 10/2000\n",
      "2/2 [==============================] - 131s 69s/step - loss: 0.6406 - binary_accuracy: 0.6227 - precision: 0.4762 - recall: 0.1389 - auc: 0.4921 - val_loss: 0.6567 - val_binary_accuracy: 0.5952 - val_precision: 0.5000 - val_recall: 0.1176 - val_auc: 0.5463\n",
      "Epoch 8/2000\n",
      "2/2 [==============================] - 92s 25s/step - loss: 0.4639 - binary_accuracy: 0.7900 - precision: 0.4375 - recall: 0.1228 - auc: 0.4090 - val_loss: 0.4247 - val_binary_accuracy: 0.8750 - val_precision: 0.8000 - val_recall: 0.2857 - val_auc: 0.4479\n",
      "Epoch 11/2000\n",
      "2/2 [==============================] - 124s 56s/step - loss: 0.6312 - binary_accuracy: 0.6382 - precision: 0.5370 - recall: 0.2014 - auc: 0.5107 - val_loss: 0.6245 - val_binary_accuracy: 0.6349 - val_precision: 0.5806 - val_recall: 0.3529 - val_auc: 0.5484\n",
      "Epoch 9/2000\n",
      "2/2 [==============================] - 99s 43s/step - loss: 0.4169 - binary_accuracy: 0.8007 - precision: 0.5385 - recall: 0.1228 - auc: 0.4907 - val_loss: 0.4182 - val_binary_accuracy: 0.8750 - val_precision: 0.8000 - val_recall: 0.2857 - val_auc: 0.4769\n",
      "Epoch 12/2000\n",
      "2/2 [==============================] - 87s 26s/step - loss: 0.4206 - binary_accuracy: 0.8327 - precision: 0.7500 - recall: 0.2632 - auc: 0.5477 - val_loss: 0.4252 - val_binary_accuracy: 0.8750 - val_precision: 0.8000 - val_recall: 0.2857 - val_auc: 0.4668\n",
      "Epoch 13/2000\n",
      "2/2 [==============================] - 156s 91s/step - loss: 0.6444 - binary_accuracy: 0.6202 - precision: 0.4857 - recall: 0.3542 - auc: 0.4816 - val_loss: 0.6355 - val_binary_accuracy: 0.6349 - val_precision: 0.5510 - val_recall: 0.5294 - val_auc: 0.5395\n",
      "Epoch 10/2000\n",
      "2/2 [==============================] - 153s 53s/step - loss: 0.3911 - binary_accuracy: 0.8327 - precision: 0.7273 - recall: 0.2807 - auc: 0.5579 - val_loss: 0.4422 - val_binary_accuracy: 0.8636 - val_precision: 0.7500 - val_recall: 0.2143 - val_auc: 0.4062\n",
      "2/2 [==============================] - 151s 66s/step - loss: 0.6090 - binary_accuracy: 0.6693 - precision: 0.5635 - recall: 0.4931 - auc: 0.5487 - val_loss: 0.6172 - val_binary_accuracy: 0.6429 - val_precision: 0.5938 - val_recall: 0.3725 - val_auc: 0.5633\n",
      "Epoch 11/2000\n",
      "Epoch 14/2000\n",
      "2/2 [==============================] - 168s 54s/step - loss: 0.4007 - binary_accuracy: 0.7900 - precision: 0.4667 - recall: 0.2456 - auc: 0.4864 - val_loss: 0.4691 - val_binary_accuracy: 0.8636 - val_precision: 1.0000 - val_recall: 0.1429 - val_auc: 0.3220\n",
      "Epoch 15/2000\n",
      "2/2 [==============================] - 222s 109s/step - loss: 0.6032 - binary_accuracy: 0.6744 - precision: 0.6324 - recall: 0.2986 - auc: 0.5982 - val_loss: 0.6102 - val_binary_accuracy: 0.6349 - val_precision: 0.6316 - val_recall: 0.2353 - val_auc: 0.5894\n",
      "Epoch 12/2000\n",
      "2/2 [==============================] - 130s 36s/step - loss: 0.3864 - binary_accuracy: 0.8149 - precision: 0.6000 - recall: 0.2632 - auc: 0.5306 - val_loss: 0.4530 - val_binary_accuracy: 0.8523 - val_precision: 0.6667 - val_recall: 0.1429 - val_auc: 0.3364\n",
      "Epoch 16/2000\n",
      "2/2 [==============================] - 182s 91s/step - loss: 0.6250 - binary_accuracy: 0.6744 - precision: 0.6364 - recall: 0.2917 - auc: 0.5558 - val_loss: 0.6197 - val_binary_accuracy: 0.6667 - val_precision: 0.6552 - val_recall: 0.3725 - val_auc: 0.5713\n",
      "Epoch 13/2000\n",
      "2/2 [==============================] - 148s 60s/step - loss: 0.3803 - binary_accuracy: 0.8078 - precision: 0.5882 - recall: 0.1754 - auc: 0.5571 - val_loss: 0.4325 - val_binary_accuracy: 0.8636 - val_precision: 0.7500 - val_recall: 0.2143 - val_auc: 0.4811\n",
      "Epoch 17/2000\n",
      "2/2 [==============================] - 131s 43s/step - loss: 0.3724 - binary_accuracy: 0.8114 - precision: 0.6000 - recall: 0.2105 - auc: 0.5682 - val_loss: 0.4515 - val_binary_accuracy: 0.8636 - val_precision: 0.6667 - val_recall: 0.2857 - val_auc: 0.4720\n",
      "Epoch 18/2000\n",
      "2/2 [==============================] - 215s 126s/step - loss: 0.5928 - binary_accuracy: 0.6848 - precision: 0.6341 - recall: 0.3611 - auc: 0.5834 - val_loss: 0.6224 - val_binary_accuracy: 0.6587 - val_precision: 0.6429 - val_recall: 0.3529 - val_auc: 0.5707\n",
      "Epoch 14/2000\n",
      "2/2 [==============================] - 165s 54s/step - loss: 0.3594 - binary_accuracy: 0.8149 - precision: 0.5758 - recall: 0.3333 - auc: 0.5999 - val_loss: 0.4618 - val_binary_accuracy: 0.8523 - val_precision: 0.6667 - val_recall: 0.1429 - val_auc: 0.4275\n",
      "Epoch 19/2000\n",
      "2/2 [==============================] - 182s 101s/step - loss: 0.5966 - binary_accuracy: 0.6848 - precision: 0.6341 - recall: 0.3611 - auc: 0.5805 - val_loss: 0.6169 - val_binary_accuracy: 0.6746 - val_precision: 0.7778 - val_recall: 0.2745 - val_auc: 0.5983\n",
      "Epoch 15/2000\n",
      "2/2 [==============================] - 127s 37s/step - loss: 0.3406 - binary_accuracy: 0.8292 - precision: 0.6552 - recall: 0.3333 - auc: 0.6333 - val_loss: 0.4680 - val_binary_accuracy: 0.8523 - val_precision: 0.6667 - val_recall: 0.1429 - val_auc: 0.4175\n",
      "1/2 [==============>...............] - ETA: 1:14 - loss: 0.6332 - binary_accuracy: 0.6200 - precision: 0.6286 - recall: 0.2588 - auc: 0.6262Epoch 20/2000\n",
      "2/2 [==============================] - 168s 94s/step - loss: 0.6206 - binary_accuracy: 0.6486 - precision: 0.5645 - recall: 0.2431 - auc: 0.5437 - val_loss: 0.6428 - val_binary_accuracy: 0.6746 - val_precision: 0.7083 - val_recall: 0.3333 - val_auc: 0.5763\n",
      "Epoch 16/2000\n",
      "2/2 [==============================] - 142s 52s/step - loss: 0.3648 - binary_accuracy: 0.8292 - precision: 0.7143 - recall: 0.2632 - auc: 0.6332 - val_loss: 0.4644 - val_binary_accuracy: 0.8750 - val_precision: 0.8000 - val_recall: 0.2857 - val_auc: 0.4428\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/2000\n",
      "2/2 [==============================] - 143s 50s/step - loss: 0.3417 - binary_accuracy: 0.8363 - precision: 0.6897 - recall: 0.3509 - auc: 0.6470 - val_loss: 0.4842 - val_binary_accuracy: 0.8750 - val_precision: 0.7143 - val_recall: 0.3571 - val_auc: 0.4266\n",
      "2/2 [==============================] - 202s 98s/step - loss: 0.6249 - binary_accuracy: 0.6486 - precision: 0.5571 - recall: 0.2708 - auc: 0.5270 - val_loss: 0.6340 - val_binary_accuracy: 0.6825 - val_precision: 0.7037 - val_recall: 0.3725 - val_auc: 0.5855\n",
      "Epoch 17/2000\n",
      "2/2 [==============================] - 93s 50s/step - loss: 0.6108 - binary_accuracy: 0.6977 - precision: 0.7077 - recall: 0.3194 - auc: 0.5967 - val_loss: 0.6270 - val_binary_accuracy: 0.6746 - val_precision: 0.7083 - val_recall: 0.3333 - val_auc: 0.5794\n",
      "Epoch 18/2000\n",
      "2/2 [==============================] - 93s 53s/step - loss: 0.5985 - binary_accuracy: 0.7028 - precision: 0.7164 - recall: 0.3333 - auc: 0.6186 - val_loss: 0.6345 - val_binary_accuracy: 0.6429 - val_precision: 0.5882 - val_recall: 0.3922 - val_auc: 0.5776\n",
      "Epoch 19/2000\n",
      "2/2 [==============================] - 100s 56s/step - loss: 0.5640 - binary_accuracy: 0.7080 - precision: 0.6824 - recall: 0.4028 - auc: 0.6535 - val_loss: 0.6295 - val_binary_accuracy: 0.6587 - val_precision: 0.6429 - val_recall: 0.3529 - val_auc: 0.5868\n",
      "Epoch 20/2000\n",
      "2/2 [==============================] - 128s 75s/step - loss: 0.5689 - binary_accuracy: 0.7028 - precision: 0.6933 - recall: 0.3611 - auc: 0.6476 - val_loss: 0.6187 - val_binary_accuracy: 0.6349 - val_precision: 0.6471 - val_recall: 0.2157 - val_auc: 0.5772\n",
      "Epoch 21/2000\n",
      "2/2 [==============================] - 97s 53s/step - loss: 0.5851 - binary_accuracy: 0.6899 - precision: 0.7400 - recall: 0.2569 - auc: 0.6126 - val_loss: 0.6210 - val_binary_accuracy: 0.6349 - val_precision: 0.6316 - val_recall: 0.2353 - val_auc: 0.5822\n",
      "Modeling for cluster 4 finished\n",
      "Modeling for cluster 5 finished\n",
      "Modeling for cluster 1 finished\n"
     ]
    }
   ],
   "source": [
    "ccm.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside predict 1\n",
      "prediction and actuals 126 126\n",
      "inside predict 1\n",
      "prediction and actuals 88 88\n",
      "inside predict 1\n",
      "prediction and actuals 32 32\n",
      "246\n",
      "246\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.6666666666666666,\n",
       " 'recall': 0.6521739130434783,\n",
       " 'precision': 0.4368932038834951,\n",
       " 'f1_score': 0.5232558139534883,\n",
       " 'pr_auc': 0.534653237728536,\n",
       " 'auc': 0.7460902317202981}"
      ]
     },
     "execution_count": 712,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccm.metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside predict 1\n",
      "prediction and actuals 126 126\n",
      "inside predict 1\n",
      "prediction and actuals 88 88\n",
      "inside predict 1\n",
      "prediction and actuals 32 32\n",
      "246\n",
      "246\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.6504065040650406,\n",
       " 'recall': 0.782608695652174,\n",
       " 'precision': 0.432,\n",
       " 'f1_score': 0.5567010309278351,\n",
       " 'pr_auc': 0.534653237728536,\n",
       " 'auc': 0.7460902317202981}"
      ]
     },
     "execution_count": 722,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccm2.metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding adding cluster type to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [],
   "source": [
    "input0 =  ccm.models[0].model.get_layer(name='input0').input\n",
    "input1 =  ccm.models[0].model.get_layer(name='input1').input\n",
    "input2 =  ccm.models[0].model.get_layer(name='input2').input\n",
    "input3 =  ccm.models[0].model.get_layer(name='input3').input\n",
    "input4 =  ccm.models[1].model.get_layer(name='input0').input\n",
    "input5 =  ccm.models[1].model.get_layer(name='input1').input\n",
    "input6 =  ccm.models[1].model.get_layer(name='input2').input\n",
    "input7 =  ccm.models[1].model.get_layer(name='input3').input\n",
    "input8 =  ccm.models[2].model.get_layer(name='input0').input\n",
    "input9 =  ccm.models[2].model.get_layer(name='input1').input\n",
    "input10 =  ccm.models[2].model.get_layer(name='input2').input\n",
    "input11 =  ccm.models[2].model.get_layer(name='input3').input\n",
    "cluster1 = ccm.models[0].model.get_layer(name='hidden_layer3').output\n",
    "cluster2 = ccm.models[1].model.get_layer(name='hidden_layer3').output\n",
    "cluster3 = ccm.models[2].model.get_layer(name='hidden_layer3').output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.Dense at 0x7fe28cf797c0>"
      ]
     },
     "execution_count": 639,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[input0, input1, input2, input3, input4, input5, input6, input7, input8, input9, input10, input11, cluster_type_input]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 7200, 6) dtype=float32 (created by layer 'input0')>"
      ]
     },
     "execution_count": 655,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.merge.Concatenate at 0x7fe250444520>"
      ]
     },
     "execution_count": 646,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The name \"input0\" is used 3 times in the model. All layer names should be unique.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-706-995d9898fd69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mlayer3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m'hidden_layer3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster_type_input\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, name, trainable, **kwargs)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0mgeneric_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFunctional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_automatic_dependency_tracking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[0;34m(self, inputs, outputs)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;31m# Keep track of the network's nodes and layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m     nodes, nodes_by_depth, layers, _ = _map_graph_network(\n\u001b[0m\u001b[1;32m    193\u001b[0m         self.inputs, self.outputs)\n\u001b[1;32m    194\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_network_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m_map_graph_network\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m    992\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mall_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m       raise ValueError('The name \"' + name + '\" is used ' +\n\u001b[0m\u001b[1;32m    995\u001b[0m                        \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' times in the model. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m                        'All layer names should be unique.')\n",
      "\u001b[0;31mValueError\u001b[0m: The name \"input0\" is used 3 times in the model. All layer names should be unique."
     ]
    }
   ],
   "source": [
    "cluster_type_input = Input(shape=(1, ))\n",
    "clusters_concat = tf.keras.layers.Concatenate()([cluster1, cluster2, cluster3])\n",
    "final_concat = tf.keras.layers.Concatenate()([clusters_concat, cluster_type_input])\n",
    "layer1 = Dense(50, activation='relu', name ='hidden_layer1')(final_concat)\n",
    "layer2 = Dense(25, activation='relu', name ='hidden_layer2')(layer1)\n",
    "layer3 = Dense(5, activation='relu', name ='hidden_layer3')(layer2)\n",
    "out = Dense(1, activation='sigmoid')(layer3)\n",
    "Model(inputs=[input0, input1, input2, input3, input4, input5, input6, input7, input8, input9, input10, input11, cluster_type_input], outputs=out )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside predict 1\n",
      "prediction and actuals 126 126\n",
      "inside predict 1\n",
      "prediction and actuals 88 88\n",
      "inside predict 1\n",
      "prediction and actuals 32 32\n",
      "246\n",
      "246\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.6056910569105691,\n",
       " 'recall': 0.7681159420289855,\n",
       " 'precision': 0.39552238805970147,\n",
       " 'f1_score': 0.5221674876847291,\n",
       " 'pr_auc': 0.4387294881266916,\n",
       " 'auc': 0.7037582903463523}"
      ]
     },
     "execution_count": 607,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 25) dtype=float32 (created by layer 'hidden_layer3')>"
      ]
     },
     "execution_count": 614,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 25) dtype=float32 (created by layer 'hidden_layer3')>"
      ]
     },
     "execution_count": 616,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputA = Input(shape=(25,))\n",
    "inputB = Input(shape=(25,))\n",
    "inputC = Input(shape=(25,))\n",
    "inputD = Input(shape=(1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 25) dtype=float32 (created by layer 'input_9')>"
      ]
     },
     "execution_count": 618,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 25) dtype=float32 (created by layer 'input_10')>"
      ]
     },
     "execution_count": 619,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 25) dtype=float32 (created by layer 'input_11')>"
      ]
     },
     "execution_count": 620,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputC"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
