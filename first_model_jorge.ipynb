{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from multiprocessing import cpu_count\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torchmetrics.functional import accuracy\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "from keras.layers import Conv1D, Dense, Dropout, Input, Concatenate, GlobalMaxPooling1D, MaxPooling1D\n",
    "from keras.models import Model\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "# from keras.optimizers import RMSprop, adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "day1_dataset_1min = pd.read_csv('Data Slices/day1_dataset_1min_10Aug2022.csv')\n",
    "day1_dataset_10min = pd.read_csv('Data Slices/day1_dataset_10min_10Aug2022.csv')\n",
    "day1_dataset_30min = pd.read_csv('Data Slices/day1_dataset_30min_10Aug2022.csv')\n",
    "day1_dataset_60min = pd.read_csv('Data Slices/day1_dataset_60min_10Aug2022.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_and_y(df, x_columns, y_columns):\n",
    "    X = df[x_columns]\n",
    "    y = df[y_columns]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_daily_sequences(X, y, feature_columns, sequence_dict = {}):\n",
    "    for collection, group in X.groupby(\"collection\"):\n",
    "        features = group[group.columns.intersection(feature_columns)]\n",
    "        blacklist = y[y.collection == collection].iloc[0].blacklisted\n",
    "        if sequence_dict.get(collection):\n",
    "            sequence_dict[collection][0].append(features)\n",
    "        else:\n",
    "            sequence_dict[collection] = ([features], blacklist)\n",
    "    return sequence_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_daily_sequences(X, y, feature_columns, sequence_dict = {}):\n",
    "    for collection, group in X.groupby(\"collection\"):\n",
    "        features = group[group.columns.intersection(feature_columns)]\n",
    "        blacklist = y[y.collection == collection].iloc[0].blacklisted\n",
    "        if sequence_dict.get(collection):\n",
    "            sequence_dict[collection][0].append(features)\n",
    "        else:\n",
    "            sequence_dict[collection] = ([features], blacklist)\n",
    "    return sequence_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_dataset(sequences, columns = ['Price_USD', 'Price_Crypto', 'volume', 'densities', 'vertex_count', \n",
    "                              'edge_count','vertext_edge_ratio'], fitted_scaler = None):\n",
    "    collection_blacklist_dict = {sequence[0]:sequence[2] for sequence in sequences}\n",
    "    concat_df = pd.concat([sequence[1] for sequence in sequences])\n",
    "    if fitted_scaler is None:\n",
    "        fitted_scaler = StandardScaler()\n",
    "        fitted_scaler.fit(concat_df[columns])\n",
    "    concat_df[columns] = fitted_scaler.transform(concat_df[columns])\n",
    "    return  [(collection, group[columns], collection_blacklist_dict[collection]) \n",
    "             for collection, group in concat_df.groupby(\"collection\")] , fitted_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_sequences(all_df):\n",
    "    sequence_dict = {}\n",
    "    for df in all_df: \n",
    "        df = df.drop(['Unnamed: 0'], axis=1)\n",
    "        x_columns =  ['Datetime_updated_seconds','Price_USD','Price_Crypto','volume','densities',\n",
    "                   'vertex_count','edge_count','collection']\n",
    "        y_columns = ['blacklisted','collection']\n",
    "        feature_columns=['Price_USD','Price_Crypto','volume',\n",
    "                         'densities', 'vertex_count','edge_count', 'collection', 'vertext_edge_ratio']\n",
    "        X, y= get_X_and_y(df, x_columns, y_columns)\n",
    "        X['vertext_edge_ratio'] = X['vertex_count']/X['edge_count']\n",
    "        sequence_dict = get_daily_sequences(X, y, feature_columns, sequence_dict)\n",
    "    return sequence_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_all_train_test_sequences(all_df):\n",
    "    train_test_sequences = []\n",
    "    all_sequence_dict = get_all_sequences(all_df)\n",
    "        \n",
    "    train_sequences, test_sequences = train_test_split(list(all_sequence_dict.items()), \n",
    "                                                       test_size = 0.3,  random_state=1234)\n",
    "    return train_sequences, test_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-f9d6ae458486>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X['vertext_edge_ratio'] = X['vertex_count']/X['edge_count']\n"
     ]
    }
   ],
   "source": [
    "train_sequences, test_sequences = retrieve_all_train_test_sequences([day1_dataset_1min, day1_dataset_10min,\n",
    "                                                                     day1_dataset_30min,\n",
    "                                                                     day1_dataset_60min])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_train_test_sequences(train_sequences, test_sequences):\n",
    "    scaled_train_dataset_dict = {}\n",
    "    scaled_test_dataset_dict = {}\n",
    "    scaled_train_dataset= []\n",
    "    scaled_test_dataset= []\n",
    "    length = len(train_sequences[0][1][0])\n",
    "    for n in range(length):\n",
    "        train_scaled, scaler = scale_dataset([(sequence[0], sequence[1][0][n], sequence[1][1]) for sequence in\n",
    "                                              train_sequences])\n",
    "        test_scaled, _ = scale_dataset([(sequence[0], sequence[1][0][n], sequence[1][1]) for sequence in\n",
    "                                        test_sequences],\n",
    "                      fitted_scaler= scaler)\n",
    "        scaled_train_dataset.append(train_scaled)\n",
    "        scaled_test_dataset.append(test_scaled)\n",
    "\n",
    "    for scale_sequence in scaled_train_dataset:\n",
    "        for collection in scale_sequence:\n",
    "            if scaled_train_dataset_dict.get(collection[0]):\n",
    "                scaled_train_dataset_dict[collection[0]][0].append(collection[1])\n",
    "            else:\n",
    "                scaled_train_dataset_dict[collection[0]] = ([collection[1]], collection[2])\n",
    "\n",
    "    for scale_sequence in scaled_test_dataset:\n",
    "        for collection in scale_sequence:\n",
    "            if scaled_test_dataset_dict.get(collection[0]):\n",
    "                scaled_test_dataset_dict[collection[0]][0].append(collection[1])\n",
    "            else:\n",
    "                scaled_test_dataset_dict[collection[0]] = ([collection[1]], collection[2])\n",
    "                \n",
    "    return list(scaled_train_dataset_dict.values()), list(scaled_test_dataset_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values, test_values = scale_train_test_sequences(train_sequences,test_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price_USD</th>\n",
       "      <th>Price_Crypto</th>\n",
       "      <th>volume</th>\n",
       "      <th>densities</th>\n",
       "      <th>vertex_count</th>\n",
       "      <th>edge_count</th>\n",
       "      <th>vertext_edge_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>-0.235013</td>\n",
       "      <td>-0.257839</td>\n",
       "      <td>-0.022563</td>\n",
       "      <td>1.063602</td>\n",
       "      <td>-0.172599</td>\n",
       "      <td>-0.113212</td>\n",
       "      <td>0.981047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>-0.235013</td>\n",
       "      <td>-0.257839</td>\n",
       "      <td>-0.073434</td>\n",
       "      <td>1.063602</td>\n",
       "      <td>-0.172599</td>\n",
       "      <td>-0.113212</td>\n",
       "      <td>0.981047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>-0.235013</td>\n",
       "      <td>-0.257839</td>\n",
       "      <td>-0.073434</td>\n",
       "      <td>1.063602</td>\n",
       "      <td>-0.172599</td>\n",
       "      <td>-0.113212</td>\n",
       "      <td>0.981047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>-0.235013</td>\n",
       "      <td>-0.257839</td>\n",
       "      <td>-0.073434</td>\n",
       "      <td>1.063602</td>\n",
       "      <td>-0.172599</td>\n",
       "      <td>-0.113212</td>\n",
       "      <td>0.981047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>-0.235013</td>\n",
       "      <td>-0.257839</td>\n",
       "      <td>-0.073434</td>\n",
       "      <td>1.063602</td>\n",
       "      <td>-0.172599</td>\n",
       "      <td>-0.113212</td>\n",
       "      <td>0.981047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>-0.235013</td>\n",
       "      <td>-0.257839</td>\n",
       "      <td>-0.073434</td>\n",
       "      <td>1.063602</td>\n",
       "      <td>-0.172599</td>\n",
       "      <td>-0.113212</td>\n",
       "      <td>0.981047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>-0.235013</td>\n",
       "      <td>-0.257839</td>\n",
       "      <td>-0.073434</td>\n",
       "      <td>1.063602</td>\n",
       "      <td>-0.172599</td>\n",
       "      <td>-0.113212</td>\n",
       "      <td>0.981047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>-0.235013</td>\n",
       "      <td>-0.257839</td>\n",
       "      <td>-0.073434</td>\n",
       "      <td>1.063602</td>\n",
       "      <td>-0.172599</td>\n",
       "      <td>-0.113212</td>\n",
       "      <td>0.981047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>-0.235013</td>\n",
       "      <td>-0.257839</td>\n",
       "      <td>-0.073434</td>\n",
       "      <td>1.063602</td>\n",
       "      <td>-0.172599</td>\n",
       "      <td>-0.113212</td>\n",
       "      <td>0.981047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>-0.235013</td>\n",
       "      <td>-0.257839</td>\n",
       "      <td>-0.073434</td>\n",
       "      <td>1.063602</td>\n",
       "      <td>-0.172599</td>\n",
       "      <td>-0.113212</td>\n",
       "      <td>0.981047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>-0.235013</td>\n",
       "      <td>-0.257839</td>\n",
       "      <td>-0.073434</td>\n",
       "      <td>1.063602</td>\n",
       "      <td>-0.172599</td>\n",
       "      <td>-0.113212</td>\n",
       "      <td>0.981047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>-0.235013</td>\n",
       "      <td>-0.257839</td>\n",
       "      <td>-0.073434</td>\n",
       "      <td>1.063602</td>\n",
       "      <td>-0.172599</td>\n",
       "      <td>-0.113212</td>\n",
       "      <td>0.981047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>-0.235013</td>\n",
       "      <td>-0.257839</td>\n",
       "      <td>-0.073434</td>\n",
       "      <td>1.063602</td>\n",
       "      <td>-0.172599</td>\n",
       "      <td>-0.113212</td>\n",
       "      <td>0.981047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>-0.235013</td>\n",
       "      <td>-0.257839</td>\n",
       "      <td>-0.073434</td>\n",
       "      <td>1.063602</td>\n",
       "      <td>-0.172599</td>\n",
       "      <td>-0.113212</td>\n",
       "      <td>0.981047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>-0.235013</td>\n",
       "      <td>-0.257839</td>\n",
       "      <td>-0.073434</td>\n",
       "      <td>1.063602</td>\n",
       "      <td>-0.172599</td>\n",
       "      <td>-0.113212</td>\n",
       "      <td>0.981047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>-0.235013</td>\n",
       "      <td>-0.257839</td>\n",
       "      <td>-0.073434</td>\n",
       "      <td>1.063602</td>\n",
       "      <td>-0.172599</td>\n",
       "      <td>-0.113212</td>\n",
       "      <td>0.981047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>-0.235013</td>\n",
       "      <td>-0.257839</td>\n",
       "      <td>-0.073434</td>\n",
       "      <td>1.063602</td>\n",
       "      <td>-0.172599</td>\n",
       "      <td>-0.113212</td>\n",
       "      <td>0.981047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>-0.235013</td>\n",
       "      <td>-0.257839</td>\n",
       "      <td>-0.073434</td>\n",
       "      <td>1.063602</td>\n",
       "      <td>-0.172599</td>\n",
       "      <td>-0.113212</td>\n",
       "      <td>0.981047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>-0.235013</td>\n",
       "      <td>-0.257839</td>\n",
       "      <td>-0.073434</td>\n",
       "      <td>1.063602</td>\n",
       "      <td>-0.172599</td>\n",
       "      <td>-0.113212</td>\n",
       "      <td>0.981047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>-0.235013</td>\n",
       "      <td>-0.257839</td>\n",
       "      <td>-0.073434</td>\n",
       "      <td>1.063602</td>\n",
       "      <td>-0.172599</td>\n",
       "      <td>-0.113212</td>\n",
       "      <td>0.981047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>-0.235013</td>\n",
       "      <td>-0.257839</td>\n",
       "      <td>-0.073434</td>\n",
       "      <td>1.063602</td>\n",
       "      <td>-0.172599</td>\n",
       "      <td>-0.113212</td>\n",
       "      <td>0.981047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>-0.235013</td>\n",
       "      <td>-0.257839</td>\n",
       "      <td>-0.073434</td>\n",
       "      <td>1.063602</td>\n",
       "      <td>-0.172599</td>\n",
       "      <td>-0.113212</td>\n",
       "      <td>0.981047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>-0.235013</td>\n",
       "      <td>-0.257839</td>\n",
       "      <td>-0.073434</td>\n",
       "      <td>1.063602</td>\n",
       "      <td>-0.172599</td>\n",
       "      <td>-0.113212</td>\n",
       "      <td>0.981047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>-0.235013</td>\n",
       "      <td>-0.257839</td>\n",
       "      <td>-0.073434</td>\n",
       "      <td>1.063602</td>\n",
       "      <td>-0.172599</td>\n",
       "      <td>-0.113212</td>\n",
       "      <td>0.981047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Price_USD  Price_Crypto    volume  densities  vertex_count  edge_count  \\\n",
       "192  -0.235013     -0.257839 -0.022563   1.063602     -0.172599   -0.113212   \n",
       "193  -0.235013     -0.257839 -0.073434   1.063602     -0.172599   -0.113212   \n",
       "194  -0.235013     -0.257839 -0.073434   1.063602     -0.172599   -0.113212   \n",
       "195  -0.235013     -0.257839 -0.073434   1.063602     -0.172599   -0.113212   \n",
       "196  -0.235013     -0.257839 -0.073434   1.063602     -0.172599   -0.113212   \n",
       "197  -0.235013     -0.257839 -0.073434   1.063602     -0.172599   -0.113212   \n",
       "198  -0.235013     -0.257839 -0.073434   1.063602     -0.172599   -0.113212   \n",
       "199  -0.235013     -0.257839 -0.073434   1.063602     -0.172599   -0.113212   \n",
       "200  -0.235013     -0.257839 -0.073434   1.063602     -0.172599   -0.113212   \n",
       "201  -0.235013     -0.257839 -0.073434   1.063602     -0.172599   -0.113212   \n",
       "202  -0.235013     -0.257839 -0.073434   1.063602     -0.172599   -0.113212   \n",
       "203  -0.235013     -0.257839 -0.073434   1.063602     -0.172599   -0.113212   \n",
       "204  -0.235013     -0.257839 -0.073434   1.063602     -0.172599   -0.113212   \n",
       "205  -0.235013     -0.257839 -0.073434   1.063602     -0.172599   -0.113212   \n",
       "206  -0.235013     -0.257839 -0.073434   1.063602     -0.172599   -0.113212   \n",
       "207  -0.235013     -0.257839 -0.073434   1.063602     -0.172599   -0.113212   \n",
       "208  -0.235013     -0.257839 -0.073434   1.063602     -0.172599   -0.113212   \n",
       "209  -0.235013     -0.257839 -0.073434   1.063602     -0.172599   -0.113212   \n",
       "210  -0.235013     -0.257839 -0.073434   1.063602     -0.172599   -0.113212   \n",
       "211  -0.235013     -0.257839 -0.073434   1.063602     -0.172599   -0.113212   \n",
       "212  -0.235013     -0.257839 -0.073434   1.063602     -0.172599   -0.113212   \n",
       "213  -0.235013     -0.257839 -0.073434   1.063602     -0.172599   -0.113212   \n",
       "214  -0.235013     -0.257839 -0.073434   1.063602     -0.172599   -0.113212   \n",
       "215  -0.235013     -0.257839 -0.073434   1.063602     -0.172599   -0.113212   \n",
       "\n",
       "     vertext_edge_ratio  \n",
       "192            0.981047  \n",
       "193            0.981047  \n",
       "194            0.981047  \n",
       "195            0.981047  \n",
       "196            0.981047  \n",
       "197            0.981047  \n",
       "198            0.981047  \n",
       "199            0.981047  \n",
       "200            0.981047  \n",
       "201            0.981047  \n",
       "202            0.981047  \n",
       "203            0.981047  \n",
       "204            0.981047  \n",
       "205            0.981047  \n",
       "206            0.981047  \n",
       "207            0.981047  \n",
       "208            0.981047  \n",
       "209            0.981047  \n",
       "210            0.981047  \n",
       "211            0.981047  \n",
       "212            0.981047  \n",
       "213            0.981047  \n",
       "214            0.981047  \n",
       "215            0.981047  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_values[1][0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price_USD</th>\n",
       "      <th>Price_Crypto</th>\n",
       "      <th>volume</th>\n",
       "      <th>densities</th>\n",
       "      <th>vertex_count</th>\n",
       "      <th>edge_count</th>\n",
       "      <th>vertext_edge_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.251220</td>\n",
       "      <td>-0.324651</td>\n",
       "      <td>0.028307</td>\n",
       "      <td>0.135365</td>\n",
       "      <td>-0.152558</td>\n",
       "      <td>-0.104624</td>\n",
       "      <td>-0.334826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.251220</td>\n",
       "      <td>-0.324651</td>\n",
       "      <td>-0.073434</td>\n",
       "      <td>0.135365</td>\n",
       "      <td>-0.152558</td>\n",
       "      <td>-0.104624</td>\n",
       "      <td>-0.334826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.251220</td>\n",
       "      <td>-0.324651</td>\n",
       "      <td>-0.073434</td>\n",
       "      <td>0.135365</td>\n",
       "      <td>-0.152558</td>\n",
       "      <td>-0.104624</td>\n",
       "      <td>-0.334826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.251220</td>\n",
       "      <td>-0.324651</td>\n",
       "      <td>-0.073434</td>\n",
       "      <td>0.135365</td>\n",
       "      <td>-0.152558</td>\n",
       "      <td>-0.104624</td>\n",
       "      <td>-0.334826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.251220</td>\n",
       "      <td>-0.324651</td>\n",
       "      <td>-0.073434</td>\n",
       "      <td>0.135365</td>\n",
       "      <td>-0.152558</td>\n",
       "      <td>-0.104624</td>\n",
       "      <td>-0.334826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.251220</td>\n",
       "      <td>-0.324651</td>\n",
       "      <td>-0.073434</td>\n",
       "      <td>0.135365</td>\n",
       "      <td>-0.152558</td>\n",
       "      <td>-0.104624</td>\n",
       "      <td>-0.334826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-0.251220</td>\n",
       "      <td>-0.324651</td>\n",
       "      <td>-0.073434</td>\n",
       "      <td>0.135365</td>\n",
       "      <td>-0.152558</td>\n",
       "      <td>-0.104624</td>\n",
       "      <td>-0.334826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-0.251220</td>\n",
       "      <td>-0.324651</td>\n",
       "      <td>-0.073434</td>\n",
       "      <td>0.135365</td>\n",
       "      <td>-0.152558</td>\n",
       "      <td>-0.104624</td>\n",
       "      <td>-0.334826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>-0.251220</td>\n",
       "      <td>-0.324651</td>\n",
       "      <td>-0.073434</td>\n",
       "      <td>0.135365</td>\n",
       "      <td>-0.152558</td>\n",
       "      <td>-0.104624</td>\n",
       "      <td>-0.334826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>-0.251220</td>\n",
       "      <td>-0.324651</td>\n",
       "      <td>-0.073434</td>\n",
       "      <td>0.135365</td>\n",
       "      <td>-0.152558</td>\n",
       "      <td>-0.104624</td>\n",
       "      <td>-0.334826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>-0.251220</td>\n",
       "      <td>-0.324651</td>\n",
       "      <td>-0.073434</td>\n",
       "      <td>0.135365</td>\n",
       "      <td>-0.152558</td>\n",
       "      <td>-0.104624</td>\n",
       "      <td>-0.334826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>-0.251220</td>\n",
       "      <td>-0.324651</td>\n",
       "      <td>-0.073434</td>\n",
       "      <td>0.135365</td>\n",
       "      <td>-0.152558</td>\n",
       "      <td>-0.104624</td>\n",
       "      <td>-0.334826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>-0.251220</td>\n",
       "      <td>-0.324651</td>\n",
       "      <td>-0.073434</td>\n",
       "      <td>0.135365</td>\n",
       "      <td>-0.152558</td>\n",
       "      <td>-0.104624</td>\n",
       "      <td>-0.334826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>-0.251220</td>\n",
       "      <td>-0.324651</td>\n",
       "      <td>-0.073434</td>\n",
       "      <td>0.135365</td>\n",
       "      <td>-0.152558</td>\n",
       "      <td>-0.104624</td>\n",
       "      <td>-0.334826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>-0.251220</td>\n",
       "      <td>-0.324651</td>\n",
       "      <td>-0.073434</td>\n",
       "      <td>0.135365</td>\n",
       "      <td>-0.152558</td>\n",
       "      <td>-0.104624</td>\n",
       "      <td>-0.334826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>-0.251220</td>\n",
       "      <td>-0.324651</td>\n",
       "      <td>-0.073434</td>\n",
       "      <td>0.135365</td>\n",
       "      <td>-0.152558</td>\n",
       "      <td>-0.104624</td>\n",
       "      <td>-0.334826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>-0.251220</td>\n",
       "      <td>-0.324651</td>\n",
       "      <td>-0.073434</td>\n",
       "      <td>0.135365</td>\n",
       "      <td>-0.152558</td>\n",
       "      <td>-0.104624</td>\n",
       "      <td>-0.334826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>-0.248241</td>\n",
       "      <td>-0.322946</td>\n",
       "      <td>-0.022563</td>\n",
       "      <td>0.135365</td>\n",
       "      <td>-0.152558</td>\n",
       "      <td>-0.104624</td>\n",
       "      <td>-0.334826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>-0.248241</td>\n",
       "      <td>-0.322946</td>\n",
       "      <td>-0.073434</td>\n",
       "      <td>0.135365</td>\n",
       "      <td>-0.152558</td>\n",
       "      <td>-0.104624</td>\n",
       "      <td>-0.334826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>-0.248241</td>\n",
       "      <td>-0.322946</td>\n",
       "      <td>-0.073434</td>\n",
       "      <td>0.135365</td>\n",
       "      <td>-0.152558</td>\n",
       "      <td>-0.104624</td>\n",
       "      <td>-0.334826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>-0.248241</td>\n",
       "      <td>-0.322946</td>\n",
       "      <td>-0.073434</td>\n",
       "      <td>0.135365</td>\n",
       "      <td>-0.152558</td>\n",
       "      <td>-0.104624</td>\n",
       "      <td>-0.334826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>-0.248241</td>\n",
       "      <td>-0.322946</td>\n",
       "      <td>-0.073434</td>\n",
       "      <td>0.135365</td>\n",
       "      <td>-0.152558</td>\n",
       "      <td>-0.104624</td>\n",
       "      <td>-0.334826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>-0.248241</td>\n",
       "      <td>-0.322946</td>\n",
       "      <td>-0.073434</td>\n",
       "      <td>0.135365</td>\n",
       "      <td>-0.152558</td>\n",
       "      <td>-0.104624</td>\n",
       "      <td>-0.334826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>-0.248241</td>\n",
       "      <td>-0.322946</td>\n",
       "      <td>-0.073434</td>\n",
       "      <td>0.135365</td>\n",
       "      <td>-0.152558</td>\n",
       "      <td>-0.104624</td>\n",
       "      <td>-0.334826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Price_USD  Price_Crypto    volume  densities  vertex_count  edge_count  \\\n",
       "24  -0.251220     -0.324651  0.028307   0.135365     -0.152558   -0.104624   \n",
       "25  -0.251220     -0.324651 -0.073434   0.135365     -0.152558   -0.104624   \n",
       "26  -0.251220     -0.324651 -0.073434   0.135365     -0.152558   -0.104624   \n",
       "27  -0.251220     -0.324651 -0.073434   0.135365     -0.152558   -0.104624   \n",
       "28  -0.251220     -0.324651 -0.073434   0.135365     -0.152558   -0.104624   \n",
       "29  -0.251220     -0.324651 -0.073434   0.135365     -0.152558   -0.104624   \n",
       "30  -0.251220     -0.324651 -0.073434   0.135365     -0.152558   -0.104624   \n",
       "31  -0.251220     -0.324651 -0.073434   0.135365     -0.152558   -0.104624   \n",
       "32  -0.251220     -0.324651 -0.073434   0.135365     -0.152558   -0.104624   \n",
       "33  -0.251220     -0.324651 -0.073434   0.135365     -0.152558   -0.104624   \n",
       "34  -0.251220     -0.324651 -0.073434   0.135365     -0.152558   -0.104624   \n",
       "35  -0.251220     -0.324651 -0.073434   0.135365     -0.152558   -0.104624   \n",
       "36  -0.251220     -0.324651 -0.073434   0.135365     -0.152558   -0.104624   \n",
       "37  -0.251220     -0.324651 -0.073434   0.135365     -0.152558   -0.104624   \n",
       "38  -0.251220     -0.324651 -0.073434   0.135365     -0.152558   -0.104624   \n",
       "39  -0.251220     -0.324651 -0.073434   0.135365     -0.152558   -0.104624   \n",
       "40  -0.251220     -0.324651 -0.073434   0.135365     -0.152558   -0.104624   \n",
       "41  -0.248241     -0.322946 -0.022563   0.135365     -0.152558   -0.104624   \n",
       "42  -0.248241     -0.322946 -0.073434   0.135365     -0.152558   -0.104624   \n",
       "43  -0.248241     -0.322946 -0.073434   0.135365     -0.152558   -0.104624   \n",
       "44  -0.248241     -0.322946 -0.073434   0.135365     -0.152558   -0.104624   \n",
       "45  -0.248241     -0.322946 -0.073434   0.135365     -0.152558   -0.104624   \n",
       "46  -0.248241     -0.322946 -0.073434   0.135365     -0.152558   -0.104624   \n",
       "47  -0.248241     -0.322946 -0.073434   0.135365     -0.152558   -0.104624   \n",
       "\n",
       "    vertext_edge_ratio  \n",
       "24           -0.334826  \n",
       "25           -0.334826  \n",
       "26           -0.334826  \n",
       "27           -0.334826  \n",
       "28           -0.334826  \n",
       "29           -0.334826  \n",
       "30           -0.334826  \n",
       "31           -0.334826  \n",
       "32           -0.334826  \n",
       "33           -0.334826  \n",
       "34           -0.334826  \n",
       "35           -0.334826  \n",
       "36           -0.334826  \n",
       "37           -0.334826  \n",
       "38           -0.334826  \n",
       "39           -0.334826  \n",
       "40           -0.334826  \n",
       "41           -0.334826  \n",
       "42           -0.334826  \n",
       "43           -0.334826  \n",
       "44           -0.334826  \n",
       "45           -0.334826  \n",
       "46           -0.334826  \n",
       "47           -0.334826  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_values[1][0][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values = list(scaled_train_dataset_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_values = list(scaled_test_dataset_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_values[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for n in range(len(train_values[0][0])):\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_shapes = [train_values[0][0][n].shape for n in range(len(train_values[0][0]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = [20,20,10,10]\n",
    "k_sizes = [100,10,6,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_base_model(shape, k_size = K_SIZE1, num_filters = NUM_FILTERS1):\n",
    "    print(\"base model shape\", shape)\n",
    "    input_seq = Input(shape=shape)\n",
    "    nb_filters = num_filters\n",
    "    convolved = Conv1D(num_filters, k_size, padding=\"same\", activation=\"relu\")(input_seq)\n",
    "    processed = GlobalMaxPooling1D()(convolved)\n",
    "#     processed = MaxPooling1D(pool_size=2, strides=1, padding='same')(convolved)\n",
    "    compressed = Dense(50, activation=\"relu\")(processed)\n",
    "    compressed = Dropout(0.2)(compressed)\n",
    "    model = Model(inputs=input_seq, outputs=compressed)\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_model(shapes, filters, k_sizes):\n",
    "    inputs = [Input(shape=shape, name=f'input{n}')for n, shape in enumerate(shapes)]\n",
    "    sub_models = [ get_base_model(shape, k_size = k_sizes[n], num_filters=filters[n]) \n",
    "                  for n, shape in enumerate(shapes)]\n",
    "    print(sub_models[0].output)\n",
    "    embeddings = [ model(inputs[n]) for n, model in enumerate(sub_models)]\n",
    "    merged = Concatenate()(embeddings)\n",
    "    layer1 = Dense(50, activation='relu', name ='hidden_layer1')(merged)\n",
    "    layer2 = Dense(25, activation='relu', name ='hidden_layer2')(layer1)\n",
    "    layer3 = Dense(10, activation='relu', name ='hidden_layer3')(layer2)\n",
    "    out = Dense(1, activation='sigmoid')(layer3)\n",
    "    model = Model(inputs=inputs, outputs=out)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(train, validation, model_shapes, filters, k_sizes):\n",
    "    es = keras.callbacks.EarlyStopping(min_delta=0.00001, patience=10)\n",
    "    model = main_model(model_shapes, filters, k_sizes)\n",
    "    model.compile(loss='binary_crossentropy', # categorical_crossentropy\n",
    "                          optimizer='adam', #sgd, nadam, adam, rmsprop\n",
    "                          metrics=['binary_accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall(),\n",
    "                                   tf.keras.metrics.AUC(curve='PR')])\n",
    "    model.summary()\n",
    "    model_hist = model.fit(train,\n",
    "                               validation_data=validation,\n",
    "                               batch_size=50, epochs=2000, \n",
    "                           callbacks=[es]\n",
    "                          )\n",
    "    return model_hist, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_formatted_inputs(values):\n",
    "    x_train_arr = []\n",
    "    length = len(values)\n",
    "    for n in range(len(values[0][0])):\n",
    "        x_train = [sequence[0][n] for sequence in values]\n",
    "        shape = x_train[0].shape\n",
    "        x_train =  np.stack(x_train)\n",
    "        x_train = x_train.reshape(length, shape[0], shape[1])\n",
    "        x_train_arr.append(x_train)\n",
    "    return x_train_arr, [sequence[1] for sequence in values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_tensor_datasets(train, test):\n",
    "    formatted_train = ({f'input{n}': data for n, data in enumerate(train[0]) }, train[1])\n",
    "    formatted_test = ({f'input{n}': data for n, data in enumerate(test[0]) }, test[1])\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices(formatted_train).batch(100)\n",
    "    test_dataset = tf.data.Dataset.from_tensor_slices(formatted_test).batch(100)\n",
    "    return train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, validation = retrieve_tensor_datasets(get_formatted_inputs(train_values),\n",
    "                                               get_formatted_inputs(test_values) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base model shape (1440, 7)\n",
      "Model: \"model_84\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_77 (InputLayer)        [(None, 1440, 7)]         0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 1440, 20)          14020     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_56 (Glo (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 50)                1050      \n",
      "_________________________________________________________________\n",
      "dropout_76 (Dropout)         (None, 50)                0         \n",
      "=================================================================\n",
      "Total params: 15,070\n",
      "Trainable params: 15,070\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "base model shape (144, 7)\n",
      "Model: \"model_85\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_78 (InputLayer)        [(None, 144, 7)]          0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 144, 20)           1420      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_57 (Glo (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 50)                1050      \n",
      "_________________________________________________________________\n",
      "dropout_77 (Dropout)         (None, 50)                0         \n",
      "=================================================================\n",
      "Total params: 2,470\n",
      "Trainable params: 2,470\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "base model shape (48, 7)\n",
      "Model: \"model_86\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_79 (InputLayer)        [(None, 48, 7)]           0         \n",
      "_________________________________________________________________\n",
      "conv1d_78 (Conv1D)           (None, 48, 10)            430       \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_58 (Glo (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 50)                550       \n",
      "_________________________________________________________________\n",
      "dropout_78 (Dropout)         (None, 50)                0         \n",
      "=================================================================\n",
      "Total params: 980\n",
      "Trainable params: 980\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "base model shape (24, 7)\n",
      "Model: \"model_87\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_80 (InputLayer)        [(None, 24, 7)]           0         \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 24, 10)            290       \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_59 (Glo (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 50)                550       \n",
      "_________________________________________________________________\n",
      "dropout_79 (Dropout)         (None, 50)                0         \n",
      "=================================================================\n",
      "Total params: 840\n",
      "Trainable params: 840\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 50), dtype=tf.float32, name=None), name='dropout_76/Identity:0', description=\"created by layer 'dropout_76'\")\n",
      "Model: \"model_88\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input0 (InputLayer)             [(None, 1440, 7)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input1 (InputLayer)             [(None, 144, 7)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input2 (InputLayer)             [(None, 48, 7)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input3 (InputLayer)             [(None, 24, 7)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_84 (Functional)           (None, 50)           15070       input0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "model_85 (Functional)           (None, 50)           2470        input1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "model_86 (Functional)           (None, 50)           980         input2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "model_87 (Functional)           (None, 50)           840         input3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 200)          0           model_84[0][0]                   \n",
      "                                                                 model_85[0][0]                   \n",
      "                                                                 model_86[0][0]                   \n",
      "                                                                 model_87[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer1 (Dense)           (None, 50)           10050       concatenate_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer2 (Dense)           (None, 25)           1275        hidden_layer1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer3 (Dense)           (None, 10)           260         hidden_layer2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_89 (Dense)                (None, 1)            11          hidden_layer3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 30,956\n",
      "Trainable params: 30,956\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/2000\n",
      "7/7 [==============================] - 6s 415ms/step - loss: 0.7257 - binary_accuracy: 0.4569 - precision_7: 0.2917 - recall_7: 0.7074 - auc_7: 0.3097 - val_loss: 0.6584 - val_binary_accuracy: 0.7090 - val_precision_7: 0.0000e+00 - val_recall_7: 0.0000e+00 - val_auc_7: 0.3462\n",
      "Epoch 2/2000\n",
      "3/7 [===========>..................] - ETA: 1s - loss: 0.6709 - binary_accuracy: 0.6633 - precision_7: 0.2500 - recall_7: 0.0101 - auc_7: 0.4174"
     ]
    }
   ],
   "source": [
    "model_hist, model = run_model(dataset, validation, model_shapes, filters, k_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(all_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction[prediction <=0.5] = 0\n",
    "prediction[prediction >0.5] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[pred[0] for pred in prediction.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_curves(history, title=None):\n",
    "    ''' Plot the training curves for loss and accuracy given a model history\n",
    "    '''\n",
    "    # find the minimum loss epoch\n",
    "    minimum = np.min(history.history['val_loss'])\n",
    "    min_loc = np.where(minimum == history.history['val_loss'])[0]\n",
    "    # get the vline y-min and y-max\n",
    "    loss_min, loss_max = (min(history.history['val_loss'] + history.history['loss']),\n",
    "                          max(history.history['val_loss'] + history.history['loss']))\n",
    "    acc_min, acc_max = (min(history.history['val_binary_accuracy'] + history.history['binary_accuracy']),\n",
    "                        max(history.history['val_binary_accuracy'] + history.history['binary_accuracy']))\n",
    "    # create figure\n",
    "    fig, ax = plt.subplots(ncols=2, figsize = (15,7))\n",
    "    fig.suptitle(title)\n",
    "    index = np.arange(1, len(history.history['binary_accuracy']) + 1)\n",
    "    # plot the loss and validation loss\n",
    "    ax[0].plot(index, history.history['loss'], label = 'loss')\n",
    "    ax[0].plot(index, history.history['val_loss'], label = 'val_loss')\n",
    "    ax[0].vlines(min_loc + 1, loss_min, loss_max, label = 'min_loss_location')\n",
    "    ax[0].set_title('Loss')\n",
    "    ax[0].set_ylabel('Loss')\n",
    "    ax[0].set_xlabel('Epochs')\n",
    "    ax[0].legend()\n",
    "    # plot the accuracy and validation accuracy\n",
    "    ax[1].plot(index, history.history['binary_accuracy'], label = 'accuracy')\n",
    "    ax[1].plot(index, history.history['val_binary_accuracy'], label = 'val_accuracy')\n",
    "    ax[1].vlines(min_loc + 1, acc_min, acc_max, label = 'min_loss_location')\n",
    "    ax[1].set_title('Accuracy')\n",
    "    ax[1].set_ylabel('Accuracy')\n",
    "    ax[1].set_xlabel('Epochs')\n",
    "    ax[1].legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_curves_auc(history, title=None):\n",
    "    ''' Plot the training curves for loss and accuracy given a model history\n",
    "    '''\n",
    "    # find the minimum loss epoch\n",
    "    minimum = np.min(history.history['val_loss'])\n",
    "    min_loc = np.where(minimum == history.history['val_loss'])[0]\n",
    "    # get the vline y-min and y-max\n",
    "    loss_min, loss_max = (min(history.history['val_loss'] + history.history['loss']),\n",
    "                          max(history.history['val_loss'] + history.history['loss']))\n",
    "    acc_min, acc_max = (min(history.history['val_auc_19'] + history.history['auc_19']),\n",
    "                        max(history.history['val_auc_19'] + history.history['auc_19']))\n",
    "    # create figure\n",
    "    fig, ax = plt.subplots(ncols=2, figsize = (15,7))\n",
    "    fig.suptitle(title)\n",
    "    index = np.arange(1, len(history.history['auc_19']) + 1)\n",
    "    # plot the loss and validation loss\n",
    "    ax[0].plot(index, history.history['loss'], label = 'loss')\n",
    "    ax[0].plot(index, history.history['val_loss'], label = 'val_loss')\n",
    "    ax[0].vlines(min_loc + 1, loss_min, loss_max, label = 'min_loss_location')\n",
    "    ax[0].set_title('Loss')\n",
    "    ax[0].set_ylabel('Loss')\n",
    "    ax[0].set_xlabel('Epochs')\n",
    "    ax[0].legend()\n",
    "    # plot the accuracy and validation accuracy\n",
    "    ax[1].plot(index, history.history['auc_19'], label = 'auc')\n",
    "    ax[1].plot(index, history.history['val_auc_19'], label = 'val_auc')\n",
    "    ax[1].vlines(min_loc + 1, acc_min, acc_max, label = 'min_loss_location')\n",
    "    ax[1].set_title('AUC')\n",
    "    ax[1].set_ylabel('auc')\n",
    "    ax[1].set_xlabel('Epochs')\n",
    "    ax[1].legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_curves(history=model_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_curves_auc(history=model_hist)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
