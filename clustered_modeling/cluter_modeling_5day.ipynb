{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "from numpy.random import normal\n",
    "\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from multiprocessing import cpu_count\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torchmetrics.functional import accuracy\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, recall_score, precision_score, f1_score, roc_auc_score, auc, average_precision_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "from keras.layers import Conv1D, Dense, Dropout, Input, Concatenate, GlobalMaxPooling1D, MaxPooling1D\n",
    "from keras.models import Model\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# from keras.optimizers import RMSprop, adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "day1_dataset_1min = pd.read_csv('../Data Slices/5_days_timeseries_data/1min.csv')\n",
    "day1_dataset_10min = pd.read_csv('../Data Slices/5_days_timeseries_data/10min.csv')\n",
    "day1_dataset_30min = pd.read_csv('../Data Slices/5_days_timeseries_data/30min.csv')\n",
    "day1_dataset_60min = pd.read_csv('../Data Slices/5_days_timeseries_data/60min.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Datetime_updated_seconds</th>\n",
       "      <th>Price_USD</th>\n",
       "      <th>Price_Crypto</th>\n",
       "      <th>density</th>\n",
       "      <th>vertex_count</th>\n",
       "      <th>edge_count</th>\n",
       "      <th>max_diameter</th>\n",
       "      <th>max_radius</th>\n",
       "      <th>max_peripher</th>\n",
       "      <th>volume</th>\n",
       "      <th>collection</th>\n",
       "      <th>blacklisted</th>\n",
       "      <th>whitelisted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>118080</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-10-11 22:00:00</td>\n",
       "      <td>0.720015</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>zombieartist</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118081</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-10-11 23:00:00</td>\n",
       "      <td>0.720015</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>zombieartist</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118082</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-10-12 00:00:00</td>\n",
       "      <td>0.720015</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>zombieartist</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118083</th>\n",
       "      <td>3</td>\n",
       "      <td>2020-10-12 01:00:00</td>\n",
       "      <td>0.720015</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>zombieartist</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118084</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-10-12 02:00:00</td>\n",
       "      <td>0.720015</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>zombieartist</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118195</th>\n",
       "      <td>115</td>\n",
       "      <td>2020-10-16 17:00:00</td>\n",
       "      <td>0.106620</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>zombieartist</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118196</th>\n",
       "      <td>116</td>\n",
       "      <td>2020-10-16 18:00:00</td>\n",
       "      <td>0.106620</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>zombieartist</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118197</th>\n",
       "      <td>117</td>\n",
       "      <td>2020-10-16 19:00:00</td>\n",
       "      <td>0.106620</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>zombieartist</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118198</th>\n",
       "      <td>118</td>\n",
       "      <td>2020-10-16 20:00:00</td>\n",
       "      <td>0.106620</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>zombieartist</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118199</th>\n",
       "      <td>119</td>\n",
       "      <td>2020-10-16 21:00:00</td>\n",
       "      <td>0.106620</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>zombieartist</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0 Datetime_updated_seconds  Price_USD  Price_Crypto  density  \\\n",
       "118080           0      2020-10-11 22:00:00   0.720015          23.0      1.0   \n",
       "118081           1      2020-10-11 23:00:00   0.720015          23.0      1.0   \n",
       "118082           2      2020-10-12 00:00:00   0.720015          23.0      1.0   \n",
       "118083           3      2020-10-12 01:00:00   0.720015          23.0      1.0   \n",
       "118084           4      2020-10-12 02:00:00   0.720015          23.0      1.0   \n",
       "...            ...                      ...        ...           ...      ...   \n",
       "118195         115      2020-10-16 17:00:00   0.106620           3.0      0.1   \n",
       "118196         116      2020-10-16 18:00:00   0.106620           3.0      0.1   \n",
       "118197         117      2020-10-16 19:00:00   0.106620           3.0      0.1   \n",
       "118198         118      2020-10-16 20:00:00   0.106620           3.0      0.1   \n",
       "118199         119      2020-10-16 21:00:00   0.106620           3.0      0.1   \n",
       "\n",
       "        vertex_count  edge_count  max_diameter  max_radius  max_peripher  \\\n",
       "118080           2.0         1.0           1.0         1.0           2.0   \n",
       "118081           2.0         1.0           1.0         1.0           2.0   \n",
       "118082           2.0         1.0           1.0         1.0           2.0   \n",
       "118083           2.0         1.0           1.0         1.0           2.0   \n",
       "118084           2.0         1.0           1.0         1.0           2.0   \n",
       "...              ...         ...           ...         ...           ...   \n",
       "118195          20.0        19.0           0.0         0.0           0.0   \n",
       "118196          20.0        19.0           0.0         0.0           0.0   \n",
       "118197          20.0        19.0           0.0         0.0           0.0   \n",
       "118198          20.0        19.0           0.0         0.0           0.0   \n",
       "118199          20.0        19.0           0.0         0.0           0.0   \n",
       "\n",
       "        volume    collection  blacklisted  whitelisted  \n",
       "118080     1.0  zombieartist            0            1  \n",
       "118081     0.0  zombieartist            0            1  \n",
       "118082     0.0  zombieartist            0            1  \n",
       "118083     0.0  zombieartist            0            1  \n",
       "118084     0.0  zombieartist            0            1  \n",
       "...        ...           ...          ...          ...  \n",
       "118195     0.0  zombieartist            0            1  \n",
       "118196     0.0  zombieartist            0            1  \n",
       "118197     0.0  zombieartist            0            1  \n",
       "118198     0.0  zombieartist            0            1  \n",
       "118199     0.0  zombieartist            0            1  \n",
       "\n",
       "[120 rows x 14 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day1_dataset_60min[day1_dataset_60min['collection'] == 'zombieartist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_collections = pd.read_csv('NFT_Kmeans_Train_Val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2787550744248985"
      ]
     },
     "execution_count": 581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustered_collections[clustered_collections['train_val_set'] == 'Training']['blacklisted'].sum()/clustered_collections[clustered_collections['train_val_set'] == 'Training']['blacklisted'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['collection', 'blacklisted', 'train_val_set', 'kmeans_clusters'], dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustered_collections.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_df = clustered_collections[clustered_collections['train_val_set']=='Training']\n",
    "validation_df = clustered_collections[clustered_collections['train_val_set']=='Validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>collection</th>\n",
       "      <th>blacklisted</th>\n",
       "      <th>train_val_set</th>\n",
       "      <th>kmeans_clusters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1amazingbook</td>\n",
       "      <td>0</td>\n",
       "      <td>Validation</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1forthebirds</td>\n",
       "      <td>0</td>\n",
       "      <td>Validation</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1fungidents1</td>\n",
       "      <td>0</td>\n",
       "      <td>Validation</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2cryptokingg</td>\n",
       "      <td>0</td>\n",
       "      <td>Validation</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3dnanoocards</td>\n",
       "      <td>0</td>\n",
       "      <td>Validation</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>wpcwrarecard</td>\n",
       "      <td>0</td>\n",
       "      <td>Validation</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>wvmnftsonwax</td>\n",
       "      <td>0</td>\n",
       "      <td>Validation</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>xthingscards</td>\n",
       "      <td>0</td>\n",
       "      <td>Validation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>xxbleetcolxx</td>\n",
       "      <td>0</td>\n",
       "      <td>Validation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>zamuraionwax</td>\n",
       "      <td>1</td>\n",
       "      <td>Validation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>246 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       collection  blacklisted train_val_set  kmeans_clusters\n",
       "0    1amazingbook            0    Validation                4\n",
       "4    1forthebirds            0    Validation                4\n",
       "5    1fungidents1            0    Validation                4\n",
       "10   2cryptokingg            0    Validation                4\n",
       "12   3dnanoocards            0    Validation                4\n",
       "..            ...          ...           ...              ...\n",
       "968  wpcwrarecard            0    Validation                5\n",
       "970  wvmnftsonwax            0    Validation                5\n",
       "972  xthingscards            0    Validation                1\n",
       "973  xxbleetcolxx            0    Validation                1\n",
       "976  zamuraionwax            1    Validation                1\n",
       "\n",
       "[246 rows x 4 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Tuple\n",
    "from enum import Enum\n",
    "\n",
    "\n",
    "class DatasetType(Enum):\n",
    "    TRAINING = 'Training'\n",
    "    VALIDATION = 'Validation'\n",
    "    \n",
    "class Aggregation(Enum):\n",
    "    ONE_MIN = 1\n",
    "    TEN_MIN = 2\n",
    "    THIRTHY_MIN = 3\n",
    "    SIXTY_MIN = 4\n",
    "\n",
    "class Collection:\n",
    "    def __init__(self, name, aggregations:  Dict[Aggregation, pd.DataFrame] = dict(), blacklisted=0):\n",
    "        self.name = name\n",
    "        self.aggregations: Dict[Aggregation, pd.Dataframe] = aggregations\n",
    "        self.blacklisted = blacklisted\n",
    "    \n",
    "    def get_aggregation(self, aggregation: Aggregation):\n",
    "        return self.aggregations.get(aggregation)\n",
    "    \n",
    "    def add_aggregation(self,aggregation: Aggregation, a_df: pd.DataFrame):\n",
    "        self.aggregations[aggregation] = a_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, ds_type: DatasetType, cluster,  collections: List[Collection] = None, columns = []):\n",
    "        self.collections = []\n",
    "        self.ds_type = ds_type\n",
    "        self.columns = columns\n",
    "        \n",
    "    def add(self, collection: Collection):\n",
    "        self.collections.append(collection)\n",
    "        \n",
    "    def concat(self, aggregation):\n",
    "        return pd.concat(\n",
    "            [collection.get_aggregation(aggregation) for collection in self.collections], ignore_index=True)\n",
    "    \n",
    "    def fit(self, aggregation, scaler):\n",
    "        scaler.fit(self.concat(aggregation)[self.columns])\n",
    "    \n",
    "    def transform(self, aggregation, scaler: StandardScaler):\n",
    "        for collection in self.collections:\n",
    "            all_columns = collection.get_aggregation(aggregation).copy()\n",
    "            internal_df = all_columns[self.columns].copy()\n",
    "            internal_df = scaler.transform(internal_df)\n",
    "            collection.add_aggregation(\n",
    "                aggregation, internal_df.copy())\n",
    "    \n",
    "    @property\n",
    "    def length(self):\n",
    "        return len(self.collections)\n",
    "            \n",
    "    def format(self):\n",
    "        x_arr = []\n",
    "        for agg in Aggregation:\n",
    "            x = [collection.get_aggregation(agg) for collection in self.collections]\n",
    "            shape = x[0].shape\n",
    "            x =  np.stack(x)\n",
    "            x = x.reshape(self.length, shape[0], shape[1])\n",
    "            x_arr.append(x)\n",
    "        return x_arr, [collection.blacklisted for collection in self.collections]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing cluster 1 with shape (513, 4)\n",
      "processing cluster 4 with shape (369, 4)\n",
      "processing cluster 5 with shape (103, 4)\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "for cluster in list(clustered_collections.groupby(['kmeans_clusters'])):\n",
    "    print(f'processing cluster {cluster[0]} with shape {cluster[1].shape}')\n",
    "    cluster_number = cluster[0]\n",
    "    training = Dataset(ds_type=DatasetType.TRAINING, cluster = cluster_number)\n",
    "    validation = Dataset(ds_type=DatasetType.VALIDATION, \n",
    "                         cluster = cluster_number, \n",
    "                         columns = ['Price_USD', \n",
    "                                    'Price_Crypto', \n",
    "                                    'volume', \n",
    "                                    'density', \n",
    "                                    'vertex_count', \n",
    "                                    'edge_count', \n",
    "                                    'max_diameter', \n",
    "                                    'max_radius', \n",
    "                                    'max_periphery'])\n",
    "    for row in cluster[1].itertuples(index=False, name=None):\n",
    "        collection = Collection(name=row[0], blacklisted=row[1])\n",
    "        ds_type = row[2]\n",
    "        \n",
    "        for aggregation in [(Aggregation.ONE_MIN, day1_dataset_1min), \n",
    "                   (Aggregation.TEN_MIN, day1_dataset_10min), \n",
    "                   (Aggregation.THIRTHY_MIN, day1_dataset_30min),\n",
    "                   (Aggregation.SIXTY_MIN, day1_dataset_60min) ]:\n",
    "            collection.add_aggregation(aggregation[0], aggregation[1].loc[aggregation[1]['collection'] == collection.name].copy())\n",
    "        \n",
    "        \n",
    "        if ds_type == DatasetType.TRAINING.value:\n",
    "            training.add(copy.deepcopy(collection))\n",
    "        elif ds_type == DatasetType.VALIDATION.value:\n",
    "            validation.add(copy.deepcopy(collection))\n",
    "    models.append(MCNNModel(training = training, validation = validation, cluster = cluster_number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCNNModel:\n",
    "\n",
    "    def __init__(self,  training: Dataset, validation: Dataset, cluster,  \n",
    "                 filters = [200,200,200,200], \n",
    "                 k_sizes= [500,50,30,20],\n",
    "                 batch_size = 50\n",
    "                ):\n",
    "        self.training = training\n",
    "        self.validation = validation\n",
    "        self.cluster = cluster\n",
    "        self.scalers =   {agg: StandardScaler() for agg in Aggregation}\n",
    "        self.filters = filters\n",
    "        self.k_sizes = k_sizes\n",
    "        self.batch_size = 50\n",
    "        self.model = None\n",
    "        self.model_hist = None\n",
    "        self.scaled = False\n",
    "        \n",
    "    def scale(self):\n",
    "        if not self.scaled:\n",
    "            for agg in Aggregation:\n",
    "                print('fitting aggregation', agg)\n",
    "                self.training.fit(agg, self.scalers.get(agg))\n",
    "                print('transforming aggregation', agg)\n",
    "                self.training.transform(agg, self.scalers.get(agg))\n",
    "                self.validation.transform(agg, self.scalers.get(agg))\n",
    "            self.scaled = True\n",
    "            \n",
    "            \n",
    "    def retrieve_tensor_datasets(self):\n",
    "        train_x, train_y = self.training.format()\n",
    "        validation_x, validation_y = self.validation.format()\n",
    "        formatted_train = ({f'input{n}': data for n, data in enumerate(train_x) }, train_y)\n",
    "        formatted_test = ({f'input{n}': data for n, data in enumerate(validation_x) }, validation_y)\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices(formatted_train).batch(200)\n",
    "        test_dataset = tf.data.Dataset.from_tensor_slices(formatted_test).batch(200)\n",
    "        return train_dataset, test_dataset\n",
    "    \n",
    "    @property\n",
    "    def shapes(self):\n",
    "        return [aggregation_type.shape \n",
    "                for aggregation_type in list(self.training.collections[0].aggregations.values())]\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_base_model(shape, k_size = k_sizes[0], num_filters = filters[0]):\n",
    "        print(\"base model shape\", shape)\n",
    "        input_seq = Input(shape=shape)\n",
    "        nb_filters = num_filters\n",
    "        convolved = Conv1D(num_filters, k_size, padding=\"same\", activation=\"relu\")(input_seq)\n",
    "        processed = GlobalMaxPooling1D()(convolved)\n",
    "        #todo: fix maxpooling\n",
    "    #     processed = MaxPooling1D(pool_size=2, strides=1, padding='same')(convolved)\n",
    "        compressed = Dense(100, activation=\"relu\")(processed)\n",
    "        compressed = Dropout(0.3)(compressed)\n",
    "        model = Model(inputs=input_seq, outputs=compressed)\n",
    "        model.summary()\n",
    "        return model\n",
    "    \n",
    "    @staticmethod\n",
    "    def main_model(shapes, filters, k_sizes):\n",
    "        inputs = [Input(shape=shape, name=f'input{n}')for n, shape in enumerate(shapes)]\n",
    "        sub_models = [ MCNNModel.get_base_model(shape, k_size = k_sizes[n], num_filters=filters[n]) \n",
    "                      for n, shape in enumerate(shapes)]\n",
    "        print(sub_models[0].output)\n",
    "        embeddings = [ model(inputs[n]) for n, model in enumerate(sub_models)]\n",
    "        merged = Concatenate()(embeddings)\n",
    "        #todo: tweak dense be modifiable \n",
    "        layer1 = Dense(100, activation='relu', name ='hidden_layer1')(merged)\n",
    "        layer2 = Dense(50, activation='relu', name ='hidden_layer2')(layer1)\n",
    "        layer3 = Dense(25, activation='relu', name ='hidden_layer3')(layer2)\n",
    "        out = Dense(1, activation='sigmoid')(layer3)\n",
    "        model = Model(inputs=inputs, outputs=out)\n",
    "        return model\n",
    "    \n",
    "    def run_model(self):\n",
    "        train, validation = self.retrieve_tensor_datasets()\n",
    "        model_shapes = self.shapes\n",
    "        filters = self.filters\n",
    "        k_sizes = self.k_sizes\n",
    "        es = keras.callbacks.EarlyStopping(min_delta=0.001, patience=10)\n",
    "        model = MCNNModel.main_model(model_shapes, filters, k_sizes)\n",
    "        model.compile(loss='binary_crossentropy', # categorical_crossentropy\n",
    "                              optimizer='adam', #sgd, nadam, adam, rmsprop\n",
    "                              metrics=['binary_accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall(),\n",
    "                                       tf.keras.metrics.AUC(curve='PR')])\n",
    "        model.summary()\n",
    "        model_hist = model.fit(train,\n",
    "                                   validation_data=validation,\n",
    "                                   batch_size=self.batch_size, epochs=2000, \n",
    "                               callbacks=[es]\n",
    "                              )\n",
    "        self.model = model\n",
    "        self.model_hist = model_hist\n",
    "        return self\n",
    "    \n",
    "    def predict(self):\n",
    "        val_x, val_y = self.validation.format()\n",
    "        if self.model:\n",
    "            result = self.model.predict(val_x)\n",
    "            return [result[0] for result in results], val_y\n",
    "        else:\n",
    "            return [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pr_auc(actual, scores):\n",
    "    precision, recall, thresholds = precision_recall_curve(actual, scores)\n",
    "    # Use AUC function to calculate the area under the curve of precision recall curve\n",
    "    auc_precision_recall = auc(recall, precision)\n",
    "    return auc_precision_recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "class CustomClusteredModel:\n",
    "    def __init__(self, models: List[MCNNModel], threshold=0.1):\n",
    "        self.models = models\n",
    "        self.scores = dict()\n",
    "        self.threshold = threshold\n",
    "    \n",
    "    def scale(self):\n",
    "        for model in self.models:\n",
    "            model.scale()\n",
    "        \n",
    "    def train_model(self):\n",
    "        futures = []\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            for model in self.models:\n",
    "                an_executor = executor.submit(model.run_model)\n",
    "                futures.append(an_executor)\n",
    "        \n",
    "        for a_future in as_completed(futures):\n",
    "            model = a_future.result()\n",
    "            print(f'Modeling for cluster {model.cluster} finished')\n",
    "            \n",
    "    def metrics(self):\n",
    "        all_predictions = []\n",
    "        all_actuals = []\n",
    "        all_scores = []\n",
    "        for model in self.models:\n",
    "            predictions, actuals = CustomClusteredModel.predict(model)\n",
    "            print('prediction and actuals', len(predictions), len(actuals))\n",
    "            all_predictions.extend([1 if prediction > self.threshold else 0 for prediction in predictions])\n",
    "            all_scores.extend(predictions)\n",
    "            all_actuals.extend(actuals)\n",
    "        print(len(all_predictions))\n",
    "        print(len(all_actuals))\n",
    "        self.scores['accuracy'] = accuracy_score(all_actuals, all_predictions)\n",
    "        self.scores['recall'] = recall_score(all_actuals, all_predictions)\n",
    "        self.scores['precision'] = precision_score(all_actuals, all_predictions)\n",
    "        self.scores['f1_score'] = f1_score(all_actuals, all_predictions)\n",
    "        self.scores['pr_auc'] = average_precision_score(all_actuals, all_scores) #pr_auc\n",
    "        self.scores['auc'] = roc_auc_score(all_actuals, all_scores)\n",
    "        return self.scores\n",
    "        \n",
    "    @staticmethod    \n",
    "    def predict(model):\n",
    "        val_x, val_y = model.validation.format()\n",
    "#         print('val x shape', val_x)\n",
    "        if model:\n",
    "            results = model.model.predict(val_x)\n",
    "            print('inside predict', len(result))\n",
    "            return [result[0] for result in results], val_y\n",
    "        else:\n",
    "            return [], []\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccm = CustomClusteredModel(models, 0.2787)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting\n",
      "transforming\n",
      "transforming\n",
      "fitting\n",
      "transforming\n",
      "transforming\n",
      "fitting\n",
      "transforming\n",
      "transforming\n",
      "fitting\n",
      "transforming\n",
      "transforming\n",
      "fitting\n",
      "transforming\n",
      "transforming\n",
      "fitting\n",
      "transforming\n",
      "transforming\n",
      "fitting\n",
      "transforming\n",
      "transforming\n",
      "fitting\n",
      "transforming\n",
      "transforming\n",
      "fitting\n",
      "transforming\n",
      "transforming\n",
      "fitting\n",
      "transforming\n",
      "transforming\n",
      "fitting\n",
      "transforming\n",
      "transforming\n",
      "fitting\n",
      "transforming\n",
      "transforming\n"
     ]
    }
   ],
   "source": [
    "ccm.scale()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base model shape (7200, 6)\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 7200, 6)]         0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 7200, 200)         600200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 620,300\n",
      "Trainable params: 620,300\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "base model shape (720, 6)\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 720, 6)]          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 720, 200)          60200     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 80,300\n",
      "Trainable params: 80,300\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "base model shape (240, 6)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 240, 6)]          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 240, 200)          36200     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 56,300\n",
      "Trainable params: 56,300\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "base model shape (120, 6)\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 120, 6)]          0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 120, 200)          24200     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 44,300\n",
      "Trainable params: 44,300\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 100), dtype=tf.float32, name=None), name='dropout/Identity:0', description=\"created by layer 'dropout'\")\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input0 (InputLayer)             [(None, 7200, 6)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input1 (InputLayer)             [(None, 720, 6)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input2 (InputLayer)             [(None, 240, 6)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input3 (InputLayer)             [(None, 120, 6)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model (Functional)              (None, 100)          620300      input0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Functional)            (None, 100)          80300       input1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Functional)            (None, 100)          56300       input2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "model_3 (Functional)            (None, 100)          44300       input3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 400)          0           model[0][0]                      \n",
      "                                                                 model_1[0][0]                    \n",
      "                                                                 model_2[0][0]                    \n",
      "                                                                 model_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer1 (Dense)           (None, 100)          40100       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer2 (Dense)           (None, 50)           5050        hidden_layer1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer3 (Dense)           (None, 25)           1275        hidden_layer2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            26          hidden_layer3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 847,651\n",
      "Trainable params: 847,651\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/2000\n",
      "base model shape (7200, 6)\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 7200, 6)]         0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 7200, 200)         600200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 620,300\n",
      "Trainable params: 620,300\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "base model shape (720, 6)\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 720, 6)]          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 720, 200)          60200     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 80,300\n",
      "Trainable params: 80,300\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "base model shape (240, 6)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base model shape (7200, 6)Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 240, 6)]          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 240, 200)          36200     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 56,300\n",
      "Trainable params: 56,300\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "base model shape (120, 6)\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 120, 6)]          0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 120, 200)          24200     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 44,300\n",
      "Trainable params: 44,300\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 100), dtype=tf.float32, name=None), name='dropout/Identity:0', description=\"created by layer 'dropout'\")\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 7200, 6)]         0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 7200, 200)         600200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 620,300\n",
      "Trainable params: 620,300\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "base model shape (720, 6)\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 720, 6)]          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 720, 200)          60200     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 80,300\n",
      "Trainable params: 80,300\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "base model shape (240, 6)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 240, 6)]          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 240, 200)          36200     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 56,300\n",
      "Trainable params: 56,300\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "base model shape (120, 6)\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input0 (InputLayer)             [(None, 7200, 6)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input1 (InputLayer)             [(None, 720, 6)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input2 (InputLayer)             [(None, 240, 6)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input3 (InputLayer)             [(None, 120, 6)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model (Functional)              (None, 100)          620300      input0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Functional)            (None, 100)          80300       input1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Functional)            (None, 100)          56300       input2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "model_3 (Functional)            (None, 100)          44300       input3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 400)          0           model[0][0]                      \n",
      "                                                                 model_1[0][0]                    \n",
      "                                                                 model_2[0][0]                    \n",
      "                                                                 model_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer1 (Dense)           (None, 100)          40100       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer2 (Dense)           (None, 50)           5050        hidden_layer1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer3 (Dense)           (None, 25)           1275        hidden_layer2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            26          hidden_layer3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 847,651\n",
      "Trainable params: 847,651\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 120, 6)]          0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 120, 200)          24200     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 44,300\n",
      "Trainable params: 44,300\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 100), dtype=tf.float32, name=None), name='dropout/Identity:0', description=\"created by layer 'dropout'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input0 (InputLayer)             [(None, 7200, 6)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input1 (InputLayer)             [(None, 720, 6)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input2 (InputLayer)             [(None, 240, 6)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input3 (InputLayer)             [(None, 120, 6)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model (Functional)              (None, 100)          620300      input0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Functional)            (None, 100)          80300       input1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Functional)            (None, 100)          56300       input2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "model_3 (Functional)            (None, 100)          44300       input3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 400)          0           model[0][0]                      \n",
      "                                                                 model_1[0][0]                    \n",
      "                                                                 model_2[0][0]                    \n",
      "                                                                 model_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer1 (Dense)           (None, 100)          40100       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer2 (Dense)           (None, 50)           5050        hidden_layer1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer3 (Dense)           (None, 25)           1275        hidden_layer2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            26          hidden_layer3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 847,651\n",
      "Trainable params: 847,651\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/2000\n",
      "1/1 [==============================] - 56s 56s/step - loss: 0.6951 - binary_accuracy: 0.5775 - precision: 0.1212 - recall: 0.8000 - auc: 0.1321 - val_loss: 0.4042 - val_binary_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.1165\n",
      "Epoch 2/2000\n",
      "1/1 [==============================] - 21s 21s/step - loss: 0.3319 - binary_accuracy: 0.9296 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0673 - val_loss: 0.4237 - val_binary_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.1302\n",
      "Epoch 3/2000\n",
      "1/1 [==============================] - 30s 30s/step - loss: 0.2710 - binary_accuracy: 0.9296 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0947 - val_loss: 0.4764 - val_binary_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.1342\n",
      "Epoch 4/2000\n",
      "2/2 [==============================] - 120s 41s/step - loss: 0.5648 - binary_accuracy: 0.7936 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.2119 - val_loss: 0.6496 - val_binary_accuracy: 0.8409 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.1109\n",
      "Epoch 2/2000\n",
      "1/1 [==============================] - 30s 30s/step - loss: 0.3332 - binary_accuracy: 0.9296 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0731 - val_loss: 0.4322 - val_binary_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.1390\n",
      "Epoch 5/2000\n",
      "2/2 [==============================] - 152s 71s/step - loss: 0.7199 - binary_accuracy: 0.5607 - precision: 0.3333 - recall: 0.1806 - auc: 0.3716 - val_loss: 0.6587 - val_binary_accuracy: 0.5952 - val_precision: 0.5000 - val_recall: 0.0196 - val_auc: 0.5274\n",
      "Epoch 2/2000\n",
      "1/1 [==============================] - 30s 30s/step - loss: 0.2918 - binary_accuracy: 0.9296 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0915 - val_loss: 0.3828 - val_binary_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.1607\n",
      "Epoch 6/2000\n",
      "1/1 [==============================] - 18s 18s/step - loss: 0.2507 - binary_accuracy: 0.9296 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.1178 - val_loss: 0.3444 - val_binary_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.1836\n",
      "Epoch 7/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.2489 - binary_accuracy: 0.9296 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.1156 - val_loss: 0.3094 - val_binary_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.2197\n",
      "Epoch 8/2000\n",
      "2/2 [==============================] - 104s 34s/step - loss: 0.7073 - binary_accuracy: 0.7972 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.2754 - val_loss: 0.5890 - val_binary_accuracy: 0.8409 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.1121\n",
      "Epoch 3/2000\n",
      "1/1 [==============================] - 38s 38s/step - loss: 0.2215 - binary_accuracy: 0.9296 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.1191 - val_loss: 0.2989 - val_binary_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4658\n",
      "Epoch 9/2000\n",
      "1/1 [==============================] - 18s 18s/step - loss: 0.2061 - binary_accuracy: 0.9296 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.1900 - val_loss: 0.3004 - val_binary_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5228\n",
      "Epoch 10/2000\n",
      "2/2 [==============================] - 125s 67s/step - loss: 0.6781 - binary_accuracy: 0.5995 - precision: 0.3922 - recall: 0.1389 - auc: 0.4001 - val_loss: 0.6596 - val_binary_accuracy: 0.6032 - val_precision: 0.5238 - val_recall: 0.2157 - val_auc: 0.4951\n",
      "Epoch 3/2000\n",
      "1/1 [==============================] - 34s 34s/step - loss: 0.2231 - binary_accuracy: 0.9296 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.1385 - val_loss: 0.3093 - val_binary_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4932\n",
      "Epoch 11/2000\n",
      "2/2 [==============================] - 93s 29s/step - loss: 0.5584 - binary_accuracy: 0.7972 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.2542 - val_loss: 0.4703 - val_binary_accuracy: 0.8409 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.1696\n",
      "Epoch 4/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.2076 - binary_accuracy: 0.9296 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.2860 - val_loss: 0.3028 - val_binary_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.3039\n",
      "Epoch 12/2000\n",
      "1/1 [==============================] - 26s 26s/step - loss: 0.1893 - binary_accuracy: 0.9296 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.3513 - val_loss: 0.2973 - val_binary_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.3039\n",
      "Epoch 13/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 28s 28s/step - loss: 0.1817 - binary_accuracy: 0.9296 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4040 - val_loss: 0.3028 - val_binary_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.2825\n",
      "1/2 [==============>...............] - ETA: 58s - loss: 0.4925 - binary_accuracy: 0.7800 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.3404Epoch 14/2000\n",
      "2/2 [==============================] - 122s 53s/step - loss: 0.6542 - binary_accuracy: 0.6382 - precision: 0.5455 - recall: 0.1667 - auc: 0.4537 - val_loss: 0.6680 - val_binary_accuracy: 0.5873 - val_precision: 0.4286 - val_recall: 0.0588 - val_auc: 0.5027\n",
      "Epoch 4/2000\n",
      "2/2 [==============================] - 88s 29s/step - loss: 0.4691 - binary_accuracy: 0.7972 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.3159 - val_loss: 0.4675 - val_binary_accuracy: 0.8409 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.2001\n",
      "Epoch 5/2000\n",
      "1/1 [==============================] - 45s 45s/step - loss: 0.1905 - binary_accuracy: 0.9296 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5200 - val_loss: 0.3079 - val_binary_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.2917\n",
      "Epoch 15/2000\n",
      "1/1 [==============================] - 16s 16s/step - loss: 0.1579 - binary_accuracy: 0.9296 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6269 - val_loss: 0.3179 - val_binary_accuracy: 0.8438 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.2905\n",
      "Epoch 16/2000\n",
      "1/1 [==============================] - 17s 17s/step - loss: 0.1514 - binary_accuracy: 0.9437 - precision: 1.0000 - recall: 0.2000 - auc: 0.5612 - val_loss: 0.3267 - val_binary_accuracy: 0.8438 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.3072\n",
      "Epoch 17/2000\n",
      "1/1 [==============================] - 30s 30s/step - loss: 0.1616 - binary_accuracy: 0.9296 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6660 - val_loss: 0.3356 - val_binary_accuracy: 0.8438 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.2975\n",
      "Epoch 18/2000\n",
      "2/2 [==============================] - 99s 33s/step - loss: 0.4639 - binary_accuracy: 0.8043 - precision: 0.7500 - recall: 0.0526 - auc: 0.3774 - val_loss: 0.5212 - val_binary_accuracy: 0.8409 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.1314\n",
      "Epoch 6/2000\n",
      "1/1 [==============================] - 27s 27s/step - loss: 0.1444 - binary_accuracy: 0.9437 - precision: 1.0000 - recall: 0.2000 - auc: 1.0000 - val_loss: 0.3461 - val_binary_accuracy: 0.8438 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.3126\n",
      "Epoch 19/2000\n",
      "2/2 [==============================] - 138s 71s/step - loss: 0.6644 - binary_accuracy: 0.6150 - precision: 0.4000 - recall: 0.0694 - auc: 0.4449 - val_loss: 0.6638 - val_binary_accuracy: 0.5952 - val_precision: 0.5000 - val_recall: 0.0980 - val_auc: 0.5063\n",
      "Epoch 5/2000\n",
      "1/1 [==============================] - 32s 32s/step - loss: 0.1650 - binary_accuracy: 0.9437 - precision: 1.0000 - recall: 0.2000 - auc: 0.4050 - val_loss: 0.3542 - val_binary_accuracy: 0.8438 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.3108\n",
      "Epoch 20/2000\n",
      "1/1 [==============================] - 17s 17s/step - loss: 0.1331 - binary_accuracy: 0.9577 - precision: 1.0000 - recall: 0.4000 - auc: 0.6810 - val_loss: 0.3617 - val_binary_accuracy: 0.8438 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.3092\n",
      "Epoch 21/2000\n",
      "1/1 [==============================] - 20s 20s/step - loss: 0.1274 - binary_accuracy: 0.9437 - precision: 1.0000 - recall: 0.2000 - auc: 0.9189 - val_loss: 0.3709 - val_binary_accuracy: 0.8438 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.2815\n",
      "Epoch 22/2000\n",
      "2/2 [==============================] - 94s 27s/step - loss: 0.4525 - binary_accuracy: 0.8043 - precision: 1.0000 - recall: 0.0351 - auc: 0.4303 - val_loss: 0.5084 - val_binary_accuracy: 0.8409 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.1321\n",
      "Epoch 7/2000\n",
      "1/1 [==============================] - 39s 39s/step - loss: 0.1167 - binary_accuracy: 0.9437 - precision: 1.0000 - recall: 0.2000 - auc: 0.7762 - val_loss: 0.3736 - val_binary_accuracy: 0.8438 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.2762\n",
      "2/2 [==============================] - 109s 49s/step - loss: 0.6195 - binary_accuracy: 0.6641 - precision: 0.7188 - recall: 0.1597 - auc: 0.5490 - val_loss: 0.6609 - val_binary_accuracy: 0.5952 - val_precision: 0.5000 - val_recall: 0.0392 - val_auc: 0.5179\n",
      "Epoch 6/2000\n",
      "2/2 [==============================] - 77s 27s/step - loss: 0.4621 - binary_accuracy: 0.8043 - precision: 1.0000 - recall: 0.0351 - auc: 0.3917 - val_loss: 0.4952 - val_binary_accuracy: 0.8409 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.1685\n",
      "Epoch 8/2000\n",
      "2/2 [==============================] - 57s 19s/step - loss: 0.4438 - binary_accuracy: 0.8007 - precision: 0.6000 - recall: 0.0526 - auc: 0.4180 - val_loss: 0.5009 - val_binary_accuracy: 0.8409 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.1542\n",
      "Epoch 9/2000\n",
      "2/2 [==============================] - 94s 47s/step - loss: 0.6232 - binary_accuracy: 0.6357 - precision: 0.5405 - recall: 0.1389 - auc: 0.5135 - val_loss: 0.6643 - val_binary_accuracy: 0.5952 - val_precision: 0.5000 - val_recall: 0.1373 - val_auc: 0.5086\n",
      "Epoch 7/2000\n",
      "2/2 [==============================] - 70s 25s/step - loss: 0.4330 - binary_accuracy: 0.8043 - precision: 0.6250 - recall: 0.0877 - auc: 0.4291 - val_loss: 0.5639 - val_binary_accuracy: 0.8409 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.1330\n",
      "Epoch 10/2000\n",
      "2/2 [==============================] - 86s 47s/step - loss: 0.6401 - binary_accuracy: 0.6512 - precision: 0.6047 - recall: 0.1806 - auc: 0.4972 - val_loss: 0.6733 - val_binary_accuracy: 0.5873 - val_precision: 0.4737 - val_recall: 0.1765 - val_auc: 0.5178\n",
      "Epoch 8/2000\n",
      "2/2 [==============================] - 62s 16s/step - loss: 0.4557 - binary_accuracy: 0.8114 - precision: 0.8333 - recall: 0.0877 - auc: 0.4413 - val_loss: 0.5574 - val_binary_accuracy: 0.8295 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.1267\n",
      "Epoch 11/2000\n",
      "2/2 [==============================] - 85s 39s/step - loss: 0.5812 - binary_accuracy: 0.6899 - precision: 0.7069 - recall: 0.2847 - auc: 0.6172 - val_loss: 0.6747 - val_binary_accuracy: 0.5714 - val_precision: 0.3636 - val_recall: 0.0784 - val_auc: 0.5233\n",
      "Epoch 9/2000\n",
      "2/2 [==============================] - 68s 29s/step - loss: 0.4143 - binary_accuracy: 0.8007 - precision: 0.5455 - recall: 0.1053 - auc: 0.4897 - val_loss: 0.4887 - val_binary_accuracy: 0.8295 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.2004\n",
      "Epoch 12/2000\n",
      "2/2 [==============================] - 56s 16s/step - loss: 0.3936 - binary_accuracy: 0.8007 - precision: 0.5333 - recall: 0.1404 - auc: 0.5284 - val_loss: 0.4612 - val_binary_accuracy: 0.8409 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.3311\n",
      "Epoch 13/2000\n",
      "2/2 [==============================] - 90s 49s/step - loss: 0.6222 - binary_accuracy: 0.6770 - precision: 0.6667 - recall: 0.2639 - auc: 0.5638 - val_loss: 0.6917 - val_binary_accuracy: 0.6032 - val_precision: 0.5385 - val_recall: 0.1373 - val_auc: 0.5185\n",
      "Epoch 10/2000\n",
      "2/2 [==============================] - 69s 24s/step - loss: 0.4037 - binary_accuracy: 0.8221 - precision: 0.8889 - recall: 0.1404 - auc: 0.5771 - val_loss: 0.4803 - val_binary_accuracy: 0.8295 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.2446\n",
      "Epoch 14/2000\n",
      "2/2 [==============================] - 83s 47s/step - loss: 0.5856 - binary_accuracy: 0.6925 - precision: 0.7273 - recall: 0.2778 - auc: 0.6136 - val_loss: 0.7160 - val_binary_accuracy: 0.5794 - val_precision: 0.4286 - val_recall: 0.1176 - val_auc: 0.4882\n",
      "Epoch 11/2000\n",
      "2/2 [==============================] - 62s 17s/step - loss: 0.4110 - binary_accuracy: 0.8292 - precision: 0.8462 - recall: 0.1930 - auc: 0.5436 - val_loss: 0.5398 - val_binary_accuracy: 0.7614 - val_precision: 0.1111 - val_recall: 0.0714 - val_auc: 0.1840\n",
      "Epoch 15/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 87s 39s/step - loss: 0.5970 - binary_accuracy: 0.6770 - precision: 0.6462 - recall: 0.2917 - auc: 0.5825 - val_loss: 0.7064 - val_binary_accuracy: 0.5794 - val_precision: 0.4615 - val_recall: 0.2353 - val_auc: 0.4735\n",
      "2/2 [==============================] - 60s 18s/step - loss: 0.4181 - binary_accuracy: 0.8149 - precision: 0.5581 - recall: 0.4211 - auc: 0.5066 - val_loss: 0.4606 - val_binary_accuracy: 0.8409 - val_precision: 0.5000 - val_recall: 0.0714 - val_auc: 0.3758\n",
      "Epoch 16/2000\n",
      "2/2 [==============================] - 35s 12s/step - loss: 0.4134 - binary_accuracy: 0.8078 - precision: 0.6000 - recall: 0.1579 - auc: 0.5592 - val_loss: 0.4582 - val_binary_accuracy: 0.8523 - val_precision: 0.6667 - val_recall: 0.1429 - val_auc: 0.3780\n",
      "Epoch 17/2000\n",
      "2/2 [==============================] - 32s 12s/step - loss: 0.4102 - binary_accuracy: 0.8078 - precision: 0.5789 - recall: 0.1930 - auc: 0.5157 - val_loss: 0.5182 - val_binary_accuracy: 0.8295 - val_precision: 0.3333 - val_recall: 0.0714 - val_auc: 0.1748\n",
      "Epoch 18/2000\n",
      "2/2 [==============================] - 33s 12s/step - loss: 0.3853 - binary_accuracy: 0.8185 - precision: 0.6071 - recall: 0.2982 - auc: 0.5587 - val_loss: 0.5346 - val_binary_accuracy: 0.8295 - val_precision: 0.3333 - val_recall: 0.0714 - val_auc: 0.1537\n",
      "Epoch 19/2000\n",
      "2/2 [==============================] - 32s 12s/step - loss: 0.4109 - binary_accuracy: 0.8043 - precision: 0.5500 - recall: 0.1930 - auc: 0.5400 - val_loss: 0.4663 - val_binary_accuracy: 0.8523 - val_precision: 1.0000 - val_recall: 0.0714 - val_auc: 0.3969\n",
      "Epoch 20/2000\n",
      "2/2 [==============================] - 33s 12s/step - loss: 0.3639 - binary_accuracy: 0.8399 - precision: 1.0000 - recall: 0.2105 - auc: 0.6786 - val_loss: 0.4669 - val_binary_accuracy: 0.8523 - val_precision: 0.6667 - val_recall: 0.1429 - val_auc: 0.4573\n",
      "Epoch 21/2000\n",
      "2/2 [==============================] - 32s 12s/step - loss: 0.3599 - binary_accuracy: 0.8292 - precision: 0.7368 - recall: 0.2456 - auc: 0.6462 - val_loss: 0.5485 - val_binary_accuracy: 0.7727 - val_precision: 0.2857 - val_recall: 0.2857 - val_auc: 0.3631\n",
      "Epoch 22/2000\n",
      "2/2 [==============================] - 33s 12s/step - loss: 0.3734 - binary_accuracy: 0.8185 - precision: 0.5577 - recall: 0.5088 - auc: 0.6301 - val_loss: 0.5310 - val_binary_accuracy: 0.8523 - val_precision: 0.6000 - val_recall: 0.2143 - val_auc: 0.3382\n",
      "Epoch 23/2000\n",
      "2/2 [==============================] - 33s 12s/step - loss: 0.3492 - binary_accuracy: 0.8399 - precision: 0.7727 - recall: 0.2982 - auc: 0.6692 - val_loss: 0.5311 - val_binary_accuracy: 0.8523 - val_precision: 1.0000 - val_recall: 0.0714 - val_auc: 0.3319\n",
      "Epoch 24/2000\n",
      "2/2 [==============================] - 32s 12s/step - loss: 0.3443 - binary_accuracy: 0.8434 - precision: 1.0000 - recall: 0.2281 - auc: 0.7231 - val_loss: 0.5083 - val_binary_accuracy: 0.8523 - val_precision: 0.6667 - val_recall: 0.1429 - val_auc: 0.3512\n",
      "Epoch 25/2000\n",
      "2/2 [==============================] - 33s 13s/step - loss: 0.3336 - binary_accuracy: 0.8541 - precision: 0.7857 - recall: 0.3860 - auc: 0.6741 - val_loss: 0.5277 - val_binary_accuracy: 0.8636 - val_precision: 0.7500 - val_recall: 0.2143 - val_auc: 0.3497\n",
      "Epoch 26/2000\n",
      "2/2 [==============================] - 32s 12s/step - loss: 0.3306 - binary_accuracy: 0.8505 - precision: 0.7143 - recall: 0.4386 - auc: 0.6611 - val_loss: 0.5467 - val_binary_accuracy: 0.8409 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.2369\n",
      "Modeling for cluster 5 finished\n",
      "Modeling for cluster 1 finished\n",
      "Modeling for cluster 4 finished\n"
     ]
    }
   ],
   "source": [
    "ccm.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccm.models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside predict 1\n",
      "prediction and actuals 126 126\n",
      "inside predict 1\n",
      "prediction and actuals 88 88\n",
      "inside predict 1\n",
      "prediction and actuals 32 32\n",
      "246\n",
      "246\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.6056910569105691,\n",
       " 'recall': 0.7681159420289855,\n",
       " 'precision': 0.39552238805970147,\n",
       " 'f1_score': 0.5221674876847291,\n",
       " 'pr_auc': 0.4387294881266916,\n",
       " 'auc': 0.7037582903463523}"
      ]
     },
     "execution_count": 607,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccm.metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
