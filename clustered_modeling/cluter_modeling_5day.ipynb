{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "from numpy.random import normal\n",
    "\n",
    "import torch\n",
    "import torch.autograd as autograd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from multiprocessing import cpu_count\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from torchmetrics.functional import accuracy\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, recall_score, precision_score, f1_score, roc_auc_score, auc, average_precision_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "from keras.layers import Conv1D, Dense, Dropout, Input, Concatenate, GlobalMaxPooling1D, MaxPooling1D\n",
    "from keras.models import Model\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# from keras.optimizers import RMSprop, adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "day1_dataset_1min = pd.read_csv('../Data Slices/5_days_timeseries_data/1min.csv')\n",
    "day1_dataset_10min = pd.read_csv('../Data Slices/5_days_timeseries_data/10min.csv')\n",
    "day1_dataset_30min = pd.read_csv('../Data Slices/5_days_timeseries_data/30min.csv')\n",
    "day1_dataset_60min = pd.read_csv('../Data Slices/5_days_timeseries_data/60min.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Datetime_updated_seconds</th>\n",
       "      <th>Price_USD</th>\n",
       "      <th>Price_Crypto</th>\n",
       "      <th>density</th>\n",
       "      <th>vertex_count</th>\n",
       "      <th>edge_count</th>\n",
       "      <th>max_diameter</th>\n",
       "      <th>max_radius</th>\n",
       "      <th>max_peripher</th>\n",
       "      <th>volume</th>\n",
       "      <th>collection</th>\n",
       "      <th>blacklisted</th>\n",
       "      <th>whitelisted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>118080</th>\n",
       "      <td>0</td>\n",
       "      <td>2020-10-11 22:00:00</td>\n",
       "      <td>0.720015</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>zombieartist</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118081</th>\n",
       "      <td>1</td>\n",
       "      <td>2020-10-11 23:00:00</td>\n",
       "      <td>0.720015</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>zombieartist</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118082</th>\n",
       "      <td>2</td>\n",
       "      <td>2020-10-12 00:00:00</td>\n",
       "      <td>0.720015</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>zombieartist</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118083</th>\n",
       "      <td>3</td>\n",
       "      <td>2020-10-12 01:00:00</td>\n",
       "      <td>0.720015</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>zombieartist</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118084</th>\n",
       "      <td>4</td>\n",
       "      <td>2020-10-12 02:00:00</td>\n",
       "      <td>0.720015</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>zombieartist</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118195</th>\n",
       "      <td>115</td>\n",
       "      <td>2020-10-16 17:00:00</td>\n",
       "      <td>0.106620</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>zombieartist</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118196</th>\n",
       "      <td>116</td>\n",
       "      <td>2020-10-16 18:00:00</td>\n",
       "      <td>0.106620</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>zombieartist</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118197</th>\n",
       "      <td>117</td>\n",
       "      <td>2020-10-16 19:00:00</td>\n",
       "      <td>0.106620</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>zombieartist</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118198</th>\n",
       "      <td>118</td>\n",
       "      <td>2020-10-16 20:00:00</td>\n",
       "      <td>0.106620</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>zombieartist</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118199</th>\n",
       "      <td>119</td>\n",
       "      <td>2020-10-16 21:00:00</td>\n",
       "      <td>0.106620</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>zombieartist</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0 Datetime_updated_seconds  Price_USD  Price_Crypto  density  \\\n",
       "118080           0      2020-10-11 22:00:00   0.720015          23.0      1.0   \n",
       "118081           1      2020-10-11 23:00:00   0.720015          23.0      1.0   \n",
       "118082           2      2020-10-12 00:00:00   0.720015          23.0      1.0   \n",
       "118083           3      2020-10-12 01:00:00   0.720015          23.0      1.0   \n",
       "118084           4      2020-10-12 02:00:00   0.720015          23.0      1.0   \n",
       "...            ...                      ...        ...           ...      ...   \n",
       "118195         115      2020-10-16 17:00:00   0.106620           3.0      0.1   \n",
       "118196         116      2020-10-16 18:00:00   0.106620           3.0      0.1   \n",
       "118197         117      2020-10-16 19:00:00   0.106620           3.0      0.1   \n",
       "118198         118      2020-10-16 20:00:00   0.106620           3.0      0.1   \n",
       "118199         119      2020-10-16 21:00:00   0.106620           3.0      0.1   \n",
       "\n",
       "        vertex_count  edge_count  max_diameter  max_radius  max_peripher  \\\n",
       "118080           2.0         1.0           1.0         1.0           2.0   \n",
       "118081           2.0         1.0           1.0         1.0           2.0   \n",
       "118082           2.0         1.0           1.0         1.0           2.0   \n",
       "118083           2.0         1.0           1.0         1.0           2.0   \n",
       "118084           2.0         1.0           1.0         1.0           2.0   \n",
       "...              ...         ...           ...         ...           ...   \n",
       "118195          20.0        19.0           0.0         0.0           0.0   \n",
       "118196          20.0        19.0           0.0         0.0           0.0   \n",
       "118197          20.0        19.0           0.0         0.0           0.0   \n",
       "118198          20.0        19.0           0.0         0.0           0.0   \n",
       "118199          20.0        19.0           0.0         0.0           0.0   \n",
       "\n",
       "        volume    collection  blacklisted  whitelisted  \n",
       "118080     1.0  zombieartist            0            1  \n",
       "118081     0.0  zombieartist            0            1  \n",
       "118082     0.0  zombieartist            0            1  \n",
       "118083     0.0  zombieartist            0            1  \n",
       "118084     0.0  zombieartist            0            1  \n",
       "...        ...           ...          ...          ...  \n",
       "118195     0.0  zombieartist            0            1  \n",
       "118196     0.0  zombieartist            0            1  \n",
       "118197     0.0  zombieartist            0            1  \n",
       "118198     0.0  zombieartist            0            1  \n",
       "118199     0.0  zombieartist            0            1  \n",
       "\n",
       "[120 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day1_dataset_60min[day1_dataset_60min['collection'] == 'zombieartist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_collections = pd.read_csv('NFT_Kmeans_Train_Val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2787550744248985"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustered_collections[clustered_collections['train_val_set'] == 'Training']['blacklisted'].sum()/clustered_collections[clustered_collections['train_val_set'] == 'Training']['blacklisted'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_4= clustered_collections[clustered_collections['kmeans_clusters'] == 4]\n",
    "cluster_5= clustered_collections[clustered_collections['kmeans_clusters'] == 5]\n",
    "cluster_1= clustered_collections[clustered_collections['kmeans_clusters'] == 1]\n",
    "# clustered_collections[clustered_collections['train_val_set'] == 'Training']['blacklisted'].sum()/clustered_collections[clustered_collections['train_val_set'] == 'Training']['blacklisted'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['collection', 'blacklisted', 'train_val_set', 'kmeans_clusters'], dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustered_collections.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_df = clustered_collections[clustered_collections['train_val_set']=='Training']\n",
    "validation_df = clustered_collections[clustered_collections['train_val_set']=='Validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>collection</th>\n",
       "      <th>blacklisted</th>\n",
       "      <th>train_val_set</th>\n",
       "      <th>kmeans_clusters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1amazingbook</td>\n",
       "      <td>0</td>\n",
       "      <td>Validation</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1forthebirds</td>\n",
       "      <td>0</td>\n",
       "      <td>Validation</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1fungidents1</td>\n",
       "      <td>0</td>\n",
       "      <td>Validation</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2cryptokingg</td>\n",
       "      <td>0</td>\n",
       "      <td>Validation</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3dnanoocards</td>\n",
       "      <td>0</td>\n",
       "      <td>Validation</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>wpcwrarecard</td>\n",
       "      <td>0</td>\n",
       "      <td>Validation</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>wvmnftsonwax</td>\n",
       "      <td>0</td>\n",
       "      <td>Validation</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>xthingscards</td>\n",
       "      <td>0</td>\n",
       "      <td>Validation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>xxbleetcolxx</td>\n",
       "      <td>0</td>\n",
       "      <td>Validation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>zamuraionwax</td>\n",
       "      <td>1</td>\n",
       "      <td>Validation</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>246 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       collection  blacklisted train_val_set  kmeans_clusters\n",
       "0    1amazingbook            0    Validation                4\n",
       "4    1forthebirds            0    Validation                4\n",
       "5    1fungidents1            0    Validation                4\n",
       "10   2cryptokingg            0    Validation                4\n",
       "12   3dnanoocards            0    Validation                4\n",
       "..            ...          ...           ...              ...\n",
       "968  wpcwrarecard            0    Validation                5\n",
       "970  wvmnftsonwax            0    Validation                5\n",
       "972  xthingscards            0    Validation                1\n",
       "973  xxbleetcolxx            0    Validation                1\n",
       "976  zamuraionwax            1    Validation                1\n",
       "\n",
       "[246 rows x 4 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Tuple\n",
    "from enum import Enum\n",
    "\n",
    "\n",
    "class DatasetType(Enum):\n",
    "    TRAINING = 'Training'\n",
    "    VALIDATION = 'Validation'\n",
    "    \n",
    "class Aggregation(Enum):\n",
    "    ONE_MIN = 1\n",
    "    TEN_MIN = 2\n",
    "    THIRTHY_MIN = 3\n",
    "    SIXTY_MIN = 4\n",
    "\n",
    "class Collection:\n",
    "    def __init__(self, name, aggregations:  Dict[Aggregation, pd.DataFrame] = dict(), blacklisted=0):\n",
    "        self.name = name\n",
    "        self.aggregations: Dict[Aggregation, pd.Dataframe] = aggregations\n",
    "        self.blacklisted = blacklisted\n",
    "    \n",
    "    def get_aggregation(self, aggregation: Aggregation):\n",
    "        return self.aggregations.get(aggregation)\n",
    "    \n",
    "    def add_aggregation(self,aggregation: Aggregation, a_df: pd.DataFrame):\n",
    "        self.aggregations[aggregation] = a_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, ds_type: DatasetType, cluster,  collections: List[Collection] = None, columns = []):\n",
    "        self.collections = []\n",
    "        self.ds_type = ds_type\n",
    "        self.columns = columns\n",
    "        \n",
    "    def add(self, collection: Collection):\n",
    "        self.collections.append(collection)\n",
    "        \n",
    "    def concat(self, aggregation):\n",
    "        return pd.concat(\n",
    "            [collection.get_aggregation(aggregation) for collection in self.collections], ignore_index=True)\n",
    "    \n",
    "    def fit(self, aggregation, scaler):\n",
    "        scaler.fit(self.concat(aggregation)[self.columns])\n",
    "    \n",
    "    def transform(self, aggregation, scaler: StandardScaler):\n",
    "        for collection in self.collections:\n",
    "            all_columns = collection.get_aggregation(aggregation).copy()\n",
    "            internal_df = all_columns[self.columns].copy()\n",
    "            internal_df = scaler.transform(internal_df)\n",
    "            collection.add_aggregation(\n",
    "                aggregation, internal_df.copy())\n",
    "    \n",
    "    @property\n",
    "    def length(self):\n",
    "        return len(self.collections)\n",
    "            \n",
    "    def format(self):\n",
    "        x_arr = []\n",
    "        for agg in Aggregation:\n",
    "            x = [collection.get_aggregation(agg) for collection in self.collections]\n",
    "            shape = x[0].shape\n",
    "            x =  np.stack(x)\n",
    "            x = x.reshape(self.length, shape[0], shape[1])\n",
    "            x_arr.append(x)\n",
    "        return x_arr, [collection.blacklisted for collection in self.collections]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>collection</th>\n",
       "      <th>blacklisted</th>\n",
       "      <th>train_val_set</th>\n",
       "      <th>kmeans_clusters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1amazingbook</td>\n",
       "      <td>0</td>\n",
       "      <td>Validation</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1bitcoinlive</td>\n",
       "      <td>0</td>\n",
       "      <td>Training</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1bodyinmove1</td>\n",
       "      <td>0</td>\n",
       "      <td>Training</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1coolartnft1</td>\n",
       "      <td>0</td>\n",
       "      <td>Training</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1forthebirds</td>\n",
       "      <td>0</td>\n",
       "      <td>Validation</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>zeugencorona</td>\n",
       "      <td>1</td>\n",
       "      <td>Training</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>zippergirls1</td>\n",
       "      <td>0</td>\n",
       "      <td>Training</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>zlfhomedecor</td>\n",
       "      <td>0</td>\n",
       "      <td>Training</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>zombaeseries</td>\n",
       "      <td>0</td>\n",
       "      <td>Training</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>zombieartist</td>\n",
       "      <td>0</td>\n",
       "      <td>Training</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>985 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       collection  blacklisted train_val_set  kmeans_clusters\n",
       "0    1amazingbook            0    Validation                4\n",
       "1    1bitcoinlive            0      Training                1\n",
       "2    1bodyinmove1            0      Training                1\n",
       "3    1coolartnft1            0      Training                4\n",
       "4    1forthebirds            0    Validation                4\n",
       "..            ...          ...           ...              ...\n",
       "980  zeugencorona            1      Training                4\n",
       "981  zippergirls1            0      Training                1\n",
       "982  zlfhomedecor            0      Training                4\n",
       "983  zombaeseries            0      Training                1\n",
       "984  zombieartist            0      Training                4\n",
       "\n",
       "[985 rows x 4 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustered_collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_singular_mcnn():\n",
    "    training = Dataset(ds_type=DatasetType.TRAINING, cluster = None,columns=columns )\n",
    "    validation = Dataset(ds_type=DatasetType.VALIDATION, \n",
    "                             cluster = None, \n",
    "                             columns = columns)\n",
    "    for row in clustered_collections.itertuples(index=False, name=None):\n",
    "        collection = Collection(name=row[0], blacklisted=row[1])\n",
    "        ds_type = row[2]\n",
    "        for aggregation in [(Aggregation.ONE_MIN, day1_dataset_1min), (Aggregation.TEN_MIN, day1_dataset_10min), \n",
    "                       (Aggregation.THIRTHY_MIN, day1_dataset_30min),(Aggregation.SIXTY_MIN, day1_dataset_60min) ]:\n",
    "                collection.add_aggregation(aggregation[0], aggregation[1].loc[aggregation[1]['collection'] == collection.name].copy())\n",
    "        if ds_type == DatasetType.TRAINING.value:\n",
    "            training.add(copy.deepcopy(collection))\n",
    "        elif ds_type == DatasetType.VALIDATION.value:\n",
    "            validation.add(copy.deepcopy(collection))\n",
    "    return MCNNModel(training = training, validation = validation, cluster = cluster_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcnn_model = create_singular_mcnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "246"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcnn_model.validation.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing cluster 1 with shape (513, 4)\n",
      "processing cluster 4 with shape (369, 4)\n",
      "processing cluster 5 with shape (103, 4)\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "for cluster in list(clustered_collections.groupby(['kmeans_clusters'])):\n",
    "    print(f'processing cluster {cluster[0]} with shape {cluster[1].shape}')\n",
    "    cluster_number = cluster[0]\n",
    "    columns = ['Price_USD', \n",
    "                                    'Price_Crypto', \n",
    "                                    'volume', \n",
    "                                    'density', \n",
    "                                    'vertex_count', \n",
    "                                    'edge_count', \n",
    "                                    'max_diameter', \n",
    "                                    'max_radius', \n",
    "                                    'max_peripher']\n",
    "    training = Dataset(ds_type=DatasetType.TRAINING, cluster = cluster_number,columns=columns )\n",
    "    validation = Dataset(ds_type=DatasetType.VALIDATION, \n",
    "                         cluster = cluster_number, \n",
    "                         columns = columns)\n",
    "    for row in cluster[1].itertuples(index=False, name=None):\n",
    "        collection = Collection(name=row[0], blacklisted=row[1])\n",
    "        ds_type = row[2]\n",
    "        \n",
    "        for aggregation in [(Aggregation.ONE_MIN, day1_dataset_1min), \n",
    "                   (Aggregation.TEN_MIN, day1_dataset_10min), \n",
    "                   (Aggregation.THIRTHY_MIN, day1_dataset_30min),\n",
    "                   (Aggregation.SIXTY_MIN, day1_dataset_60min) ]:\n",
    "            collection.add_aggregation(aggregation[0], aggregation[1].loc[aggregation[1]['collection'] == collection.name].copy())\n",
    "        \n",
    "        \n",
    "        if ds_type == DatasetType.TRAINING.value:\n",
    "            training.add(copy.deepcopy(collection))\n",
    "        elif ds_type == DatasetType.VALIDATION.value:\n",
    "            validation.add(copy.deepcopy(collection))\n",
    "    models.append(MCNNModel(training = training, validation = validation, cluster = cluster_number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Price_USD',\n",
       " 'Price_Crypto',\n",
       " 'volume',\n",
       " 'density',\n",
       " 'vertex_count',\n",
       " 'edge_count',\n",
       " 'max_diameter',\n",
       " 'max_radius',\n",
       " 'max_peripher']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models[0].training.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCNNModel:\n",
    "\n",
    "    def __init__(self,  training: Dataset, validation: Dataset, cluster,  \n",
    "                 filters = [200,200,200,200], \n",
    "                 k_sizes= [500,50,30,20],\n",
    "                 batch_size = 50\n",
    "                ):\n",
    "        self.training = training\n",
    "        self.validation = validation\n",
    "        self.cluster = cluster\n",
    "        self.scalers =   {agg: StandardScaler() for agg in Aggregation}\n",
    "        self.filters = filters\n",
    "        self.k_sizes = k_sizes\n",
    "        self.batch_size = 50\n",
    "        self.model = None\n",
    "        self.model_hist = None\n",
    "        self.scaled = False\n",
    "        \n",
    "    def scale(self):\n",
    "        if not self.scaled:\n",
    "            for agg in Aggregation:\n",
    "                print('fitting aggregation', agg)\n",
    "                self.training.fit(agg, self.scalers.get(agg))\n",
    "                print('transforming aggregation', agg)\n",
    "                self.training.transform(agg, self.scalers.get(agg))\n",
    "                self.validation.transform(agg, self.scalers.get(agg))\n",
    "            self.scaled = True\n",
    "            \n",
    "            \n",
    "    def retrieve_tensor_datasets(self):\n",
    "        train_x, train_y = self.training.format()\n",
    "        validation_x, validation_y = self.validation.format()\n",
    "        formatted_train = ({f'input{n}': data for n, data in enumerate(train_x) }, train_y)\n",
    "        formatted_test = ({f'input{n}': data for n, data in enumerate(validation_x) }, validation_y)\n",
    "        train_dataset = tf.data.Dataset.from_tensor_slices(formatted_train).batch(200)\n",
    "        test_dataset = tf.data.Dataset.from_tensor_slices(formatted_test).batch(200)\n",
    "        return train_dataset, test_dataset\n",
    "    \n",
    "    @property\n",
    "    def shapes(self):\n",
    "        return [aggregation_type.shape \n",
    "                for aggregation_type in list(self.training.collections[0].aggregations.values())]\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_base_model(shape, k_size, num_filters):\n",
    "        print(\"base model shape\", shape)\n",
    "        input_seq = Input(shape=shape)\n",
    "        nb_filters = num_filters\n",
    "        convolved = Conv1D(num_filters, k_size, padding=\"same\", activation=\"relu\")(input_seq)\n",
    "        processed = GlobalMaxPooling1D()(convolved)\n",
    "        #todo: fix maxpooling\n",
    "    #     processed = MaxPooling1D(pool_size=2, strides=1, padding='same')(convolved)\n",
    "        compressed = Dense(100, activation=\"relu\")(processed)\n",
    "        compressed = Dropout(0.3)(compressed)\n",
    "        model = Model(inputs=input_seq, outputs=compressed)\n",
    "        model.summary()\n",
    "        return model\n",
    "    \n",
    "    @staticmethod\n",
    "    def main_model(shapes, filters, k_sizes):\n",
    "        inputs = [Input(shape=shape, name=f'input{n}')for n, shape in enumerate(shapes)]\n",
    "        sub_models = [ MCNNModel.get_base_model(shape, k_size = k_sizes[n], num_filters=filters[n]) \n",
    "                      for n, shape in enumerate(shapes)]\n",
    "        print(sub_models[0].output)\n",
    "        embeddings = [ model(inputs[n]) for n, model in enumerate(sub_models)]\n",
    "        merged = Concatenate()(embeddings)\n",
    "        #todo: tweak dense be modifiable \n",
    "        layer1 = Dense(100, activation='relu', name ='hidden_layer1')(merged)\n",
    "        layer2 = Dense(50, activation='relu', name ='hidden_layer2')(layer1)\n",
    "        layer3 = Dense(25, activation='relu', name ='hidden_layer3')(layer2)\n",
    "        out = Dense(1, activation='sigmoid')(layer3)\n",
    "        model = Model(inputs=inputs, outputs=out)\n",
    "        return model\n",
    "    \n",
    "    def run_model(self):\n",
    "        train, validation = self.retrieve_tensor_datasets()\n",
    "        model_shapes = self.shapes\n",
    "        filters = self.filters\n",
    "        k_sizes = self.k_sizes\n",
    "        es = keras.callbacks.EarlyStopping(min_delta=0.0001, patience=10)\n",
    "        model = MCNNModel.main_model(model_shapes, filters, k_sizes)\n",
    "        model.compile(loss='binary_crossentropy', # categorical_crossentropy\n",
    "                              optimizer='adam', #sgd, nadam, adam, rmsprop\n",
    "                              metrics=['binary_accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall(),\n",
    "                                       tf.keras.metrics.AUC(curve='PR')])\n",
    "        model.summary()\n",
    "        model_hist = model.fit(train,\n",
    "                                   validation_data=validation,\n",
    "                                   batch_size=self.batch_size, epochs=2000, \n",
    "                               callbacks=[es]\n",
    "                              )\n",
    "        self.model = model\n",
    "        self.model_hist = model_hist\n",
    "        return self\n",
    "    \n",
    "    def predict(self):\n",
    "        val_x, val_y = self.validation.format()\n",
    "        if self.model:\n",
    "            results = self.model.predict(val_x)\n",
    "            return [result[0] for result in results], val_y\n",
    "        else:\n",
    "            return [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pr_auc(actual, scores):\n",
    "    precision, recall, thresholds = precision_recall_curve(actual, scores)\n",
    "    # Use AUC function to calculate the area under the curve of precision recall curve\n",
    "    auc_precision_recall = auc(recall, precision)\n",
    "    return auc_precision_recall\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "class CustomClusteredModel:\n",
    "    def __init__(self, models: List[MCNNModel], thresholds=None):\n",
    "        self.models = models\n",
    "        self.scores = dict()\n",
    "        if thresholds:\n",
    "            self.thresholds = thresholds\n",
    "        else:\n",
    "            self.thresholds = {\n",
    "                1:0.37209302325581395,\n",
    "                4:0.20284697508896798,\n",
    "                5:0.07042253521126761\n",
    "            }\n",
    "    \n",
    "    def scale(self):\n",
    "        for model in self.models:\n",
    "            model.scale()\n",
    "        \n",
    "    def train_model(self):\n",
    "        futures = []\n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            for model in self.models:\n",
    "                an_executor = executor.submit(model.run_model)\n",
    "                futures.append(an_executor)\n",
    "        \n",
    "        for a_future in as_completed(futures):\n",
    "            model = a_future.result()\n",
    "            print(f'Modeling for cluster {model.cluster} finished')\n",
    "            \n",
    "    def metrics(self):\n",
    "        all_predictions = []\n",
    "        all_actuals = []\n",
    "        all_scores = []\n",
    "        \n",
    "        model_scores = {}\n",
    "        for model in self.models:\n",
    "            predictions, actuals = CustomClusteredModel.predict(model)\n",
    "            print('prediction and actuals', len(predictions), len(actuals))\n",
    "            model_scores[model] = (predictions,actuals)\n",
    "            all_predictions.extend([1 if prediction > self.thresholds.get(model.cluster) else 0 for prediction in predictions])\n",
    "            all_scores.extend(predictions)\n",
    "            all_actuals.extend(actuals)\n",
    "        print(len(all_predictions))\n",
    "        print(len(all_actuals))\n",
    "        self.scores['accuracy'] = accuracy_score(all_actuals, all_predictions)\n",
    "        self.scores['recall'] = recall_score(all_actuals, all_predictions)\n",
    "        self.scores['precision'] = precision_score(all_actuals, all_predictions)\n",
    "        self.scores['f1_score'] = f1_score(all_actuals, all_predictions)\n",
    "        self.scores['pr_auc'] = average_precision_score(all_actuals, all_scores) #pr_auc\n",
    "        self.scores['auc'] = roc_auc_score(all_actuals, all_scores)\n",
    "        return self.scores, all_scores, all_actuals, model_scores\n",
    "        \n",
    "    @staticmethod    \n",
    "    def predict(model):\n",
    "        #add choose model (Andrew's clustering/classifcation) \n",
    "        val_x, val_y = model.validation.format()\n",
    "#         print('val x shape', val_x)\n",
    "        if model:\n",
    "            results = model.model.predict(val_x)\n",
    "            return [r[0] for r in results], val_y\n",
    "        else:\n",
    "            return [], []\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccm = CustomClusteredModel(models)\n",
    "ccm2 = CustomClusteredModel(models, thresholds={\n",
    "                1:0.2558139534883721,\n",
    "                4:0.594306049822064,\n",
    "                5:0.8591549295774648\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting aggregation Aggregation.ONE_MIN\n",
      "transforming aggregation Aggregation.ONE_MIN\n",
      "fitting aggregation Aggregation.TEN_MIN\n",
      "transforming aggregation Aggregation.TEN_MIN\n",
      "fitting aggregation Aggregation.THIRTHY_MIN\n",
      "transforming aggregation Aggregation.THIRTHY_MIN\n",
      "fitting aggregation Aggregation.SIXTY_MIN\n",
      "transforming aggregation Aggregation.SIXTY_MIN\n",
      "fitting aggregation Aggregation.ONE_MIN\n",
      "transforming aggregation Aggregation.ONE_MIN\n",
      "fitting aggregation Aggregation.TEN_MIN\n",
      "transforming aggregation Aggregation.TEN_MIN\n",
      "fitting aggregation Aggregation.THIRTHY_MIN\n",
      "transforming aggregation Aggregation.THIRTHY_MIN\n",
      "fitting aggregation Aggregation.SIXTY_MIN\n",
      "transforming aggregation Aggregation.SIXTY_MIN\n",
      "fitting aggregation Aggregation.ONE_MIN\n",
      "transforming aggregation Aggregation.ONE_MIN\n",
      "fitting aggregation Aggregation.TEN_MIN\n",
      "transforming aggregation Aggregation.TEN_MIN\n",
      "fitting aggregation Aggregation.THIRTHY_MIN\n",
      "transforming aggregation Aggregation.THIRTHY_MIN\n",
      "fitting aggregation Aggregation.SIXTY_MIN\n",
      "transforming aggregation Aggregation.SIXTY_MIN\n"
     ]
    }
   ],
   "source": [
    "ccm2.scale()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base model shape (7200, 9)\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 7200, 9)]         0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 7200, 200)         900200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 920,300\n",
      "Trainable params: 920,300\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "base model shape (720, 9)\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 720, 9)]          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 720, 200)          90200     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 110,300\n",
      "Trainable params: 110,300\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "base model shape (240, 9)\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 240, 9)]          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 240, 200)          54200     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 74,300\n",
      "Trainable params: 74,300\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "base model shape (120, 9)\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 120, 9)]          0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 120, 200)          36200     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 56,300\n",
      "Trainable params: 56,300\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 100), dtype=tf.float32, name=None), name='dropout/Identity:0', description=\"created by layer 'dropout'\")\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input0 (InputLayer)             [(None, 7200, 9)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input1 (InputLayer)             [(None, 720, 9)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input2 (InputLayer)             [(None, 240, 9)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input3 (InputLayer)             [(None, 120, 9)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model (Functional)              (None, 100)          920300      input0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Functional)            (None, 100)          110300      input1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Functional)            (None, 100)          74300       input2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "model_3 (Functional)            (None, 100)          56300       input3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 400)          0           model[0][0]                      \n",
      "                                                                 model_1[0][0]                    \n",
      "                                                                 model_2[0][0]                    \n",
      "                                                                 model_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer1 (Dense)           (None, 100)          40100       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer2 (Dense)           (None, 50)           5050        hidden_layer1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer3 (Dense)           (None, 25)           1275        hidden_layer2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            26          hidden_layer3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,207,651\n",
      "Trainable params: 1,207,651\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "base model shape (7200, 9)\n",
      "Epoch 1/2000\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 7200, 9)]         0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 7200, 200)         900200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 920,300\n",
      "Trainable params: 920,300\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "base model shape (720, 9)\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 720, 9)]          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 720, 200)          90200     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 110,300\n",
      "Trainable params: 110,300\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "base model shape (240, 9)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 240, 9)]          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 240, 200)          54200     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 74,300\n",
      "Trainable params: 74,300\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "base model shape (120, 9)\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 120, 9)]          0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 120, 200)          36200     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 56,300\n",
      "Trainable params: 56,300\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 100), dtype=tf.float32, name=None), name='dropout/Identity:0', description=\"created by layer 'dropout'\")\n",
      "base model shape (7200, 9)\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 7200, 9)]         0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 7200, 200)         900200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 920,300\n",
      "Trainable params: 920,300\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "base model shape (720, 9)\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 720, 9)]          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 720, 200)          90200     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 110,300\n",
      "Trainable params: 110,300\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "base model shape (240, 9)\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input0 (InputLayer)             [(None, 7200, 9)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input1 (InputLayer)             [(None, 720, 9)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input2 (InputLayer)             [(None, 240, 9)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input3 (InputLayer)             [(None, 120, 9)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model (Functional)              (None, 100)          920300      input0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Functional)            (None, 100)          110300      input1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Functional)            (None, 100)          74300       input2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "model_3 (Functional)            (None, 100)          56300       input3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 400)          0           model[0][0]                      \n",
      "Model: \"model_2\"                                                                 model_1[0][0]                    \n",
      "                                                                 model_2[0][0]                    \n",
      "                                                                 model_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer1 (Dense)           (None, 100)          40100       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer2 (Dense)           (None, 50)           5050        hidden_layer1[0][0]              \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 240, 9)]          0         \n",
      "_________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer3 (Dense)           (None, 25)           1275        hidden_layer2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            26          hidden_layer3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,207,651\n",
      "conv1d_2 (Conv1D)            (None, 240, 200)          54200     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "Trainable params: 1,207,651\n",
      "Non-trainable params: 0\n",
      "\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 74,300\n",
      "Trainable params: 74,300__________________________________________________________________________________________________\n",
      "\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "base model shape (120, 9)\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 120, 9)]          0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 120, 200)          36200     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 56,300\n",
      "Trainable params: 56,300\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "KerasTensor(type_spec=TensorSpec(shape=(None, 100), dtype=tf.float32, name=None), name='dropout/Identity:0', description=\"created by layer 'dropout'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input0 (InputLayer)             [(None, 7200, 9)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input1 (InputLayer)             [(None, 720, 9)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input2 (InputLayer)             [(None, 240, 9)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input3 (InputLayer)             [(None, 120, 9)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model (Functional)              (None, 100)          920300      input0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Functional)            (None, 100)          110300      input1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "model_2 (Functional)            (None, 100)          74300       input2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "model_3 (Functional)            (None, 100)          56300       input3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 400)          0           model[0][0]                      \n",
      "                                                                 model_1[0][0]                    \n",
      "                                                                 model_2[0][0]                    \n",
      "                                                                 model_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer1 (Dense)           (None, 100)          40100       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer2 (Dense)           (None, 50)           5050        hidden_layer1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "hidden_layer3 (Dense)           (None, 25)           1275        hidden_layer2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            26          hidden_layer3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,207,651\n",
      "Trainable params: 1,207,651\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/2000\n",
      "1/1 [==============================] - 61s 61s/step - loss: 0.5604 - binary_accuracy: 0.9296 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.2714 - val_loss: 0.4237 - val_binary_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0885\n",
      "Epoch 2/2000\n",
      "1/1 [==============================] - 26s 26s/step - loss: 0.2838 - binary_accuracy: 0.9296 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0700 - val_loss: 0.6016 - val_binary_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.0945\n",
      "Epoch 3/2000\n",
      "1/1 [==============================] - 43s 43s/step - loss: 0.2497 - binary_accuracy: 0.9296 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.1354 - val_loss: 0.7366 - val_binary_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.1319\n",
      "Epoch 4/2000\n",
      "2/2 [==============================] - 152s 52s/step - loss: 0.5853 - binary_accuracy: 0.7402 - precision: 0.1923 - recall: 0.0877 - auc: 0.2244 - val_loss: 0.8202 - val_binary_accuracy: 0.8409 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.1060\n",
      "Epoch 2/2000\n",
      "1/1 [==============================] - 37s 37s/step - loss: 0.2724 - binary_accuracy: 0.9296 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.3007 - val_loss: 0.7194 - val_binary_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.1581\n",
      "Epoch 5/2000\n",
      "1/1 [==============================] - 31s 31s/step - loss: 0.2405 - binary_accuracy: 0.9296 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.1614 - val_loss: 0.6764 - val_binary_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4028\n",
      "Epoch 6/2000\n",
      "2/2 [==============================] - 204s 102s/step - loss: 0.7278 - binary_accuracy: 0.5168 - precision: 0.4122 - recall: 0.7014 - auc: 0.4000 - val_loss: 0.6558 - val_binary_accuracy: 0.5952 - val_precision: 0.5000 - val_recall: 0.0588 - val_auc: 0.5262\n",
      "Epoch 2/2000\n",
      "1/1 [==============================] - 41s 41s/step - loss: 0.2271 - binary_accuracy: 0.9296 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.1216 - val_loss: 0.6962 - val_binary_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.2500 - val_auc: 0.3945\n",
      "Epoch 7/2000\n",
      "1/1 [==============================] - 30s 30s/step - loss: 0.2020 - binary_accuracy: 0.9296 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.3361 - val_loss: 0.7288 - val_binary_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.2500 - val_auc: 0.3858\n",
      "Epoch 8/2000\n",
      "2/2 [==============================] - 133s 39s/step - loss: 0.7367 - binary_accuracy: 0.7972 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.2571 - val_loss: 0.6167 - val_binary_accuracy: 0.8409 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.1727\n",
      "Epoch 3/2000\n",
      "1/1 [==============================] - 53s 53s/step - loss: 0.2032 - binary_accuracy: 0.8873 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.2478 - val_loss: 0.7708 - val_binary_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.2500 - val_auc: 0.3813\n",
      "Epoch 9/2000\n",
      "1/1 [==============================] - 24s 24s/step - loss: 0.1873 - binary_accuracy: 0.9437 - precision: 1.0000 - recall: 0.2000 - auc: 0.3806 - val_loss: 0.8300 - val_binary_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.3779\n",
      "Epoch 10/2000\n",
      "1/1 [==============================] - 26s 26s/step - loss: 0.1618 - binary_accuracy: 0.9296 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4717 - val_loss: 0.8938 - val_binary_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.3775\n",
      "Epoch 11/2000\n",
      "2/2 [==============================] - 182s 95s/step - loss: 0.6987 - binary_accuracy: 0.5736 - precision: 0.3158 - recall: 0.1250 - auc: 0.3816 - val_loss: 0.6522 - val_binary_accuracy: 0.6190 - val_precision: 0.5714 - val_recall: 0.2353 - val_auc: 0.5281\n",
      "Epoch 3/2000\n",
      "1/1 [==============================] - 47s 47s/step - loss: 0.2406 - binary_accuracy: 0.9296 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.2021 - val_loss: 0.9219 - val_binary_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.2500 - val_auc: 0.3765\n",
      "Epoch 12/2000\n",
      "2/2 [==============================] - 145s 52s/step - loss: 0.5794 - binary_accuracy: 0.7687 - precision: 0.1667 - recall: 0.0351 - auc: 0.2494 - val_loss: 0.5587 - val_binary_accuracy: 0.8409 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.1030\n",
      "Epoch 4/2000\n",
      "1/1 [==============================] - 40s 40s/step - loss: 0.1619 - binary_accuracy: 0.9296 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6423 - val_loss: 0.9511 - val_binary_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.2500 - val_auc: 0.3795\n",
      "Epoch 13/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 37s 37s/step - loss: 0.1617 - binary_accuracy: 0.9296 - precision: 0.5000 - recall: 0.2000 - auc: 0.4997 - val_loss: 0.9869 - val_binary_accuracy: 0.8438 - val_precision: 0.3333 - val_recall: 0.2500 - val_auc: 0.3766\n",
      "Epoch 14/2000\n",
      "1/1 [==============================] - 29s 29s/step - loss: 0.1595 - binary_accuracy: 0.9296 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6023 - val_loss: 1.0053 - val_binary_accuracy: 0.8438 - val_precision: 0.3333 - val_recall: 0.2500 - val_auc: 0.3806\n",
      "Epoch 15/2000\n",
      "2/2 [==============================] - 120s 37s/step - loss: 0.5114 - binary_accuracy: 0.8114 - precision: 1.0000 - recall: 0.0702 - auc: 0.3505 - val_loss: 0.4730 - val_binary_accuracy: 0.8409 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.1321\n",
      "Epoch 5/2000\n",
      "1/1 [==============================] - 30s 30s/step - loss: 0.1145 - binary_accuracy: 0.9718 - precision: 1.0000 - recall: 0.6000 - auc: 0.7989 - val_loss: 1.0330 - val_binary_accuracy: 0.8438 - val_precision: 0.3333 - val_recall: 0.2500 - val_auc: 0.3818\n",
      "Epoch 16/2000\n",
      "2/2 [==============================] - 191s 104s/step - loss: 0.6749 - binary_accuracy: 0.6253 - precision: 0.4921 - recall: 0.2153 - auc: 0.4540 - val_loss: 0.6289 - val_binary_accuracy: 0.6429 - val_precision: 0.6667 - val_recall: 0.2353 - val_auc: 0.6072\n",
      "Epoch 4/2000\n",
      "1/1 [==============================] - 53s 53s/step - loss: 0.1599 - binary_accuracy: 0.9155 - precision: 0.4000 - recall: 0.4000 - auc: 0.4722 - val_loss: 1.0608 - val_binary_accuracy: 0.8750 - val_precision: 0.5000 - val_recall: 0.2500 - val_auc: 0.3568\n",
      "Epoch 17/2000\n",
      "1/1 [==============================] - 29s 29s/step - loss: 0.1352 - binary_accuracy: 0.9155 - precision: 0.4000 - recall: 0.4000 - auc: 0.3823 - val_loss: 1.0940 - val_binary_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.2500 - val_auc: 0.3590\n",
      "Epoch 18/2000\n",
      "1/1 [==============================] - 58s 58s/step - loss: 0.1132 - binary_accuracy: 0.9437 - precision: 1.0000 - recall: 0.2000 - auc: 0.6928 - val_loss: 1.1566 - val_binary_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.3631\n",
      "2/2 [==============================] - 159s 53s/step - loss: 0.5026 - binary_accuracy: 0.8007 - precision: 1.0000 - recall: 0.0175 - auc: 0.2841 - val_loss: 0.4528 - val_binary_accuracy: 0.8523 - val_precision: 1.0000 - val_recall: 0.0714 - val_auc: 0.3495\n",
      "Epoch 6/2000\n",
      "Epoch 19/2000\n",
      "1/1 [==============================] - 34s 34s/step - loss: 0.1489 - binary_accuracy: 0.9296 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6849 - val_loss: 1.1751 - val_binary_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.2500 - val_auc: 0.3680\n",
      "Epoch 20/2000\n",
      "2/2 [==============================] - 189s 98s/step - loss: 0.6523 - binary_accuracy: 0.6434 - precision: 0.5625 - recall: 0.1875 - auc: 0.4776 - val_loss: 0.6262 - val_binary_accuracy: 0.6587 - val_precision: 0.7222 - val_recall: 0.2549 - val_auc: 0.6016\n",
      "1/1 [==============================] - 27s 27s/step - loss: 0.1298 - binary_accuracy: 0.9296 - precision: 0.5000 - recall: 0.2000 - auc: 0.5648 - val_loss: 1.1842 - val_binary_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.2500 - val_auc: 0.3680\n",
      "Epoch 21/2000\n",
      "Epoch 5/2000\n",
      "1/1 [==============================] - 41s 41s/step - loss: 0.1116 - binary_accuracy: 0.9577 - precision: 1.0000 - recall: 0.4000 - auc: 0.7436 - val_loss: 1.1901 - val_binary_accuracy: 0.9062 - val_precision: 1.0000 - val_recall: 0.2500 - val_auc: 0.3609\n",
      "2/2 [==============================] - 121s 30s/step - loss: 0.4616 - binary_accuracy: 0.8007 - precision: 0.6667 - recall: 0.0351 - auc: 0.3720 - val_loss: 0.4722 - val_binary_accuracy: 0.8409 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.3127\n",
      "Epoch 7/2000\n",
      "2/2 [==============================] - 130s 55s/step - loss: 0.6651 - binary_accuracy: 0.6253 - precision: 0.4932 - recall: 0.2500 - auc: 0.4457 - val_loss: 0.6421 - val_binary_accuracy: 0.6587 - val_precision: 0.6333 - val_recall: 0.3725 - val_auc: 0.5571\n",
      "Epoch 6/2000\n",
      "2/2 [==============================] - 99s 43s/step - loss: 0.4640 - binary_accuracy: 0.7829 - precision: 0.2500 - recall: 0.0351 - auc: 0.3301 - val_loss: 0.4514 - val_binary_accuracy: 0.8409 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.1782\n",
      "Epoch 8/2000\n",
      "2/2 [==============================] - 79s 25s/step - loss: 0.4557 - binary_accuracy: 0.7972 - precision: 0.5000 - recall: 0.0351 - auc: 0.4197 - val_loss: 0.4428 - val_binary_accuracy: 0.8409 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.1799\n",
      "Epoch 9/2000\n",
      "2/2 [==============================] - 132s 71s/step - loss: 0.6250 - binary_accuracy: 0.6408 - precision: 0.5263 - recall: 0.3472 - auc: 0.5334 - val_loss: 0.6425 - val_binary_accuracy: 0.6508 - val_precision: 0.6522 - val_recall: 0.2941 - val_auc: 0.5500\n",
      "Epoch 7/2000\n",
      "2/2 [==============================] - 88s 25s/step - loss: 0.4745 - binary_accuracy: 0.7865 - precision: 0.2000 - recall: 0.0175 - auc: 0.3740 - val_loss: 0.4318 - val_binary_accuracy: 0.8409 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.2016\n",
      "Epoch 10/2000\n",
      "2/2 [==============================] - 115s 62s/step - loss: 0.6188 - binary_accuracy: 0.6460 - precision: 0.5614 - recall: 0.2222 - auc: 0.5380 - val_loss: 0.6345 - val_binary_accuracy: 0.6429 - val_precision: 0.6667 - val_recall: 0.2353 - val_auc: 0.5850\n",
      "1/2 [==============>...............] - ETA: 1:00 - loss: 0.5133 - binary_accuracy: 0.7950 - precision: 0.8000 - recall: 0.0909 - auc: 0.3746Epoch 8/2000\n",
      "2/2 [==============================] - 96s 35s/step - loss: 0.4638 - binary_accuracy: 0.8114 - precision: 0.7500 - recall: 0.1053 - auc: 0.3916 - val_loss: 0.4228 - val_binary_accuracy: 0.8409 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.2499\n",
      "Epoch 11/2000\n",
      "2/2 [==============================] - 84s 28s/step - loss: 0.4702 - binary_accuracy: 0.7900 - precision: 0.4167 - recall: 0.0877 - auc: 0.3760 - val_loss: 0.4326 - val_binary_accuracy: 0.8295 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.2779\n",
      "Epoch 12/2000\n",
      "2/2 [==============================] - 130s 66s/step - loss: 0.6276 - binary_accuracy: 0.6408 - precision: 0.5490 - recall: 0.1944 - auc: 0.5168 - val_loss: 0.6371 - val_binary_accuracy: 0.6587 - val_precision: 0.6818 - val_recall: 0.2941 - val_auc: 0.5433\n",
      "Epoch 9/2000\n",
      "2/2 [==============================] - 93s 35s/step - loss: 0.4381 - binary_accuracy: 0.7794 - precision: 0.3810 - recall: 0.1404 - auc: 0.4187 - val_loss: 0.4434 - val_binary_accuracy: 0.8409 - val_precision: 0.5000 - val_recall: 0.0714 - val_auc: 0.2828\n",
      "Epoch 13/2000\n",
      "2/2 [==============================] - 119s 66s/step - loss: 0.6247 - binary_accuracy: 0.6408 - precision: 0.5342 - recall: 0.2708 - auc: 0.5267 - val_loss: 0.6561 - val_binary_accuracy: 0.6587 - val_precision: 0.6429 - val_recall: 0.3529 - val_auc: 0.5496\n",
      "Epoch 10/2000\n",
      "2/2 [==============================] - 86s 24s/step - loss: 0.4386 - binary_accuracy: 0.7972 - precision: 0.5000 - recall: 0.1579 - auc: 0.4123 - val_loss: 0.4445 - val_binary_accuracy: 0.8523 - val_precision: 1.0000 - val_recall: 0.0714 - val_auc: 0.3026\n",
      "Epoch 14/2000\n",
      "2/2 [==============================] - 118s 53s/step - loss: 0.6050 - binary_accuracy: 0.6873 - precision: 0.6264 - recall: 0.3958 - auc: 0.5841 - val_loss: 0.6351 - val_binary_accuracy: 0.6667 - val_precision: 0.7368 - val_recall: 0.2745 - val_auc: 0.5729\n",
      "Epoch 11/2000\n",
      "2/2 [==============================] - 96s 42s/step - loss: 0.4356 - binary_accuracy: 0.8114 - precision: 0.7000 - recall: 0.1228 - auc: 0.5103 - val_loss: 0.4672 - val_binary_accuracy: 0.8523 - val_precision: 1.0000 - val_recall: 0.0714 - val_auc: 0.3352\n",
      "Epoch 15/2000\n",
      "2/2 [==============================] - 78s 24s/step - loss: 0.4284 - binary_accuracy: 0.8114 - precision: 0.7500 - recall: 0.1053 - auc: 0.4482 - val_loss: 0.4929 - val_binary_accuracy: 0.8295 - val_precision: 0.4000 - val_recall: 0.1429 - val_auc: 0.3114\n",
      "Epoch 16/2000\n",
      "2/2 [==============================] - 129s 69s/step - loss: 0.5986 - binary_accuracy: 0.6770 - precision: 0.6792 - recall: 0.2500 - auc: 0.5721 - val_loss: 0.6320 - val_binary_accuracy: 0.6587 - val_precision: 0.7500 - val_recall: 0.2353 - val_auc: 0.5991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/2000\n",
      "2/2 [==============================] - 96s 34s/step - loss: 0.4064 - binary_accuracy: 0.8078 - precision: 0.6154 - recall: 0.1404 - auc: 0.5066 - val_loss: 0.4832 - val_binary_accuracy: 0.8295 - val_precision: 0.4286 - val_recall: 0.2143 - val_auc: 0.3381\n",
      "Epoch 17/2000\n",
      "2/2 [==============================] - 113s 65s/step - loss: 0.6197 - binary_accuracy: 0.6718 - precision: 0.6735 - recall: 0.2292 - auc: 0.5554 - val_loss: 0.6407 - val_binary_accuracy: 0.6667 - val_precision: 0.6552 - val_recall: 0.3725 - val_auc: 0.5738\n",
      "Epoch 13/2000\n",
      "2/2 [==============================] - 85s 23s/step - loss: 0.4321 - binary_accuracy: 0.7972 - precision: 0.5000 - recall: 0.2281 - auc: 0.4445 - val_loss: 0.4607 - val_binary_accuracy: 0.8523 - val_precision: 0.6667 - val_recall: 0.1429 - val_auc: 0.3904\n",
      "Epoch 18/2000\n",
      "2/2 [==============================] - 116s 54s/step - loss: 0.6320 - binary_accuracy: 0.6589 - precision: 0.5667 - recall: 0.3542 - auc: 0.5396 - val_loss: 0.6418 - val_binary_accuracy: 0.6587 - val_precision: 0.6000 - val_recall: 0.4706 - val_auc: 0.5808\n",
      "Epoch 14/2000\n",
      "2/2 [==============================] - 95s 41s/step - loss: 0.4080 - binary_accuracy: 0.8292 - precision: 0.8000 - recall: 0.2105 - auc: 0.5679 - val_loss: 0.4432 - val_binary_accuracy: 0.8523 - val_precision: 0.5714 - val_recall: 0.2857 - val_auc: 0.4372\n",
      "Epoch 19/2000\n",
      "2/2 [==============================] - 77s 24s/step - loss: 0.3922 - binary_accuracy: 0.8185 - precision: 0.6250 - recall: 0.2632 - auc: 0.5598 - val_loss: 0.4464 - val_binary_accuracy: 0.8295 - val_precision: 0.4444 - val_recall: 0.2857 - val_auc: 0.4485\n",
      "Epoch 20/2000\n",
      "2/2 [==============================] - 126s 68s/step - loss: 0.5950 - binary_accuracy: 0.6925 - precision: 0.6404 - recall: 0.3958 - auc: 0.6087 - val_loss: 0.6176 - val_binary_accuracy: 0.6508 - val_precision: 0.6000 - val_recall: 0.4118 - val_auc: 0.5882\n",
      "Epoch 15/2000\n",
      "2/2 [==============================] - 95s 34s/step - loss: 0.3958 - binary_accuracy: 0.8221 - precision: 0.6061 - recall: 0.3509 - auc: 0.5586 - val_loss: 0.4508 - val_binary_accuracy: 0.8409 - val_precision: 0.5000 - val_recall: 0.2143 - val_auc: 0.4090\n",
      "Epoch 21/2000\n",
      "2/2 [==============================] - 113s 65s/step - loss: 0.5801 - binary_accuracy: 0.7183 - precision: 0.7778 - recall: 0.3403 - auc: 0.6573 - val_loss: 0.6209 - val_binary_accuracy: 0.6508 - val_precision: 0.6207 - val_recall: 0.3529 - val_auc: 0.5890\n",
      "Epoch 16/2000\n",
      "2/2 [==============================] - 84s 23s/step - loss: 0.4086 - binary_accuracy: 0.8185 - precision: 0.6000 - recall: 0.3158 - auc: 0.5229 - val_loss: 0.4658 - val_binary_accuracy: 0.8523 - val_precision: 0.5714 - val_recall: 0.2857 - val_auc: 0.4092\n",
      "Epoch 22/2000\n",
      "2/2 [==============================] - 115s 53s/step - loss: 0.5813 - binary_accuracy: 0.6951 - precision: 0.6857 - recall: 0.3333 - auc: 0.6266 - val_loss: 0.6330 - val_binary_accuracy: 0.6508 - val_precision: 0.6129 - val_recall: 0.3725 - val_auc: 0.5714\n",
      "Epoch 17/2000\n",
      "2/2 [==============================] - 93s 40s/step - loss: 0.3618 - binary_accuracy: 0.8363 - precision: 0.6571 - recall: 0.4035 - auc: 0.6324 - val_loss: 0.5064 - val_binary_accuracy: 0.8182 - val_precision: 0.4000 - val_recall: 0.2857 - val_auc: 0.3430\n",
      "Epoch 23/2000\n",
      "2/2 [==============================] - 78s 23s/step - loss: 0.3747 - binary_accuracy: 0.8185 - precision: 0.5938 - recall: 0.3333 - auc: 0.5728 - val_loss: 0.5100 - val_binary_accuracy: 0.8409 - val_precision: 0.5000 - val_recall: 0.0714 - val_auc: 0.2963\n",
      "Epoch 24/2000\n",
      "2/2 [==============================] - 126s 67s/step - loss: 0.6026 - binary_accuracy: 0.6718 - precision: 0.6104 - recall: 0.3264 - auc: 0.5931 - val_loss: 0.6397 - val_binary_accuracy: 0.6667 - val_precision: 0.6800 - val_recall: 0.3333 - val_auc: 0.5690\n",
      "Epoch 18/2000\n",
      "2/2 [==============================] - 86s 27s/step - loss: 0.3647 - binary_accuracy: 0.8363 - precision: 0.7895 - recall: 0.2632 - auc: 0.6405 - val_loss: 0.4857 - val_binary_accuracy: 0.8409 - val_precision: 0.5000 - val_recall: 0.1429 - val_auc: 0.3722\n",
      "Epoch 25/2000\n",
      "2/2 [==============================] - 110s 62s/step - loss: 0.5644 - binary_accuracy: 0.7416 - precision: 0.7750 - recall: 0.4306 - auc: 0.6615 - val_loss: 0.6227 - val_binary_accuracy: 0.6746 - val_precision: 0.7273 - val_recall: 0.3137 - val_auc: 0.5982\n",
      "Epoch 19/2000\n",
      "2/2 [==============================] - 91s 34s/step - loss: 0.3483 - binary_accuracy: 0.8399 - precision: 0.7143 - recall: 0.3509 - auc: 0.6360 - val_loss: 0.4475 - val_binary_accuracy: 0.8636 - val_precision: 0.7500 - val_recall: 0.2143 - val_auc: 0.4766\n",
      "Epoch 26/2000\n",
      "2/2 [==============================] - 80s 27s/step - loss: 0.3535 - binary_accuracy: 0.8470 - precision: 0.7692 - recall: 0.3509 - auc: 0.6478 - val_loss: 0.4530 - val_binary_accuracy: 0.8636 - val_precision: 0.6667 - val_recall: 0.2857 - val_auc: 0.4668\n",
      "Epoch 27/2000\n",
      "2/2 [==============================] - 123s 60s/step - loss: 0.5579 - binary_accuracy: 0.7132 - precision: 0.7619 - recall: 0.3333 - auc: 0.6792 - val_loss: 0.6476 - val_binary_accuracy: 0.6429 - val_precision: 0.6000 - val_recall: 0.3529 - val_auc: 0.5788\n",
      "Epoch 20/2000\n",
      "2/2 [==============================] - 90s 33s/step - loss: 0.2919 - binary_accuracy: 0.8612 - precision: 0.7500 - recall: 0.4737 - auc: 0.7603 - val_loss: 0.4884 - val_binary_accuracy: 0.8523 - val_precision: 0.5714 - val_recall: 0.2857 - val_auc: 0.3880\n",
      "Epoch 28/2000\n",
      "2/2 [==============================] - 117s 65s/step - loss: 0.5613 - binary_accuracy: 0.7158 - precision: 0.6809 - recall: 0.4444 - auc: 0.6672 - val_loss: 0.6580 - val_binary_accuracy: 0.6349 - val_precision: 0.5926 - val_recall: 0.3137 - val_auc: 0.5645\n",
      "Epoch 21/2000\n",
      "2/2 [==============================] - 83s 23s/step - loss: 0.3173 - binary_accuracy: 0.8541 - precision: 0.7222 - recall: 0.4561 - auc: 0.7072 - val_loss: 0.5463 - val_binary_accuracy: 0.8068 - val_precision: 0.3636 - val_recall: 0.2857 - val_auc: 0.3323\n",
      "Epoch 29/2000\n",
      "2/2 [==============================] - 115s 53s/step - loss: 0.5365 - binary_accuracy: 0.7313 - precision: 0.7564 - recall: 0.4097 - auc: 0.6921 - val_loss: 0.6185 - val_binary_accuracy: 0.6429 - val_precision: 0.6250 - val_recall: 0.2941 - val_auc: 0.6018\n",
      "Epoch 22/2000\n",
      "2/2 [==============================] - 94s 41s/step - loss: 0.3109 - binary_accuracy: 0.8648 - precision: 0.7436 - recall: 0.5088 - auc: 0.7411 - val_loss: 0.5315 - val_binary_accuracy: 0.7955 - val_precision: 0.3333 - val_recall: 0.2857 - val_auc: 0.3573\n",
      "Epoch 30/2000\n",
      "2/2 [==============================] - 77s 23s/step - loss: 0.3131 - binary_accuracy: 0.8683 - precision: 0.7778 - recall: 0.4912 - auc: 0.7265 - val_loss: 0.4796 - val_binary_accuracy: 0.8636 - val_precision: 0.7500 - val_recall: 0.2143 - val_auc: 0.4204\n",
      "2/2 [==============================] - 114s 54s/step - loss: 0.5496 - binary_accuracy: 0.7028 - precision: 0.7231 - recall: 0.3264 - auc: 0.6962 - val_loss: 0.6391 - val_binary_accuracy: 0.6905 - val_precision: 0.6875 - val_recall: 0.4314 - val_auc: 0.5900\n",
      "Epoch 23/2000\n",
      "2/2 [==============================] - 62s 34s/step - loss: 0.5169 - binary_accuracy: 0.7545 - precision: 0.8101 - recall: 0.4444 - auc: 0.7385 - val_loss: 0.6341 - val_binary_accuracy: 0.6825 - val_precision: 0.6667 - val_recall: 0.4314 - val_auc: 0.5954\n",
      "Epoch 24/2000\n",
      "2/2 [==============================] - 67s 39s/step - loss: 0.5179 - binary_accuracy: 0.7519 - precision: 0.8000 - recall: 0.4444 - auc: 0.7274 - val_loss: 0.6300 - val_binary_accuracy: 0.6667 - val_precision: 0.6800 - val_recall: 0.3333 - val_auc: 0.5957\n",
      "Epoch 25/2000\n",
      "2/2 [==============================] - 69s 39s/step - loss: 0.5013 - binary_accuracy: 0.7545 - precision: 0.8451 - recall: 0.4167 - auc: 0.7566 - val_loss: 0.6342 - val_binary_accuracy: 0.6984 - val_precision: 0.6970 - val_recall: 0.4510 - val_auc: 0.6094\n",
      "Epoch 26/2000\n",
      "2/2 [==============================] - 69s 38s/step - loss: 0.5054 - binary_accuracy: 0.7519 - precision: 0.8000 - recall: 0.4444 - auc: 0.7555 - val_loss: 0.6554 - val_binary_accuracy: 0.6825 - val_precision: 0.6341 - val_recall: 0.5098 - val_auc: 0.6115\n",
      "Epoch 27/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 69s 38s/step - loss: 0.4994 - binary_accuracy: 0.7545 - precision: 0.7634 - recall: 0.4931 - auc: 0.7524 - val_loss: 0.6517 - val_binary_accuracy: 0.6984 - val_precision: 0.6667 - val_recall: 0.5098 - val_auc: 0.6087\n",
      "Epoch 28/2000\n",
      "2/2 [==============================] - 75s 40s/step - loss: 0.4903 - binary_accuracy: 0.7545 - precision: 0.7952 - recall: 0.4583 - auc: 0.7496 - val_loss: 0.7020 - val_binary_accuracy: 0.6508 - val_precision: 0.6000 - val_recall: 0.4118 - val_auc: 0.5467\n",
      "Epoch 29/2000\n",
      "2/2 [==============================] - 79s 48s/step - loss: 0.4934 - binary_accuracy: 0.7597 - precision: 0.7931 - recall: 0.4792 - auc: 0.7625 - val_loss: 0.7042 - val_binary_accuracy: 0.6270 - val_precision: 0.5455 - val_recall: 0.4706 - val_auc: 0.5648\n",
      "Epoch 30/2000\n",
      "2/2 [==============================] - 111s 62s/step - loss: 0.4805 - binary_accuracy: 0.7752 - precision: 0.7938 - recall: 0.5347 - auc: 0.7774 - val_loss: 0.6537 - val_binary_accuracy: 0.6667 - val_precision: 0.6216 - val_recall: 0.4510 - val_auc: 0.6169\n",
      "Epoch 31/2000\n",
      "2/2 [==============================] - 93s 46s/step - loss: 0.4654 - binary_accuracy: 0.7623 - precision: 0.8171 - recall: 0.4653 - auc: 0.7722 - val_loss: 0.6607 - val_binary_accuracy: 0.6587 - val_precision: 0.6250 - val_recall: 0.3922 - val_auc: 0.5794\n",
      "Epoch 32/2000\n",
      "2/2 [==============================] - 100s 61s/step - loss: 0.4726 - binary_accuracy: 0.7545 - precision: 0.7692 - recall: 0.4861 - auc: 0.7720 - val_loss: 0.7215 - val_binary_accuracy: 0.6270 - val_precision: 0.5476 - val_recall: 0.4510 - val_auc: 0.5444\n",
      "Epoch 33/2000\n",
      "2/2 [==============================] - 86s 48s/step - loss: 0.4382 - binary_accuracy: 0.7752 - precision: 0.7938 - recall: 0.5347 - auc: 0.8087 - val_loss: 0.6689 - val_binary_accuracy: 0.6508 - val_precision: 0.6129 - val_recall: 0.3725 - val_auc: 0.5735\n",
      "Epoch 34/2000\n",
      "2/2 [==============================] - 94s 55s/step - loss: 0.4348 - binary_accuracy: 0.7984 - precision: 0.8929 - recall: 0.5208 - auc: 0.8182 - val_loss: 0.6915 - val_binary_accuracy: 0.6429 - val_precision: 0.5714 - val_recall: 0.4706 - val_auc: 0.5688\n",
      "Modeling for cluster 4 finished\n",
      "Modeling for cluster 1 finished\n",
      "Modeling for cluster 5 finished\n"
     ]
    }
   ],
   "source": [
    "ccm2.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction and actuals 126 126\n",
      "prediction and actuals 88 88\n",
      "prediction and actuals 32 32\n",
      "246\n",
      "246\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'accuracy': 0.7073170731707317,\n",
       "  'recall': 0.7681159420289855,\n",
       "  'precision': 0.48623853211009177,\n",
       "  'f1_score': 0.5955056179775281,\n",
       "  'pr_auc': 0.5555525061596606,\n",
       "  'auc': 0.7609105051993776},\n",
       " [0.61231315,\n",
       "  0.46982074,\n",
       "  0.4481584,\n",
       "  0.30700344,\n",
       "  0.6662127,\n",
       "  0.7796637,\n",
       "  0.90517277,\n",
       "  0.36214733,\n",
       "  0.603771,\n",
       "  0.863167,\n",
       "  0.8232345,\n",
       "  0.4232804,\n",
       "  0.65359735,\n",
       "  0.9474193,\n",
       "  0.3039164,\n",
       "  0.91275424,\n",
       "  0.42196465,\n",
       "  0.5641688,\n",
       "  0.59019744,\n",
       "  0.7526735,\n",
       "  0.9426371,\n",
       "  0.99890184,\n",
       "  0.13326666,\n",
       "  0.41544598,\n",
       "  0.70453864,\n",
       "  0.09954885,\n",
       "  0.3207967,\n",
       "  0.3239746,\n",
       "  0.9377845,\n",
       "  0.4975063,\n",
       "  0.5059294,\n",
       "  0.20002624,\n",
       "  0.4806873,\n",
       "  0.38144466,\n",
       "  0.38805905,\n",
       "  0.5589733,\n",
       "  0.18100089,\n",
       "  0.30330837,\n",
       "  0.7995721,\n",
       "  0.29057914,\n",
       "  0.6763704,\n",
       "  0.12336916,\n",
       "  0.30968213,\n",
       "  0.06904635,\n",
       "  0.0013312101,\n",
       "  0.3299384,\n",
       "  0.20356485,\n",
       "  0.9446499,\n",
       "  0.19500864,\n",
       "  0.32308364,\n",
       "  0.3054132,\n",
       "  0.31121463,\n",
       "  0.36172962,\n",
       "  0.304227,\n",
       "  0.043332636,\n",
       "  0.43311402,\n",
       "  0.44141328,\n",
       "  0.40956205,\n",
       "  0.26854867,\n",
       "  0.30255705,\n",
       "  0.005213827,\n",
       "  0.34012234,\n",
       "  0.031080365,\n",
       "  0.40363258,\n",
       "  0.3062819,\n",
       "  0.1850752,\n",
       "  0.6923065,\n",
       "  0.4402995,\n",
       "  0.36651778,\n",
       "  0.7846429,\n",
       "  0.3035788,\n",
       "  0.19892877,\n",
       "  0.55753046,\n",
       "  0.2197797,\n",
       "  0.75518376,\n",
       "  0.54642516,\n",
       "  0.4073543,\n",
       "  0.86737037,\n",
       "  0.28455997,\n",
       "  0.7929294,\n",
       "  0.3638559,\n",
       "  0.93996656,\n",
       "  0.8791753,\n",
       "  0.80661964,\n",
       "  0.3061251,\n",
       "  0.22451621,\n",
       "  0.17687514,\n",
       "  0.3170544,\n",
       "  0.3870274,\n",
       "  0.9996265,\n",
       "  0.6832768,\n",
       "  0.30260015,\n",
       "  0.5561083,\n",
       "  0.30733615,\n",
       "  0.28652596,\n",
       "  0.22965476,\n",
       "  0.37264007,\n",
       "  0.35407344,\n",
       "  0.76929474,\n",
       "  0.31827593,\n",
       "  0.3166709,\n",
       "  0.250696,\n",
       "  0.7248037,\n",
       "  0.42595825,\n",
       "  0.34281534,\n",
       "  0.15313184,\n",
       "  0.9854591,\n",
       "  0.34633988,\n",
       "  0.49158067,\n",
       "  0.30404568,\n",
       "  0.30462933,\n",
       "  0.9585813,\n",
       "  0.94761014,\n",
       "  0.27452248,\n",
       "  0.7880485,\n",
       "  0.94222474,\n",
       "  0.2145629,\n",
       "  0.32296374,\n",
       "  0.30591607,\n",
       "  0.3116422,\n",
       "  0.30458677,\n",
       "  0.32326764,\n",
       "  0.4829457,\n",
       "  0.31286836,\n",
       "  0.31339407,\n",
       "  0.46747017,\n",
       "  0.08626282,\n",
       "  0.19470876,\n",
       "  0.20495349,\n",
       "  0.023318708,\n",
       "  0.37474346,\n",
       "  0.9948871,\n",
       "  0.65558755,\n",
       "  0.97126406,\n",
       "  0.075523496,\n",
       "  0.37608612,\n",
       "  0.032308042,\n",
       "  0.03169191,\n",
       "  0.11337939,\n",
       "  0.08581278,\n",
       "  0.11650774,\n",
       "  0.17582247,\n",
       "  0.022574067,\n",
       "  0.04639715,\n",
       "  0.06418243,\n",
       "  0.08971757,\n",
       "  0.042391032,\n",
       "  0.29982713,\n",
       "  0.12324381,\n",
       "  0.34019566,\n",
       "  0.11624551,\n",
       "  0.14820501,\n",
       "  0.25177234,\n",
       "  0.0028997064,\n",
       "  0.0071787536,\n",
       "  0.1954275,\n",
       "  0.07591218,\n",
       "  0.013126552,\n",
       "  0.103129715,\n",
       "  0.28638858,\n",
       "  0.054408222,\n",
       "  0.0071160495,\n",
       "  0.041268826,\n",
       "  0.12588775,\n",
       "  0.059032083,\n",
       "  0.10076991,\n",
       "  0.13431656,\n",
       "  0.012151897,\n",
       "  0.036654323,\n",
       "  0.015743643,\n",
       "  0.0016233921,\n",
       "  0.020603329,\n",
       "  0.278127,\n",
       "  0.28411436,\n",
       "  0.116332054,\n",
       "  0.10989517,\n",
       "  0.07525158,\n",
       "  0.16941112,\n",
       "  0.06304327,\n",
       "  0.0047988594,\n",
       "  0.18084013,\n",
       "  0.033597976,\n",
       "  0.00547719,\n",
       "  8.5816086e-05,\n",
       "  0.23986778,\n",
       "  0.081003934,\n",
       "  0.21930814,\n",
       "  0.23887232,\n",
       "  0.10747099,\n",
       "  0.030785918,\n",
       "  0.10498637,\n",
       "  0.1429882,\n",
       "  1.622547e-08,\n",
       "  0.82425857,\n",
       "  0.14782706,\n",
       "  0.008613467,\n",
       "  0.11611098,\n",
       "  0.10155159,\n",
       "  0.021181643,\n",
       "  0.44955456,\n",
       "  0.07158315,\n",
       "  0.0004118383,\n",
       "  0.057902485,\n",
       "  0.29654264,\n",
       "  0.028671682,\n",
       "  0.23978084,\n",
       "  0.014411807,\n",
       "  0.121576846,\n",
       "  0.028558254,\n",
       "  0.25583047,\n",
       "  0.071924865,\n",
       "  0.17216289,\n",
       "  0.04487139,\n",
       "  0.011584491,\n",
       "  0.00055372715,\n",
       "  7.683416e-06,\n",
       "  0.00039499998,\n",
       "  0.00090929866,\n",
       "  0.001242429,\n",
       "  1.2726389e-15,\n",
       "  0.25044727,\n",
       "  1.2188035e-07,\n",
       "  0.06860301,\n",
       "  0.096963614,\n",
       "  0.011022031,\n",
       "  0.00012990832,\n",
       "  0.0028222501,\n",
       "  2.5730376e-08,\n",
       "  0.10796893,\n",
       "  0.005233139,\n",
       "  0.0036078691,\n",
       "  0.009899646,\n",
       "  0.00054234266,\n",
       "  0.25400966,\n",
       "  3.3972152e-05,\n",
       "  3.626633e-05,\n",
       "  0.7826457,\n",
       "  0.006755501,\n",
       "  1.5236814e-11,\n",
       "  0.0,\n",
       "  0.2878093,\n",
       "  4.756842e-05,\n",
       "  4.6709167e-07,\n",
       "  0.0,\n",
       "  6.878516e-13,\n",
       "  6.353152e-08],\n",
       " [1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " {<__main__.MCNNModel at 0x7f9fb0f92970>: ([0.61231315,\n",
       "    0.46982074,\n",
       "    0.4481584,\n",
       "    0.30700344,\n",
       "    0.6662127,\n",
       "    0.7796637,\n",
       "    0.90517277,\n",
       "    0.36214733,\n",
       "    0.603771,\n",
       "    0.863167,\n",
       "    0.8232345,\n",
       "    0.4232804,\n",
       "    0.65359735,\n",
       "    0.9474193,\n",
       "    0.3039164,\n",
       "    0.91275424,\n",
       "    0.42196465,\n",
       "    0.5641688,\n",
       "    0.59019744,\n",
       "    0.7526735,\n",
       "    0.9426371,\n",
       "    0.99890184,\n",
       "    0.13326666,\n",
       "    0.41544598,\n",
       "    0.70453864,\n",
       "    0.09954885,\n",
       "    0.3207967,\n",
       "    0.3239746,\n",
       "    0.9377845,\n",
       "    0.4975063,\n",
       "    0.5059294,\n",
       "    0.20002624,\n",
       "    0.4806873,\n",
       "    0.38144466,\n",
       "    0.38805905,\n",
       "    0.5589733,\n",
       "    0.18100089,\n",
       "    0.30330837,\n",
       "    0.7995721,\n",
       "    0.29057914,\n",
       "    0.6763704,\n",
       "    0.12336916,\n",
       "    0.30968213,\n",
       "    0.06904635,\n",
       "    0.0013312101,\n",
       "    0.3299384,\n",
       "    0.20356485,\n",
       "    0.9446499,\n",
       "    0.19500864,\n",
       "    0.32308364,\n",
       "    0.3054132,\n",
       "    0.31121463,\n",
       "    0.36172962,\n",
       "    0.304227,\n",
       "    0.043332636,\n",
       "    0.43311402,\n",
       "    0.44141328,\n",
       "    0.40956205,\n",
       "    0.26854867,\n",
       "    0.30255705,\n",
       "    0.005213827,\n",
       "    0.34012234,\n",
       "    0.031080365,\n",
       "    0.40363258,\n",
       "    0.3062819,\n",
       "    0.1850752,\n",
       "    0.6923065,\n",
       "    0.4402995,\n",
       "    0.36651778,\n",
       "    0.7846429,\n",
       "    0.3035788,\n",
       "    0.19892877,\n",
       "    0.55753046,\n",
       "    0.2197797,\n",
       "    0.75518376,\n",
       "    0.54642516,\n",
       "    0.4073543,\n",
       "    0.86737037,\n",
       "    0.28455997,\n",
       "    0.7929294,\n",
       "    0.3638559,\n",
       "    0.93996656,\n",
       "    0.8791753,\n",
       "    0.80661964,\n",
       "    0.3061251,\n",
       "    0.22451621,\n",
       "    0.17687514,\n",
       "    0.3170544,\n",
       "    0.3870274,\n",
       "    0.9996265,\n",
       "    0.6832768,\n",
       "    0.30260015,\n",
       "    0.5561083,\n",
       "    0.30733615,\n",
       "    0.28652596,\n",
       "    0.22965476,\n",
       "    0.37264007,\n",
       "    0.35407344,\n",
       "    0.76929474,\n",
       "    0.31827593,\n",
       "    0.3166709,\n",
       "    0.250696,\n",
       "    0.7248037,\n",
       "    0.42595825,\n",
       "    0.34281534,\n",
       "    0.15313184,\n",
       "    0.9854591,\n",
       "    0.34633988,\n",
       "    0.49158067,\n",
       "    0.30404568,\n",
       "    0.30462933,\n",
       "    0.9585813,\n",
       "    0.94761014,\n",
       "    0.27452248,\n",
       "    0.7880485,\n",
       "    0.94222474,\n",
       "    0.2145629,\n",
       "    0.32296374,\n",
       "    0.30591607,\n",
       "    0.3116422,\n",
       "    0.30458677,\n",
       "    0.32326764,\n",
       "    0.4829457,\n",
       "    0.31286836,\n",
       "    0.31339407,\n",
       "    0.46747017],\n",
       "   [1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1]),\n",
       "  <__main__.MCNNModel at 0x7f9cdcdff0a0>: ([0.08626282,\n",
       "    0.19470876,\n",
       "    0.20495349,\n",
       "    0.023318708,\n",
       "    0.37474346,\n",
       "    0.9948871,\n",
       "    0.65558755,\n",
       "    0.97126406,\n",
       "    0.075523496,\n",
       "    0.37608612,\n",
       "    0.032308042,\n",
       "    0.03169191,\n",
       "    0.11337939,\n",
       "    0.08581278,\n",
       "    0.11650774,\n",
       "    0.17582247,\n",
       "    0.022574067,\n",
       "    0.04639715,\n",
       "    0.06418243,\n",
       "    0.08971757,\n",
       "    0.042391032,\n",
       "    0.29982713,\n",
       "    0.12324381,\n",
       "    0.34019566,\n",
       "    0.11624551,\n",
       "    0.14820501,\n",
       "    0.25177234,\n",
       "    0.0028997064,\n",
       "    0.0071787536,\n",
       "    0.1954275,\n",
       "    0.07591218,\n",
       "    0.013126552,\n",
       "    0.103129715,\n",
       "    0.28638858,\n",
       "    0.054408222,\n",
       "    0.0071160495,\n",
       "    0.041268826,\n",
       "    0.12588775,\n",
       "    0.059032083,\n",
       "    0.10076991,\n",
       "    0.13431656,\n",
       "    0.012151897,\n",
       "    0.036654323,\n",
       "    0.015743643,\n",
       "    0.0016233921,\n",
       "    0.020603329,\n",
       "    0.278127,\n",
       "    0.28411436,\n",
       "    0.116332054,\n",
       "    0.10989517,\n",
       "    0.07525158,\n",
       "    0.16941112,\n",
       "    0.06304327,\n",
       "    0.0047988594,\n",
       "    0.18084013,\n",
       "    0.033597976,\n",
       "    0.00547719,\n",
       "    8.5816086e-05,\n",
       "    0.23986778,\n",
       "    0.081003934,\n",
       "    0.21930814,\n",
       "    0.23887232,\n",
       "    0.10747099,\n",
       "    0.030785918,\n",
       "    0.10498637,\n",
       "    0.1429882,\n",
       "    1.622547e-08,\n",
       "    0.82425857,\n",
       "    0.14782706,\n",
       "    0.008613467,\n",
       "    0.11611098,\n",
       "    0.10155159,\n",
       "    0.021181643,\n",
       "    0.44955456,\n",
       "    0.07158315,\n",
       "    0.0004118383,\n",
       "    0.057902485,\n",
       "    0.29654264,\n",
       "    0.028671682,\n",
       "    0.23978084,\n",
       "    0.014411807,\n",
       "    0.121576846,\n",
       "    0.028558254,\n",
       "    0.25583047,\n",
       "    0.071924865,\n",
       "    0.17216289,\n",
       "    0.04487139,\n",
       "    0.011584491],\n",
       "   [0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0]),\n",
       "  <__main__.MCNNModel at 0x7f9cfce1a310>: ([0.00055372715,\n",
       "    7.683416e-06,\n",
       "    0.00039499998,\n",
       "    0.00090929866,\n",
       "    0.001242429,\n",
       "    1.2726389e-15,\n",
       "    0.25044727,\n",
       "    1.2188035e-07,\n",
       "    0.06860301,\n",
       "    0.096963614,\n",
       "    0.011022031,\n",
       "    0.00012990832,\n",
       "    0.0028222501,\n",
       "    2.5730376e-08,\n",
       "    0.10796893,\n",
       "    0.005233139,\n",
       "    0.0036078691,\n",
       "    0.009899646,\n",
       "    0.00054234266,\n",
       "    0.25400966,\n",
       "    3.3972152e-05,\n",
       "    3.626633e-05,\n",
       "    0.7826457,\n",
       "    0.006755501,\n",
       "    1.5236814e-11,\n",
       "    0.0,\n",
       "    0.2878093,\n",
       "    4.756842e-05,\n",
       "    4.6709167e-07,\n",
       "    0.0,\n",
       "    6.878516e-13,\n",
       "    6.353152e-08],\n",
       "   [0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0])})"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccm2.metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def get_permutations():\n",
    "    tuning1 = [i*.02 for i in range(int(1/0.02))]\n",
    "    param_comb = []\n",
    "    for subset in itertools.permutations(tuning1, 3):\n",
    "        param_comb.append(subset)\n",
    "    return param_comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutations = get_permutations()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.98, 0.96, 0.9400000000000001)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permutations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "720"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(permutations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction and actuals 126 126\n",
      "prediction and actuals 88 88\n",
      "prediction and actuals 32 32\n",
      "246\n",
      "246\n"
     ]
    }
   ],
   "source": [
    "_,_,_,a = ccm2.metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{<__main__.MCNNModel at 0x7f9fc956e070>: ([0.2834437,\n",
       "   0.4197714,\n",
       "   0.4456398,\n",
       "   0.33118904,\n",
       "   0.25454122,\n",
       "   0.6164682,\n",
       "   0.29436156,\n",
       "   0.333063,\n",
       "   0.20764238,\n",
       "   0.48848838,\n",
       "   0.15442693,\n",
       "   0.5819849,\n",
       "   0.60199434,\n",
       "   0.5908707,\n",
       "   0.0921191,\n",
       "   0.5605314,\n",
       "   0.49317726,\n",
       "   0.09617284,\n",
       "   0.56882054,\n",
       "   0.65288985,\n",
       "   0.89689124,\n",
       "   0.9805275,\n",
       "   0.13848403,\n",
       "   0.6048446,\n",
       "   0.63964033,\n",
       "   0.07996616,\n",
       "   0.1356155,\n",
       "   0.37464005,\n",
       "   0.74741495,\n",
       "   0.4002385,\n",
       "   0.49612054,\n",
       "   0.11510727,\n",
       "   0.4319935,\n",
       "   0.6212717,\n",
       "   0.008309811,\n",
       "   0.19647992,\n",
       "   0.04822889,\n",
       "   0.33007085,\n",
       "   0.56192535,\n",
       "   0.07135308,\n",
       "   0.22680154,\n",
       "   0.040951997,\n",
       "   0.3321486,\n",
       "   0.035749614,\n",
       "   0.018501222,\n",
       "   0.35068056,\n",
       "   0.14094749,\n",
       "   0.5492408,\n",
       "   0.045867205,\n",
       "   0.3414599,\n",
       "   0.33066714,\n",
       "   0.33273333,\n",
       "   0.34415752,\n",
       "   0.33018896,\n",
       "   0.14340073,\n",
       "   0.492446,\n",
       "   0.54715216,\n",
       "   0.4506877,\n",
       "   0.03819129,\n",
       "   0.3295639,\n",
       "   0.012631685,\n",
       "   0.5165477,\n",
       "   0.07380307,\n",
       "   0.4470405,\n",
       "   0.33095238,\n",
       "   0.15242136,\n",
       "   0.05012551,\n",
       "   0.08508423,\n",
       "   0.5615897,\n",
       "   0.5347782,\n",
       "   0.3299421,\n",
       "   0.1663095,\n",
       "   0.38864774,\n",
       "   0.1282269,\n",
       "   0.20939633,\n",
       "   0.5630134,\n",
       "   0.54550666,\n",
       "   0.26582918,\n",
       "   0.31566453,\n",
       "   0.57080156,\n",
       "   0.54884374,\n",
       "   0.51749986,\n",
       "   0.7776308,\n",
       "   0.7427022,\n",
       "   0.33168215,\n",
       "   0.75123286,\n",
       "   0.049740225,\n",
       "   0.33697632,\n",
       "   0.5978555,\n",
       "   0.9205822,\n",
       "   0.7513437,\n",
       "   0.3295782,\n",
       "   0.40503135,\n",
       "   0.33156806,\n",
       "   0.312518,\n",
       "   0.10663599,\n",
       "   0.42499125,\n",
       "   0.38948432,\n",
       "   0.2524433,\n",
       "   0.33670205,\n",
       "   0.33672965,\n",
       "   0.06115353,\n",
       "   0.38401192,\n",
       "   0.5096895,\n",
       "   0.079752445,\n",
       "   0.070174694,\n",
       "   0.936199,\n",
       "   0.37867847,\n",
       "   0.09768316,\n",
       "   0.33012897,\n",
       "   0.33032113,\n",
       "   0.8709576,\n",
       "   0.7733633,\n",
       "   0.2919093,\n",
       "   0.26136592,\n",
       "   0.2243582,\n",
       "   0.026141614,\n",
       "   0.34081012,\n",
       "   0.331614,\n",
       "   0.3330047,\n",
       "   0.330308,\n",
       "   0.34162104,\n",
       "   0.1246593,\n",
       "   0.33355093,\n",
       "   0.33378446,\n",
       "   0.56258464],\n",
       "  [1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1]),\n",
       " <__main__.MCNNModel at 0x7f9ff991b1c0>: ([0.15225518,\n",
       "   0.15936464,\n",
       "   0.19396949,\n",
       "   0.0413917,\n",
       "   0.37834695,\n",
       "   0.85149896,\n",
       "   0.3590231,\n",
       "   0.31279826,\n",
       "   0.07350296,\n",
       "   0.104497075,\n",
       "   0.013102949,\n",
       "   0.056097686,\n",
       "   0.14098388,\n",
       "   0.1490126,\n",
       "   0.12047514,\n",
       "   0.20539844,\n",
       "   0.03512752,\n",
       "   0.072695196,\n",
       "   0.060091883,\n",
       "   0.065421164,\n",
       "   0.0069202185,\n",
       "   0.008623183,\n",
       "   0.1241861,\n",
       "   0.41813326,\n",
       "   0.13401097,\n",
       "   0.15161118,\n",
       "   0.44377077,\n",
       "   0.0061259866,\n",
       "   0.002219975,\n",
       "   0.2068004,\n",
       "   0.033281565,\n",
       "   0.02535212,\n",
       "   0.03740439,\n",
       "   0.26206663,\n",
       "   0.049643874,\n",
       "   0.037744552,\n",
       "   0.034878522,\n",
       "   0.1661239,\n",
       "   0.061944902,\n",
       "   0.104855835,\n",
       "   0.35350895,\n",
       "   0.013515174,\n",
       "   0.048004836,\n",
       "   0.029510856,\n",
       "   0.00032880902,\n",
       "   0.019959599,\n",
       "   0.12175533,\n",
       "   0.17096245,\n",
       "   0.05414352,\n",
       "   0.02587527,\n",
       "   0.036241293,\n",
       "   0.22155187,\n",
       "   0.08504468,\n",
       "   0.00439173,\n",
       "   0.06261039,\n",
       "   0.07741317,\n",
       "   7.756409e-05,\n",
       "   5.264305e-05,\n",
       "   0.22097942,\n",
       "   0.03174001,\n",
       "   0.18857452,\n",
       "   0.32010013,\n",
       "   0.1188387,\n",
       "   0.07646829,\n",
       "   0.17283297,\n",
       "   0.059437633,\n",
       "   1.725207e-08,\n",
       "   0.27851763,\n",
       "   0.18547359,\n",
       "   0.0016202629,\n",
       "   0.011888236,\n",
       "   0.02329579,\n",
       "   0.038960993,\n",
       "   0.503026,\n",
       "   0.0166516,\n",
       "   0.000104265455,\n",
       "   0.101255625,\n",
       "   0.2277376,\n",
       "   0.010237306,\n",
       "   0.29128647,\n",
       "   0.00052273273,\n",
       "   0.11028072,\n",
       "   0.011018366,\n",
       "   0.18317097,\n",
       "   0.12206498,\n",
       "   0.17093393,\n",
       "   0.1349841,\n",
       "   0.015234321],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0]),\n",
       " <__main__.MCNNModel at 0x7f9fa44992e0>: ([0.086797476,\n",
       "   0.021998823,\n",
       "   0.045119137,\n",
       "   0.08182335,\n",
       "   0.10129222,\n",
       "   7.418809e-06,\n",
       "   0.302786,\n",
       "   0.07495955,\n",
       "   0.13361207,\n",
       "   0.16899648,\n",
       "   0.14240187,\n",
       "   0.030464202,\n",
       "   0.12223247,\n",
       "   0.0013522804,\n",
       "   0.24815801,\n",
       "   0.12878367,\n",
       "   0.023311466,\n",
       "   0.1458801,\n",
       "   0.06098768,\n",
       "   0.17307493,\n",
       "   0.021523207,\n",
       "   0.16349757,\n",
       "   0.21422076,\n",
       "   0.108113885,\n",
       "   1.3465718e-05,\n",
       "   8.126837e-17,\n",
       "   0.317132,\n",
       "   0.08662674,\n",
       "   0.016008735,\n",
       "   0.0,\n",
       "   1.838542e-05,\n",
       "   0.0017962754],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0])}"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'accuracy': 0.3780487804878049,\n",
       "  'recall': 0.9420289855072463,\n",
       "  'precision': 0.3037383177570093,\n",
       "  'f1_score': 0.4593639575971731,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.3780487804878049,\n",
       "  'recall': 0.9420289855072463,\n",
       "  'precision': 0.3037383177570093,\n",
       "  'f1_score': 0.4593639575971731,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.3780487804878049,\n",
       "  'recall': 0.9420289855072463,\n",
       "  'precision': 0.3037383177570093,\n",
       "  'f1_score': 0.4593639575971731,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.3780487804878049,\n",
       "  'recall': 0.9420289855072463,\n",
       "  'precision': 0.3037383177570093,\n",
       "  'f1_score': 0.4593639575971731,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.3780487804878049,\n",
       "  'recall': 0.9420289855072463,\n",
       "  'precision': 0.3037383177570093,\n",
       "  'f1_score': 0.4593639575971731,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.3780487804878049,\n",
       "  'recall': 0.9420289855072463,\n",
       "  'precision': 0.3037383177570093,\n",
       "  'f1_score': 0.4593639575971731,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.3780487804878049,\n",
       "  'recall': 0.9420289855072463,\n",
       "  'precision': 0.3037383177570093,\n",
       "  'f1_score': 0.4593639575971731,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.3780487804878049,\n",
       "  'recall': 0.9420289855072463,\n",
       "  'precision': 0.3037383177570093,\n",
       "  'f1_score': 0.4593639575971731,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.3780487804878049,\n",
       "  'recall': 0.9420289855072463,\n",
       "  'precision': 0.3037383177570093,\n",
       "  'f1_score': 0.4593639575971731,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.3780487804878049,\n",
       "  'recall': 0.9420289855072463,\n",
       "  'precision': 0.3037383177570093,\n",
       "  'f1_score': 0.4593639575971731,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368}]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction and actuals 126 126\n",
      "prediction and actuals 88 88\n",
      "prediction and actuals 32 32\n",
      "246\n",
      "246\n"
     ]
    }
   ],
   "source": [
    "tunningCCM = CustomClusteredModel(ccm2.models, thresholds={\n",
    "                1:0.2558139534883721,\n",
    "                4:0.594306049822064,\n",
    "                5:0.8591549295774648\n",
    "        })\n",
    "_,_,_,a= tunningCCM.metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = []\n",
    "for params in get_permutations():\n",
    "    all_model_predictions = []\n",
    "    all_model_raw_scores = []\n",
    "    all_actuals = []\n",
    "    for index, model in enumerate(a.items()):\n",
    "        model_prediction= [1 if prediction > params[index] else 0 for prediction in model[1][0]]\n",
    "        all_model_predictions.extend(model_prediction)\n",
    "        all_model_raw_scores.extend(model[1][0])\n",
    "        all_actuals.extend(model[1][1])\n",
    "    scores = {}\n",
    "    scores['accuracy'] = accuracy_score(all_actuals, all_model_predictions)\n",
    "    scores['recall'] = recall_score(all_actuals, all_model_predictions)\n",
    "    scores['precision'] = precision_score(all_actuals, all_model_predictions)\n",
    "    scores['f1_score'] = f1_score(all_actuals, all_model_predictions)\n",
    "    scores['pr_auc'] = average_precision_score(all_actuals, all_model_raw_scores) #pr_auc\n",
    "    scores['auc'] = roc_auc_score(all_actuals, all_model_raw_scores)\n",
    "    all_scores.append((scores,params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_f1 = all_scores[0] \n",
    "for idx, score in enumerate(all_scores):\n",
    "    if score[0]['f1_score'] > max_f1[0]['f1_score']:\n",
    "        max_f1 = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'accuracy': 0.7113821138211383,\n",
       "  'recall': 0.6956521739130435,\n",
       "  'precision': 0.4897959183673469,\n",
       "  'f1_score': 0.5748502994011976,\n",
       "  'pr_auc': 0.5156985725622069,\n",
       "  'auc': 0.729632358961762},\n",
       " (0.18, 0.38, 0.52))"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores[22056]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'accuracy': 0.7113821138211383,\n",
       "  'recall': 0.8115942028985508,\n",
       "  'precision': 0.49122807017543857,\n",
       "  'f1_score': 0.6120218579234973,\n",
       "  'pr_auc': 0.5555525061596606,\n",
       "  'auc': 0.7609105051993776},\n",
       " (0.26, 0.3, 0.32))"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0, 0.1, 0.2)\n",
      "prediction and actuals 126 126\n",
      "prediction and actuals 88 88\n",
      "prediction and actuals 32 32\n",
      "246\n",
      "246\n",
      "(0.0, 0.1, 0.30000000000000004)\n",
      "prediction and actuals 126 126\n",
      "prediction and actuals 88 88\n",
      "prediction and actuals 32 32\n",
      "246\n",
      "246\n",
      "(0.0, 0.1, 0.4)\n",
      "prediction and actuals 126 126\n",
      "prediction and actuals 88 88\n",
      "prediction and actuals 32 32\n",
      "246\n",
      "246\n",
      "(0.0, 0.1, 0.5)\n",
      "prediction and actuals 126 126\n",
      "prediction and actuals 88 88\n",
      "prediction and actuals 32 32\n",
      "246\n",
      "246\n",
      "(0.0, 0.1, 0.6000000000000001)\n",
      "prediction and actuals 126 126\n",
      "prediction and actuals 88 88\n",
      "prediction and actuals 32 32\n",
      "246\n",
      "246\n",
      "(0.0, 0.1, 0.7000000000000001)\n",
      "prediction and actuals 126 126\n",
      "prediction and actuals 88 88\n",
      "prediction and actuals 32 32\n",
      "246\n",
      "246\n",
      "(0.0, 0.1, 0.8)\n",
      "prediction and actuals 126 126\n",
      "prediction and actuals 88 88\n",
      "prediction and actuals 32 32\n",
      "246\n",
      "246\n",
      "(0.0, 0.1, 0.9)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-c16f352efe72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     }\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mall_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtunningCCM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-738f8fc01318>\u001b[0m in \u001b[0;36mmetrics\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactuals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCustomClusteredModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'prediction and actuals'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactuals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mall_predictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthresholds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-738f8fc01318>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;31m#         print('val x shape', val_x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1749\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1750\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1751\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1752\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1753\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    922\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1963\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tunningCCM = CustomClusteredModel(ccm2.models, thresholds={\n",
    "                1:0.2558139534883721,\n",
    "                4:0.594306049822064,\n",
    "                5:0.8591549295774648\n",
    "        })\n",
    "all_scores = [] \n",
    "for params in permutations:\n",
    "    print(params)\n",
    "    tunningCCM.thresholds = {\n",
    "        1: params[0],\n",
    "        4: params[1],\n",
    "        5: params[2]\n",
    "    }\n",
    "    all_scores.append(tunningCCM.metrics())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "720"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368},\n",
       " {'accuracy': 0.7195121951219512,\n",
       "  'recall': 0.0,\n",
       "  'precision': 0.0,\n",
       "  'f1_score': 0.0,\n",
       "  'pr_auc': 0.5267216771984266,\n",
       "  'auc': 0.7315155981331368}]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in all_scores]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding adding cluster type to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "input0 =  ccm.models[0].model.get_layer(name='input0').input\n",
    "input1 =  ccm.models[0].model.get_layer(name='input1').input\n",
    "input2 =  ccm.models[0].model.get_layer(name='input2').input\n",
    "input3 =  ccm.models[0].model.get_layer(name='input3').input\n",
    "input4 =  ccm.models[1].model.get_layer(name='input0').input\n",
    "input5 =  ccm.models[1].model.get_layer(name='input1').input\n",
    "input6 =  ccm.models[1].model.get_layer(name='input2').input\n",
    "input7 =  ccm.models[1].model.get_layer(name='input3').input\n",
    "input8 =  ccm.models[2].model.get_layer(name='input0').input\n",
    "input9 =  ccm.models[2].model.get_layer(name='input1').input\n",
    "input10 =  ccm.models[2].model.get_layer(name='input2').input\n",
    "input11 =  ccm.models[2].model.get_layer(name='input3').input\n",
    "cluster1 = ccm.models[0].model.get_layer(name='hidden_layer3').output\n",
    "cluster2 = ccm.models[1].model.get_layer(name='hidden_layer3').output\n",
    "cluster3 = ccm.models[2].model.get_layer(name='hidden_layer3').output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.Dense at 0x7fe28cf797c0>"
      ]
     },
     "execution_count": 639,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[input0, input1, input2, input3, input4, input5, input6, input7, input8, input9, input10, input11, cluster_type_input]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 7200, 6) dtype=float32 (created by layer 'input0')>"
      ]
     },
     "execution_count": 655,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.merge.Concatenate at 0x7fe250444520>"
      ]
     },
     "execution_count": 646,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.functional.Functional at 0x7f9fb13fad30>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_type_input = Input(shape=(1, ))\n",
    "clusters_concat = tf.keras.layers.Concatenate()([cluster1, cluster_type_input])\n",
    "layer3 = Dense(5, activation='relu', name ='hidden_layer4')(clusters_concat)\n",
    "out = Dense(1, activation='sigmoid')(layer3)\n",
    "Model(inputs=[input0, input1, input2, input3, cluster_type_input], outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<BatchDataset shapes: ({input0: (None, 7200, 9), input1: (None, 720, 9), input2: (None, 240, 9), input3: (None, 120, 9)}, (None,)), types: ({input0: tf.float64, input1: tf.float64, input2: tf.float64, input3: tf.float64}, tf.int32)>,\n",
       " <BatchDataset shapes: ({input0: (None, 7200, 9), input1: (None, 720, 9), input2: (None, 240, 9), input3: (None, 120, 9)}, (None,)), types: ({input0: tf.float64, input1: tf.float64, input2: tf.float64, input3: tf.float64}, tf.int32)>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccm2.models[0].retrieve_tensor_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(formatted_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimensions 387 and 71 are not compatible",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-1d89af4d9a08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mformatted_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34mf'input{n}'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# formatted_test = ({f'input{n}': data for n, data in enumerate(validation_x) }, validation_y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformatted_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;31m# test_dataset = tf.data.Dataset.from_tensor_slices(formatted_test).batch(200)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# return train_dataset, test_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mfrom_tensor_slices\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    683\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m     \"\"\"\n\u001b[0;32m--> 685\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mTensorSliceDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m   \u001b[0;32mclass\u001b[0m \u001b[0m_GeneratorState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, element)\u001b[0m\n\u001b[1;32m   3851\u001b[0m         self._tensors[0].get_shape()[0]))\n\u001b[1;32m   3852\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3853\u001b[0;31m       batch_dim.assert_is_compatible_with(tensor_shape.Dimension(\n\u001b[0m\u001b[1;32m   3854\u001b[0m           tensor_shape.dimension_value(t.get_shape()[0])))\n\u001b[1;32m   3855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36massert_is_compatible_with\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    286\u001b[0m     \"\"\"\n\u001b[1;32m    287\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m       raise ValueError(\"Dimensions %s and %s are not compatible\" %\n\u001b[0m\u001b[1;32m    289\u001b[0m                        (self, other))\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Dimensions 387 and 71 are not compatible"
     ]
    }
   ],
   "source": [
    "train_x1, train_y1, = ccm2.models[0].training.format()\n",
    "train_x2, train_y2, = ccm2.models[1].training.format()\n",
    "train_x3, train_y3, = ccm2.models[2].training.format()\n",
    "cluster_1 = [1 for _ in train_y]\n",
    "cluster_2 = [2 for _ in train_y2]\n",
    "cluster_3 = [3 for _ in train_y3]\n",
    "\n",
    "train_x1.extend(train_x2)\n",
    "train_x1.extend(train_x3)\n",
    "train_y1.extend(train_y2)\n",
    "train_y1.extend(train_y3)\n",
    "cluster_1.extend(cluster_2)\n",
    "cluster_1.extend(cluster_3)\n",
    "\n",
    "# validation_x, validation_y = ccm2.models[0].validation.format()\n",
    "formatted_train = ({f'input{n}': data for n, data in enumerate(train_x1) }, train_y1, cluster_1)\n",
    "# formatted_test = ({f'input{n}': data for n, data in enumerate(validation_x) }, validation_y)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(formatted_train).batch(200)\n",
    "# test_dataset = tf.data.Dataset.from_tensor_slices(formatted_test).batch(200)\n",
    "# return train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1 for _ in train_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[ 3.16932185e+00,  1.07767017e+00,  2.86599418e+01, ...,\n",
       "           1.62129982e+00,  2.30014276e+00,  2.06701132e+00],\n",
       "         [ 3.16932185e+00,  1.07767017e+00, -1.91749909e-02, ...,\n",
       "          -3.95215782e-01, -4.23877217e-01, -4.09637161e-01],\n",
       "         [ 3.16932185e+00,  1.07767017e+00, -1.91749909e-02, ...,\n",
       "          -3.95215782e-01, -4.23877217e-01, -4.09637161e-01],\n",
       "         ...,\n",
       "         [ 3.16932185e+00,  1.07767017e+00, -1.91749909e-02, ...,\n",
       "          -3.95215782e-01, -4.23877217e-01, -4.09637161e-01],\n",
       "         [ 3.16932185e+00,  1.07767017e+00, -1.91749909e-02, ...,\n",
       "          -3.95215782e-01, -4.23877217e-01, -4.09637161e-01],\n",
       "         [ 3.16932185e+00,  1.07767017e+00, -1.91749909e-02, ...,\n",
       "          -3.95215782e-01, -4.23877217e-01, -4.09637161e-01]],\n",
       " \n",
       "        [[-2.39906705e-01, -1.06176253e-01,  2.86599418e+01, ...,\n",
       "           1.62129982e+00,  2.30014276e+00,  2.06701132e+00],\n",
       "         [-2.39906705e-01, -1.06176253e-01, -1.91749909e-02, ...,\n",
       "          -3.95215782e-01, -4.23877217e-01, -4.09637161e-01],\n",
       "         [-2.39906705e-01, -1.06176253e-01, -1.91749909e-02, ...,\n",
       "          -3.95215782e-01, -4.23877217e-01, -4.09637161e-01],\n",
       "         ...,\n",
       "         [-2.39906705e-01, -1.06176253e-01, -1.91749909e-02, ...,\n",
       "          -3.95215782e-01, -4.23877217e-01, -4.09637161e-01],\n",
       "         [-2.39906705e-01, -1.06176253e-01, -1.91749909e-02, ...,\n",
       "          -3.95215782e-01, -4.23877217e-01, -4.09637161e-01],\n",
       "         [-2.39906705e-01, -1.06176253e-01, -1.91749909e-02, ...,\n",
       "          -3.95215782e-01, -4.23877217e-01, -4.09637161e-01]],\n",
       " \n",
       "        [[-3.18207278e-01, -3.26033446e-01,  8.60181753e+01, ...,\n",
       "           3.63781543e+00,  2.30014276e+00,  3.30533556e+00],\n",
       "         [-3.17801315e-01, -3.26033446e-01,  5.73390586e+01, ...,\n",
       "           3.63781543e+00,  2.30014276e+00,  5.78198404e+00],\n",
       "         [-3.17801315e-01, -3.26033446e-01, -1.91749909e-02, ...,\n",
       "           3.63781543e+00,  2.30014276e+00,  5.78198404e+00],\n",
       "         ...,\n",
       "         [-3.26780452e-01, -3.28852128e-01, -1.91749909e-02, ...,\n",
       "          -3.95215782e-01, -4.23877217e-01, -4.09637161e-01],\n",
       "         [-3.26780452e-01, -3.28852128e-01, -1.91749909e-02, ...,\n",
       "          -3.95215782e-01, -4.23877217e-01, -4.09637161e-01],\n",
       "         [-3.26780452e-01, -3.28852128e-01, -1.91749909e-02, ...,\n",
       "          -3.95215782e-01, -4.23877217e-01, -4.09637161e-01]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[-1.65696489e-01, -2.61203761e-01,  2.86599418e+01, ...,\n",
       "           1.62129982e+00,  2.30014276e+00,  2.06701132e+00],\n",
       "         [-1.65696489e-01, -2.61203761e-01, -1.91749909e-02, ...,\n",
       "          -3.95215782e-01, -4.23877217e-01, -4.09637161e-01],\n",
       "         [-1.65696489e-01, -2.61203761e-01, -1.91749909e-02, ...,\n",
       "          -3.95215782e-01, -4.23877217e-01, -4.09637161e-01],\n",
       "         ...,\n",
       "         [-1.65696489e-01, -2.61203761e-01, -1.91749909e-02, ...,\n",
       "          -3.95215782e-01, -4.23877217e-01, -4.09637161e-01],\n",
       "         [-1.65696489e-01, -2.61203761e-01, -1.91749909e-02, ...,\n",
       "          -3.95215782e-01, -4.23877217e-01, -4.09637161e-01],\n",
       "         [-1.65696489e-01, -2.61203761e-01, -1.91749909e-02, ...,\n",
       "          -3.95215782e-01, -4.23877217e-01, -4.09637161e-01]],\n",
       " \n",
       "        [[ 1.03697182e-01,  8.52175614e-01,  2.86599418e+01, ...,\n",
       "           1.62129982e+00,  2.30014276e+00,  2.06701132e+00],\n",
       "         [ 1.03697182e-01,  8.52175614e-01, -1.91749909e-02, ...,\n",
       "          -3.95215782e-01, -4.23877217e-01, -4.09637161e-01],\n",
       "         [ 1.03697182e-01,  8.52175614e-01, -1.91749909e-02, ...,\n",
       "          -3.95215782e-01, -4.23877217e-01, -4.09637161e-01],\n",
       "         ...,\n",
       "         [ 1.03697182e-01,  8.52175614e-01, -1.91749909e-02, ...,\n",
       "          -3.95215782e-01, -4.23877217e-01, -4.09637161e-01],\n",
       "         [ 1.03697182e-01,  8.52175614e-01, -1.91749909e-02, ...,\n",
       "          -3.95215782e-01, -4.23877217e-01, -4.09637161e-01],\n",
       "         [ 1.03697182e-01,  8.52175614e-01, -1.91749909e-02, ...,\n",
       "          -3.95215782e-01, -4.23877217e-01, -4.09637161e-01]],\n",
       " \n",
       "        [[-1.23191888e-01, -2.49929033e-01,  2.86599418e+01, ...,\n",
       "           1.62129982e+00,  2.30014276e+00,  2.06701132e+00],\n",
       "         [-1.23191888e-01, -2.49929033e-01, -1.91749909e-02, ...,\n",
       "          -3.95215782e-01, -4.23877217e-01, -4.09637161e-01],\n",
       "         [-1.23191888e-01, -2.49929033e-01, -1.91749909e-02, ...,\n",
       "          -3.95215782e-01, -4.23877217e-01, -4.09637161e-01],\n",
       "         ...,\n",
       "         [-1.23191888e-01, -2.49929033e-01, -1.91749909e-02, ...,\n",
       "          -3.95215782e-01, -4.23877217e-01, -4.09637161e-01],\n",
       "         [-1.23191888e-01, -2.49929033e-01, -1.91749909e-02, ...,\n",
       "          -3.95215782e-01, -4.23877217e-01, -4.09637161e-01],\n",
       "         [-1.23191888e-01, -2.49929033e-01, -1.91749909e-02, ...,\n",
       "          -3.95215782e-01, -4.23877217e-01, -4.09637161e-01]]]),\n",
       " array([[[ 3.21802993e+00,  1.23185162e+00,  5.53480181e+00, ...,\n",
       "           1.60816844e+00,  2.28788094e+00,  2.04571026e+00],\n",
       "         [ 3.21802993e+00,  1.23185162e+00, -3.72550312e-02, ...,\n",
       "          -3.96914986e-01, -4.25811264e-01, -4.10469573e-01],\n",
       "         [ 3.21802993e+00,  1.23185162e+00, -3.72550312e-02, ...,\n",
       "          -3.96914986e-01, -4.25811264e-01, -4.10469573e-01],\n",
       "         ...,\n",
       "         [ 3.21802993e+00,  1.23185162e+00, -3.72550312e-02, ...,\n",
       "          -3.96914986e-01, -4.25811264e-01, -4.10469573e-01],\n",
       "         [ 3.21802993e+00,  1.23185162e+00, -3.72550312e-02, ...,\n",
       "          -3.96914986e-01, -4.25811264e-01, -4.10469573e-01],\n",
       "         [ 3.21802993e+00,  1.23185162e+00, -3.72550312e-02, ...,\n",
       "          -3.96914986e-01, -4.25811264e-01, -4.10469573e-01]],\n",
       " \n",
       "        [[-2.39964557e-01, -1.02451461e-01,  5.53480181e+00, ...,\n",
       "           1.60816844e+00,  2.28788094e+00,  2.04571026e+00],\n",
       "         [-2.39964557e-01, -1.02451461e-01, -3.72550312e-02, ...,\n",
       "          -3.96914986e-01, -4.25811264e-01, -4.10469573e-01],\n",
       "         [-2.39964557e-01, -1.02451461e-01, -3.72550312e-02, ...,\n",
       "          -3.96914986e-01, -4.25811264e-01, -4.10469573e-01],\n",
       "         ...,\n",
       "         [-2.39964557e-01, -1.02451461e-01, -3.72550312e-02, ...,\n",
       "          -3.96914986e-01, -4.25811264e-01, -4.10469573e-01],\n",
       "         [-2.39964557e-01, -1.02451461e-01, -3.72550312e-02, ...,\n",
       "          -3.96914986e-01, -4.25811264e-01, -4.10469573e-01],\n",
       "         [-2.39964557e-01, -1.02451461e-01, -3.72550312e-02, ...,\n",
       "          -3.96914986e-01, -4.25811264e-01, -4.10469573e-01]],\n",
       " \n",
       "        [[-3.19220440e-01, -3.50250604e-01,  2.78230292e+01, ...,\n",
       "           3.61325187e+00,  2.28788094e+00,  5.72998000e+00],\n",
       "         [-3.27960641e-01, -3.53200594e-01,  7.79715407e+01, ...,\n",
       "           3.61325187e+00,  2.28788094e+00,  1.18704296e+01],\n",
       "         [-3.28054604e-01, -3.53427516e-01,  2.78230292e+01, ...,\n",
       "           3.61325187e+00,  2.28788094e+00,  1.43266094e+01],\n",
       "         ...,\n",
       "         [-3.28054604e-01, -3.53427516e-01, -3.72550312e-02, ...,\n",
       "          -3.96914986e-01, -4.25811264e-01, -4.10469573e-01],\n",
       "         [-3.28054604e-01, -3.53427516e-01, -3.72550312e-02, ...,\n",
       "          -3.96914986e-01, -4.25811264e-01, -4.10469573e-01],\n",
       "         [-3.28054604e-01, -3.53427516e-01, -3.72550312e-02, ...,\n",
       "          -3.96914986e-01, -4.25811264e-01, -4.10469573e-01]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[-1.64692831e-01, -2.77181626e-01,  5.53480181e+00, ...,\n",
       "           1.60816844e+00,  2.28788094e+00,  2.04571026e+00],\n",
       "         [-1.64692831e-01, -2.77181626e-01, -3.72550312e-02, ...,\n",
       "          -3.96914986e-01, -4.25811264e-01, -4.10469573e-01],\n",
       "         [-1.64692831e-01, -2.77181626e-01, -3.72550312e-02, ...,\n",
       "          -3.96914986e-01, -4.25811264e-01, -4.10469573e-01],\n",
       "         ...,\n",
       "         [-1.64692831e-01, -2.77181626e-01, -3.72550312e-02, ...,\n",
       "          -3.96914986e-01, -4.25811264e-01, -4.10469573e-01],\n",
       "         [-1.64692831e-01, -2.77181626e-01, -3.72550312e-02, ...,\n",
       "          -3.96914986e-01, -4.25811264e-01, -4.10469573e-01],\n",
       "         [-1.64692831e-01, -2.77181626e-01, -3.72550312e-02, ...,\n",
       "          -3.96914986e-01, -4.25811264e-01, -4.10469573e-01]],\n",
       " \n",
       "        [[ 1.08554273e-01,  9.77698653e-01,  5.53480181e+00, ...,\n",
       "           1.60816844e+00,  2.28788094e+00,  2.04571026e+00],\n",
       "         [ 1.08554273e-01,  9.77698653e-01, -3.72550312e-02, ...,\n",
       "          -3.96914986e-01, -4.25811264e-01, -4.10469573e-01],\n",
       "         [ 1.08554273e-01,  9.77698653e-01, -3.72550312e-02, ...,\n",
       "          -3.96914986e-01, -4.25811264e-01, -4.10469573e-01],\n",
       "         ...,\n",
       "         [ 1.08554273e-01,  9.77698653e-01, -3.72550312e-02, ...,\n",
       "          -3.96914986e-01, -4.25811264e-01, -4.10469573e-01],\n",
       "         [ 1.08554273e-01,  9.77698653e-01, -3.72550312e-02, ...,\n",
       "          -3.96914986e-01, -4.25811264e-01, -4.10469573e-01],\n",
       "         [ 1.08554273e-01,  9.77698653e-01, -3.72550312e-02, ...,\n",
       "          -3.96914986e-01, -4.25811264e-01, -4.10469573e-01]],\n",
       " \n",
       "        [[-1.21580239e-01, -2.64473978e-01,  5.53480181e+00, ...,\n",
       "           1.60816844e+00,  2.28788094e+00,  2.04571026e+00],\n",
       "         [-1.21580239e-01, -2.64473978e-01, -3.72550312e-02, ...,\n",
       "          -3.96914986e-01, -4.25811264e-01, -4.10469573e-01],\n",
       "         [-1.21580239e-01, -2.64473978e-01, -3.72550312e-02, ...,\n",
       "          -3.96914986e-01, -4.25811264e-01, -4.10469573e-01],\n",
       "         ...,\n",
       "         [-1.21580239e-01, -2.64473978e-01, -3.72550312e-02, ...,\n",
       "          -3.96914986e-01, -4.25811264e-01, -4.10469573e-01],\n",
       "         [-1.21580239e-01, -2.64473978e-01, -3.72550312e-02, ...,\n",
       "          -3.96914986e-01, -4.25811264e-01, -4.10469573e-01],\n",
       "         [-1.21580239e-01, -2.64473978e-01, -3.72550312e-02, ...,\n",
       "          -3.96914986e-01, -4.25811264e-01, -4.10469573e-01]]]),\n",
       " array([[[ 3.21341853,  1.23275135,  2.61474208, ...,  1.58068584,\n",
       "           2.26149796,  2.00539398],\n",
       "         [ 3.21341853,  1.23275135, -0.05352038, ..., -0.40069129,\n",
       "          -0.43011293, -0.41306171],\n",
       "         [ 3.21341853,  1.23275135, -0.05352038, ..., -0.40069129,\n",
       "          -0.43011293, -0.41306171],\n",
       "         ...,\n",
       "         [ 3.21341853,  1.23275135, -0.05352038, ..., -0.40069129,\n",
       "          -0.43011293, -0.41306171],\n",
       "         [ 3.21341853,  1.23275135, -0.05352038, ..., -0.40069129,\n",
       "          -0.43011293, -0.41306171],\n",
       "         [ 3.21341853,  1.23275135, -0.05352038, ..., -0.40069129,\n",
       "          -0.43011293, -0.41306171]],\n",
       " \n",
       "        [[-0.24150214, -0.10270973,  2.61474208, ...,  1.58068584,\n",
       "           2.26149796,  2.00539398],\n",
       "         [-0.24150214, -0.10270973, -0.05352038, ..., -0.40069129,\n",
       "          -0.43011293, -0.41306171],\n",
       "         [-0.24150214, -0.10270973, -0.05352038, ..., -0.40069129,\n",
       "          -0.43011293, -0.41306171],\n",
       "         ...,\n",
       "         [-0.24150214, -0.10270973, -0.05352038, ..., -0.40069129,\n",
       "          -0.43011293, -0.41306171],\n",
       "         [-0.24150214, -0.10270973, -0.05352038, ..., -0.40069129,\n",
       "          -0.43011293, -0.41306171],\n",
       "         [-0.24150214, -0.10270973, -0.05352038, ..., -0.40069129,\n",
       "          -0.43011293, -0.41306171]],\n",
       " \n",
       "        [[-0.32068757, -0.35072393, 13.28779194, ...,  3.56206297,\n",
       "           2.26149796,  5.63307752],\n",
       "         [-0.32944471, -0.35373625, 50.64346644, ...,  3.56206297,\n",
       "           2.26149796, 14.09767244],\n",
       "         [-0.32944471, -0.35373625, -0.05352038, ..., -0.40069129,\n",
       "          -0.43011293, -0.41306171],\n",
       "         ...,\n",
       "         [-0.32944471, -0.35373625, -0.05352038, ..., -0.40069129,\n",
       "          -0.43011293, -0.41306171],\n",
       "         [-0.32944471, -0.35373625, -0.05352038, ..., -0.40069129,\n",
       "          -0.43011293, -0.41306171],\n",
       "         [-0.32944471, -0.35373625, -0.05352038, ..., -0.40069129,\n",
       "          -0.43011293, -0.41306171]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[-0.16629732, -0.27759154,  2.61474208, ...,  1.58068584,\n",
       "           2.26149796,  2.00539398],\n",
       "         [-0.16629732, -0.27759154, -0.05352038, ..., -0.40069129,\n",
       "          -0.43011293, -0.41306171],\n",
       "         [-0.16629732, -0.27759154, -0.05352038, ..., -0.40069129,\n",
       "          -0.43011293, -0.41306171],\n",
       "         ...,\n",
       "         [-0.16629732, -0.27759154, -0.05352038, ..., -0.40069129,\n",
       "          -0.43011293, -0.41306171],\n",
       "         [-0.16629732, -0.27759154, -0.05352038, ..., -0.40069129,\n",
       "          -0.43011293, -0.41306171],\n",
       "         [-0.16629732, -0.27759154, -0.05352038, ..., -0.40069129,\n",
       "          -0.43011293, -0.41306171]],\n",
       " \n",
       "        [[ 0.10670689,  0.97837781,  2.61474208, ...,  1.58068584,\n",
       "           2.26149796,  2.00539398],\n",
       "         [ 0.10670689,  0.97837781, -0.05352038, ..., -0.40069129,\n",
       "          -0.43011293, -0.41306171],\n",
       "         [ 0.10670689,  0.97837781, -0.05352038, ..., -0.40069129,\n",
       "          -0.43011293, -0.41306171],\n",
       "         ...,\n",
       "         [ 0.10670689,  0.97837781, -0.05352038, ..., -0.40069129,\n",
       "          -0.43011293, -0.41306171],\n",
       "         [ 0.10670689,  0.97837781, -0.05352038, ..., -0.40069129,\n",
       "          -0.43011293, -0.41306171],\n",
       "         [ 0.10670689,  0.97837781, -0.05352038, ..., -0.40069129,\n",
       "          -0.43011293, -0.41306171]],\n",
       " \n",
       "        [[-0.12322306, -0.26487287,  2.61474208, ...,  1.58068584,\n",
       "           2.26149796,  2.00539398],\n",
       "         [-0.12322306, -0.26487287, -0.05352038, ..., -0.40069129,\n",
       "          -0.43011293, -0.41306171],\n",
       "         [-0.12322306, -0.26487287, -0.05352038, ..., -0.40069129,\n",
       "          -0.43011293, -0.41306171],\n",
       "         ...,\n",
       "         [-0.12322306, -0.26487287, -0.05352038, ..., -0.40069129,\n",
       "          -0.43011293, -0.41306171],\n",
       "         [-0.12322306, -0.26487287, -0.05352038, ..., -0.40069129,\n",
       "          -0.43011293, -0.41306171],\n",
       "         [-0.12322306, -0.26487287, -0.05352038, ..., -0.40069129,\n",
       "          -0.43011293, -0.41306171]]]),\n",
       " array([[[ 3.22139641,  1.24416787,  1.71696252, ...,  1.54079709,\n",
       "           2.22537137,  1.94456395],\n",
       "         [ 3.22139641,  1.24416787, -0.07171664, ..., -0.40600244,\n",
       "          -0.43620236, -0.41593347],\n",
       "         [ 3.22139641,  1.24416787, -0.07171664, ..., -0.40600244,\n",
       "          -0.43620236, -0.41593347],\n",
       "         ...,\n",
       "         [ 3.22139641,  1.24416787, -0.07171664, ..., -0.40600244,\n",
       "          -0.43620236, -0.41593347],\n",
       "         [ 3.22139641,  1.24416787, -0.07171664, ..., -0.40600244,\n",
       "          -0.43620236, -0.41593347],\n",
       "         [ 3.22139641,  1.24416787, -0.07171664, ..., -0.40600244,\n",
       "          -0.43620236, -0.41593347]],\n",
       " \n",
       "        [[-0.24016173, -0.10184174,  1.71696252, ...,  1.54079709,\n",
       "           2.22537137,  1.94456395],\n",
       "         [-0.24016173, -0.10184174, -0.07171664, ..., -0.40600244,\n",
       "          -0.43620236, -0.41593347],\n",
       "         [-0.24016173, -0.10184174, -0.07171664, ..., -0.40600244,\n",
       "          -0.43620236, -0.41593347],\n",
       "         ...,\n",
       "         [-0.24016173, -0.10184174, -0.07171664, ..., -0.40600244,\n",
       "          -0.43620236, -0.41593347],\n",
       "         [-0.24016173, -0.10184174, -0.07171664, ..., -0.40600244,\n",
       "          -0.43620236, -0.41593347],\n",
       "         [-0.24016173, -0.10184174, -0.07171664, ..., -0.40600244,\n",
       "          -0.43620236, -0.41593347]],\n",
       " \n",
       "        [[-0.31949929, -0.35181495,  8.87167913, ...,  3.48759663,\n",
       "           2.22537137,  5.48531008],\n",
       "         [-0.32827325, -0.35485106, 33.91318728, ...,  3.48759663,\n",
       "           2.22537137, 13.74705105],\n",
       "         [-0.32827325, -0.35485106, -0.07171664, ..., -0.40600244,\n",
       "          -0.43620236, -0.41593347],\n",
       "         ...,\n",
       "         [-0.32827325, -0.35485106, -0.07171664, ..., -0.40600244,\n",
       "          -0.43620236, -0.41593347],\n",
       "         [-0.32827325, -0.35485106, -0.07171664, ..., -0.40600244,\n",
       "          -0.43620236, -0.41593347],\n",
       "         [-0.32827325, -0.35485106, -0.07171664, ..., -0.40600244,\n",
       "          -0.43620236, -0.41593347]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[-0.16481243, -0.2781049 ,  1.71696252, ...,  1.54079709,\n",
       "           2.22537137,  1.94456395],\n",
       "         [-0.16481243, -0.2781049 , -0.07171664, ..., -0.40600244,\n",
       "          -0.43620236, -0.41593347],\n",
       "         [-0.16481243, -0.2781049 , -0.07171664, ..., -0.40600244,\n",
       "          -0.43620236, -0.41593347],\n",
       "         ...,\n",
       "         [-0.16481243, -0.2781049 , -0.07171664, ..., -0.40600244,\n",
       "          -0.43620236, -0.41593347],\n",
       "         [-0.16481243, -0.2781049 , -0.07171664, ..., -0.40600244,\n",
       "          -0.43620236, -0.41593347],\n",
       "         [-0.16481243, -0.2781049 , -0.07171664, ..., -0.40600244,\n",
       "          -0.43620236, -0.41593347]],\n",
       " \n",
       "        [[ 0.10871627,  0.98778509,  1.71696252, ...,  1.54079709,\n",
       "           2.22537137,  1.94456395],\n",
       "         [ 0.10871627,  0.98778509, -0.07171664, ..., -0.40600244,\n",
       "          -0.43620236, -0.41593347],\n",
       "         [ 0.10871627,  0.98778509, -0.07171664, ..., -0.40600244,\n",
       "          -0.43620236, -0.41593347],\n",
       "         ...,\n",
       "         [ 0.10871627,  0.98778509, -0.07171664, ..., -0.40600244,\n",
       "          -0.43620236, -0.41593347],\n",
       "         [ 0.10871627,  0.98778509, -0.07171664, ..., -0.40600244,\n",
       "          -0.43620236, -0.41593347],\n",
       "         [ 0.10871627,  0.98778509, -0.07171664, ..., -0.40600244,\n",
       "          -0.43620236, -0.41593347]],\n",
       " \n",
       "        [[-0.12165541, -0.26528576,  1.71696252, ...,  1.54079709,\n",
       "           2.22537137,  1.94456395],\n",
       "         [-0.12165541, -0.26528576, -0.07171664, ..., -0.40600244,\n",
       "          -0.43620236, -0.41593347],\n",
       "         [-0.12165541, -0.26528576, -0.07171664, ..., -0.40600244,\n",
       "          -0.43620236, -0.41593347],\n",
       "         ...,\n",
       "         [-0.12165541, -0.26528576, -0.07171664, ..., -0.40600244,\n",
       "          -0.43620236, -0.41593347],\n",
       "         [-0.12165541, -0.26528576, -0.07171664, ..., -0.40600244,\n",
       "          -0.43620236, -0.41593347],\n",
       "         [-0.12165541, -0.26528576, -0.07171664, ..., -0.40600244,\n",
       "          -0.43620236, -0.41593347]]])]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "387"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The name \"input0\" is used 3 times in the model. All layer names should be unique.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-706-995d9898fd69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mlayer3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m'hidden_layer3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster_type_input\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, inputs, outputs, name, trainable, **kwargs)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0mgeneric_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFunctional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_automatic_dependency_tracking\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[0;34m(self, inputs, outputs)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;31m# Keep track of the network's nodes and layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m     nodes, nodes_by_depth, layers, _ = _map_graph_network(\n\u001b[0m\u001b[1;32m    193\u001b[0m         self.inputs, self.outputs)\n\u001b[1;32m    194\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_network_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/keras/engine/functional.py\u001b[0m in \u001b[0;36m_map_graph_network\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m    992\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mall_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m       raise ValueError('The name \"' + name + '\" is used ' +\n\u001b[0m\u001b[1;32m    995\u001b[0m                        \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' times in the model. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m                        'All layer names should be unique.')\n",
      "\u001b[0;31mValueError\u001b[0m: The name \"input0\" is used 3 times in the model. All layer names should be unique."
     ]
    }
   ],
   "source": [
    "cluster_type_input = Input(shape=(1, ))\n",
    "clusters_concat = tf.keras.layers.Concatenate()([cluster1, cluster2, cluster3])\n",
    "final_concat = tf.keras.layers.Concatenate()([clusters_concat, cluster_type_input])\n",
    "layer1 = Dense(50, activation='relu', name ='hidden_layer1')(final_concat)\n",
    "layer2 = Dense(25, activation='relu', name ='hidden_layer2')(layer1)\n",
    "layer3 = Dense(5, activation='relu', name ='hidden_layer3')(layer2)\n",
    "out = Dense(1, activation='sigmoid')(layer3)\n",
    "Model(inputs=[input0, input1, input2, input3, input4, input5, input6, input7, input8, input9, input10, input11, cluster_type_input], outputs=out )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside predict 1\n",
      "prediction and actuals 126 126\n",
      "inside predict 1\n",
      "prediction and actuals 88 88\n",
      "inside predict 1\n",
      "prediction and actuals 32 32\n",
      "246\n",
      "246\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.6056910569105691,\n",
       " 'recall': 0.7681159420289855,\n",
       " 'precision': 0.39552238805970147,\n",
       " 'f1_score': 0.5221674876847291,\n",
       " 'pr_auc': 0.4387294881266916,\n",
       " 'auc': 0.7037582903463523}"
      ]
     },
     "execution_count": 607,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 25) dtype=float32 (created by layer 'hidden_layer3')>"
      ]
     },
     "execution_count": 614,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 25) dtype=float32 (created by layer 'hidden_layer3')>"
      ]
     },
     "execution_count": 616,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputA = Input(shape=(25,))\n",
    "inputB = Input(shape=(25,))\n",
    "inputC = Input(shape=(25,))\n",
    "inputD = Input(shape=(1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 25) dtype=float32 (created by layer 'input_9')>"
      ]
     },
     "execution_count": 618,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 25) dtype=float32 (created by layer 'input_10')>"
      ]
     },
     "execution_count": 619,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 25) dtype=float32 (created by layer 'input_11')>"
      ]
     },
     "execution_count": 620,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputC"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
